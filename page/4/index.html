<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"juggler.fun","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:type" content="website">
<meta property="og:title" content="JugglerDancing">
<meta property="og:url" content="https://juggler.fun/page/4/index.html">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Juggler">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://juggler.fun/page/4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/4/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>JugglerDancing</title>
  





  <script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js" integrity="sha256-6Y7CJDaltoeNgk+ZftgCD9jLgmGv4xKUo8nQ0HgAwVo=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" integrity="sha256-uqQQGnDcmRKvhKwc5Vm4XT1GQ2oV6t1U0NR2N9tV+BQ=" crossorigin="anonymous" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
<div id="aplayer"></div>
<script type="text/javascript" src="/dist/music.js"></script>
	<div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">JugglerDancing</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Juggler is dancing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container">
  <div class="algolia-stats"><hr></div>
  <div class="algolia-hits"></div>
  <div class="algolia-pagination"></div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Juggler"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Juggler</p>
  <div class="site-description" itemprop="description">吾之生命如流星，誓要从全世界路过。</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">22</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/Pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/Pytorch/" class="post-title-link" itemprop="url">Pytorch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:44" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:44+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:41" itemprop="dateModified" datetime="2022-03-23T11:23:41+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s</p>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,dtype=torch.double)</span><br><span class="line">x.size()</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>,device=device)</span><br><span class="line">y = torch.rand(<span class="number">2</span>,<span class="number">2</span>,device=device)</span><br><span class="line">z = x+y <span class="comment">#+-*/</span></span><br><span class="line">z = torch.add(x,y)<span class="comment">#add sub mul</span></span><br><span class="line">y.add_(x)<span class="comment"># sub_ div_ 原地操作</span></span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">x[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line"></span><br><span class="line">y=x.view(-<span class="number">1</span>,<span class="number">2</span>) <span class="comment">#插眼</span></span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">a.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">a.add_(<span class="number">13</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"></span><br><span class="line">a = np.ones(<span class="number">6</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)<span class="comment">#***</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = x+<span class="number">2</span></span><br><span class="line">z = y*y*<span class="number">2</span></span><br><span class="line"><span class="comment">#z = z.mean()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.001</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">z.backward(v)<span class="comment"># 插眼：如果不是标量则必须给vecor ***</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dont calculate 插眼</span></span><br><span class="line"><span class="comment">#x.requires_grad_(False)</span></span><br><span class="line"><span class="comment">#y = x.detach()</span></span><br><span class="line"><span class="comment">#with torch.no_grad():</span></span><br><span class="line"><span class="comment">#    y = x + 2</span></span><br><span class="line"><span class="comment">#    print(y)</span></span><br><span class="line"></span><br><span class="line">weights = torch.ones(<span class="number">4</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model_output = (weights*<span class="number">3</span>).<span class="built_in">sum</span>()</span><br><span class="line">    model_output.backward()</span><br><span class="line">    <span class="built_in">print</span>(weights.grad)</span><br><span class="line"></span><br><span class="line">    weights.grad.zero_() <span class="comment">#将积累的计算清零 插眼，需要深入理解 ***</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#optimizer</span></span><br><span class="line"><span class="comment">#optimizer = torch.optim.SGD([weights], lr=0.01)</span></span><br><span class="line"><span class="comment">#optimizer.step()</span></span><br><span class="line"><span class="comment">#optimizer.zero_grad()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">w = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_hat = w * x</span><br><span class="line">loss = (y_hat-y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>

<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png" alt="image-20220316151942503"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=np.float32)</span><br><span class="line">w = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    dw = gradient(x,y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    w-=learning_rate * dw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png" alt="image-20220316145349626"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= learning_rate * w.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    w.grad.zero_()        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Training-pipeline"><a href="#Training-pipeline" class="headerlink" title="Training pipeline"></a>Training pipeline</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png" alt="image-20220316153456524"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="comment">#y_pred = model(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png" alt="image-20220316153507880"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line"><span class="comment">#w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    <span class="comment">#y_pred = forward(x)</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">x_numpy,y_numpy = datasets.make_regression(n_samples=<span class="number">100</span>,n_features=<span class="number">1</span>,noise=<span class="number">20</span>,random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = torch.from_numpy(x_numpy.astype(np.float32))</span><br><span class="line">y = torch.from_numpy(y_numpy.astype(np.float32))</span><br><span class="line">y = y.view(y.shape[<span class="number">0</span>],<span class="number">1</span>)<span class="comment"># 插眼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = nn.Linear(input_size,output_size)</span><br><span class="line">pr = model(x).detach().numpy()</span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># forward pss and loss</span></span><br><span class="line">    y_predicted = model(x)</span><br><span class="line">    loss = criterion(y_predicted,y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">predicted = model(x).detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(x_numpy,y_numpy,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x_numpy,predicted,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">bc = datasets.load_breast_cancer()</span><br><span class="line">x,y = bc.data,bc.target</span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#sclae</span></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">x_train = sc.fit_transform(x_train)</span><br><span class="line">x_test = sc.transform(x_test)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train.astype(np.float32))</span><br><span class="line">x_test = torch.from_numpy(x_test.astype(np.float32))</span><br><span class="line">y_train = torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">y_test = torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line">y_train = y_train.view(y_train.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line">y_test = y_test.view(y_test.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"><span class="comment"># f = wx+b, sigmod at the end</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_predicted = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_predicted</span><br><span class="line">model = LogisticRegression(n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.03</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="comment">#forward pass and loss</span></span><br><span class="line">    y_predicted = model(x_train)</span><br><span class="line">    loss = criterion(y_predicted,y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y_predicted = model(x_test)</span><br><span class="line">    y_predicted_cls = y_predicted.<span class="built_in">round</span>()</span><br><span class="line">    acc = y_predicted_cls.eq(y_test).<span class="built_in">sum</span>()/<span class="built_in">float</span>(y_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,</span><br><span class="line">                        skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = torch.from_numpy(xy[:, <span class="number">1</span>:])</span><br><span class="line">        self.y = torch.from_numpy(xy[:, [<span class="number">0</span>]])</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = WineDataSet()</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datatiter = iter(dataloader)</span></span><br><span class="line"><span class="comment"># data = datatiter.next()</span></span><br><span class="line"><span class="comment"># features, labels = data</span></span><br><span class="line"><span class="comment"># print(features,labels)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line">n_iterations = math.ceil(total_samples / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(total_samples, n_iterations)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># forward backward, update</span></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_iterations&#125;</span>,inputs <span class="subst">&#123;inputs.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-transformers"><a href="#Dataset-transformers" class="headerlink" title="Dataset transformers"></a>Dataset transformers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = xy[:, <span class="number">1</span>:]</span><br><span class="line">        self.y = xy[:, [<span class="number">0</span>]]</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        sample = self.x[index],self.y[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToTensor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,targets = sample</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(inputs),torch.from_numpy(targets)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulTransform</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,factor</span>):</span><br><span class="line">        self.factor = factor</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,target = sample</span><br><span class="line">        inputs *= self.factor</span><br><span class="line">        <span class="keyword">return</span> inputs,target</span><br><span class="line"></span><br><span class="line">dataset = WineDataSet(transform=<span class="literal">None</span>)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br><span class="line"></span><br><span class="line">composed = torchvision.transforms.Compose([ToTensor(),MulTransform(<span class="number">2</span>)])</span><br><span class="line">dataset = WineDataSet(transform=composed)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br></pre></td></tr></table></figure>

<h1 id="SoftMax-and-Crossentropy"><a href="#SoftMax-and-Crossentropy" class="headerlink" title="SoftMax and Crossentropy"></a>SoftMax and Crossentropy</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png" alt="image-20220317185503305"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x)/np.<span class="built_in">sum</span>(np.exp(x),axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = softmax(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;softmax numpy:&#x27;</span>,outputs)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = torch.softmax(x,dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">actual,predicted</span>):</span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(actual * np.log(predicted))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">Y_pred_good = np.array([<span class="number">0.7</span>,<span class="number">0.2</span>,<span class="number">0.1</span>])</span><br><span class="line">Y_pred_bad = np.array([<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>])</span><br><span class="line">l1 = cross_entropy(Y,Y_pred_good)</span><br><span class="line">l2 = cross_entropy(Y,Y_pred_bad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss1 numpy:<span class="subst">&#123;l1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss2 numpy:<span class="subst">&#123;l2:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#3 samples</span></span><br><span class="line"></span><br><span class="line">Y = torch.tensor([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">y_pred_good = torch.tensor([[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line">y_pred_bad = torch.tensor([[<span class="number">2.1</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">l1 = loss(y_pred_good,Y)</span><br><span class="line">l2 = loss(y_pred_bad,Y)</span><br><span class="line"><span class="built_in">print</span>(l1.item())</span><br><span class="line"><span class="built_in">print</span>(l2.item())</span><br><span class="line"></span><br><span class="line">_,pred1 = torch.<span class="built_in">max</span>(y_pred_good,<span class="number">1</span>)</span><br><span class="line">_,pred2 = torch.<span class="built_in">max</span>(y_pred_bad,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred1)</span><br><span class="line"><span class="built_in">print</span>(pred2)</span><br></pre></td></tr></table></figure>

<h1 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png" alt="image-20220318104226578"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png" alt="image-20220318104246948"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiclass problem</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line"></span><br><span class="line">        y_pred = torch.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = NeuralNet2(input_size=<span class="number">28</span>*<span class="number">28</span>,hidden_size=<span class="number">5</span>,num_classes=<span class="number">1</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># option1 create nn modules</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        <span class="comment">#nn.Sigmoid</span></span><br><span class="line">        <span class="comment">#nn.Softmax</span></span><br><span class="line">        <span class="comment">#nn.TanH</span></span><br><span class="line">        <span class="comment">#nn.LeakyReLU</span></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment"># option 2 use activation functions directly in forward pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        <span class="comment">#F.leaky_relu()</span></span><br><span class="line">        self.linear = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = torch.relu(self.linear1(x))</span><br><span class="line">        out = torch.simoid(self.linear2(out))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h1 id="Feed-Forward-Neural-Net"><a href="#Feed-Forward-Neural-Net" class="headerlink" title="Feed-Forward Neural Net"></a>Feed-Forward Neural Net</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># device config</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#hyper parameters</span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br><span class="line"><span class="comment"># DataLoader,Transformation</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">samples,labels = examples.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(samples.shape,labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(samples[i][<span class="number">0</span>],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = NeuralNet(input_size,hidden_size,num_classes)</span><br><span class="line">model=model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">## loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training loo</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#100,1,28,28</span></span><br><span class="line">        <span class="comment">#100,784</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#forward</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#backwards</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.n_ntotal_steps, loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#value,index</span></span><br><span class="line">        _,predictions = torch.<span class="built_in">max</span>(outputs,<span class="number">1</span>)</span><br><span class="line">        n_samples+= labels.shape[<span class="number">0</span>]</span><br><span class="line">        n_correct = (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = <span class="number">100.0</span>* n_correct/n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png" alt="image-20220318145648589"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset has PILImage images of range [0, 1]. </span></span><br><span class="line"><span class="comment"># We transform them to Tensors of normalized range [-1, 1]</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class</span></span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># -&gt; n, 3, 32, 32</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))  <span class="comment"># -&gt; n, 6, 14, 14</span></span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))  <span class="comment"># -&gt; n, 16, 5, 5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)            <span class="comment"># -&gt; n, 400</span></span><br><span class="line">        x = F.relu(self.fc1(x))               <span class="comment"># -&gt; n, 120</span></span><br><span class="line">        x = F.relu(self.fc2(x))               <span class="comment"># -&gt; n, 84</span></span><br><span class="line">        x = self.fc3(x)                       <span class="comment"># -&gt; n, 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet().to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># origin shape: [4, 3, 32, 32] = 4, 3, 1024</span></span><br><span class="line">        <span class="comment"># input_layer: 3 input channels, 6 output channels, 5 kernel size</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line">PATH = <span class="string">&#x27;./cnn.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    n_class_correct = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    n_class_samples = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            pred = predicted[i]</span><br><span class="line">            <span class="keyword">if</span> (label == pred):</span><br><span class="line">                n_class_correct[label] += <span class="number">1</span></span><br><span class="line">            n_class_samples[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        acc = <span class="number">100.0</span> * n_class_correct[i] / n_class_samples[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png" alt="image-20220318145729962"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">mean = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">std = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;data/hymenoptera_data&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=<span class="number">4</span>,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">25</span></span>):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        optimizer.zero_grad()</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Finetuning the convnet ####</span></span><br><span class="line"><span class="comment"># Load a pretrained model and reset final fully connected layer.</span></span><br><span class="line"></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 2.</span></span><br><span class="line"><span class="comment"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span></span><br><span class="line">model.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StepLR Decays the learning rate of each parameter group by gamma every step_size epochs</span></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Learning rate scheduling should be applied after optimizer’s update</span></span><br><span class="line"><span class="comment"># e.g., you should write your code this way:</span></span><br><span class="line"><span class="comment"># for epoch in range(100):</span></span><br><span class="line"><span class="comment">#     train(...)</span></span><br><span class="line"><span class="comment">#     validate(...)</span></span><br><span class="line"><span class="comment">#     scheduler.step()</span></span><br><span class="line"></span><br><span class="line">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### ConvNet as fixed feature extractor ####</span></span><br><span class="line"><span class="comment"># Here, we need to freeze all the network except the final layer.</span></span><br><span class="line"><span class="comment"># We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()</span></span><br><span class="line">model_conv = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that only parameters of final layer are being optimized as</span></span><br><span class="line"><span class="comment"># opposed to before.</span></span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># default `log_dir` is &quot;runs&quot; - we&#x27;ll be more specific here</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/mnist1&#x27;</span>)</span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment"># 28x28</span></span><br><span class="line">hidden_size = <span class="number">500</span> </span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST dataset </span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),  </span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, </span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, </span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">example_data, example_targets = examples.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(example_data)</span><br><span class="line">writer.add_image(<span class="string">&#x27;mnist_images&#x27;</span>, img_grid)</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully connected neural network with one hidden layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.l1 = nn.Linear(input_size, hidden_size) </span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="comment"># no activation and no softmax at the end</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = NeuralNet(input_size, hidden_size, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">writer.add_graph(model, example_data.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">running_correct = <span class="number">0</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        <span class="comment"># origin shape: [100, 1, 28, 28]</span></span><br><span class="line">        <span class="comment"># resized: [100, 784]</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        running_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>, running_loss / <span class="number">100</span>, epoch * n_total_steps + i)</span><br><span class="line">            running_accuracy = running_correct / <span class="number">100</span> / predicted.size(<span class="number">0</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, running_accuracy, epoch * n_total_steps + i)</span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            <span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="comment"># In test phase, we don&#x27;t need to compute gradients (for memory efficiency)</span></span><br><span class="line">class_labels = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        values, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        class_probs_batch = [F.softmax(output, dim=<span class="number">0</span>) <span class="keyword">for</span> output <span class="keyword">in</span> outputs]</span><br><span class="line"></span><br><span class="line">        class_preds.append(class_probs_batch)</span><br><span class="line">        class_labels.append(predicted)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000, 10, and 10000, 1</span></span><br><span class="line">    <span class="comment"># stack concatenates tensors along a new dimension</span></span><br><span class="line">    <span class="comment"># cat concatenates tensors in the given dimension</span></span><br><span class="line">    class_preds = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_preds])</span><br><span class="line">    class_labels = torch.cat(class_labels)</span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network on the 10000 test images: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">    classes = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">        labels_i = class_labels == i</span><br><span class="line">        preds_i = class_preds[:, i]</span><br><span class="line">        writer.add_pr_curve(<span class="built_in">str</span>(i), labels_i, preds_i, global_step=<span class="number">0</span>)</span><br><span class="line">        writer.close()</span><br><span class="line">    <span class="comment">###################################################</span></span><br></pre></td></tr></table></figure>

<h1 id="Save-amp-Load"><a href="#Save-amp-Load" class="headerlink" title="Save &amp; Load"></a>Save &amp; Load</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 3 DIFFERENT METHODS TO REMEMBER:</span></span><br><span class="line"><span class="string"> - torch.save(arg, PATH) # can be model, tensor, or dictionary</span></span><br><span class="line"><span class="string"> - torch.load(PATH)</span></span><br><span class="line"><span class="string"> - torch.load_state_dict(arg)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 2 DIFFERENT WAYS OF SAVING</span></span><br><span class="line"><span class="string"># 1) lazy way: save whole model</span></span><br><span class="line"><span class="string">torch.save(model, PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model class must be defined somewhere</span></span><br><span class="line"><span class="string">model = torch.load(PATH)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) recommended way: save only the state_dict</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model must be created again with parameters</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line"><span class="comment"># train your model...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################save all ######################################</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save and load entire model</span></span><br><span class="line"></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model, FILE)</span><br><span class="line"></span><br><span class="line">loaded_model = torch.load(FILE)</span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> loaded_model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############save only state dict #########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save only state dict</span></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model.state_dict(), FILE)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.state_dict())</span><br><span class="line">loaded_model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">loaded_model.load_state_dict(torch.load(FILE)) <span class="comment"># it takes the loaded dictionary, not the path file itself</span></span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loaded_model.state_dict())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########load checkpoint#####################</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="string">&quot;epoch&quot;</span>: <span class="number">90</span>,</span><br><span class="line"><span class="string">&quot;model_state&quot;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&quot;optim_state&quot;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line">FILE = <span class="string">&quot;checkpoint.pth&quot;</span></span><br><span class="line">torch.save(checkpoint, FILE)</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(FILE)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state&#x27;</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optim_state&#x27;</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line"><span class="comment"># model.train()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remember that you must call model.eval() to set dropout and batch normalization layers </span></span><br><span class="line"><span class="comment"># to evaluation mode before running inference. Failing to do this will yield </span></span><br><span class="line"><span class="comment"># inconsistent inference results. If you wish to resuming training, </span></span><br><span class="line"><span class="comment"># call model.train() to ensure these layers are in training mode.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; SAVING ON GPU/CPU </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 1) Save on GPU, Load on CPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=device))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) Save on GPU, Load on GPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note: Be sure to use the .to(torch.device(&#x27;cuda&#x27;)) function </span></span><br><span class="line"><span class="string"># on all model inputs, too!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 3) Save on CPU, Load on GPU</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># This loads the model to a given GPU device. </span></span><br><span class="line"><span class="string"># Next, be sure to call model.to(torch.device(&#x27;cuda&#x27;)) to convert the model’s parameter tensors to CUDA tensors</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





























      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/ML/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/ML/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" class="post-title-link" itemprop="url">李宏毅-機器學習</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:31" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:31+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-28 19:03:28" itemprop="dateModified" datetime="2022-03-28T19:03:28+08:00">2022-03-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>[toc]</p>
<p><a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw//~hylee/ml/2021-spring.php">https://speech.ee.ntu.edu.tw/\~hylee/ml/2021-spring.php</a></p>
<h1 id="預測本頻道觀看人數-上-機器學習基本概念簡介"><a href="#預測本頻道觀看人數-上-機器學習基本概念簡介" class="headerlink" title="預測本頻道觀看人數 (上) - 機器學習基本概念簡介"></a>預測本頻道觀看人數 (上) - 機器學習基本概念簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/Ye018rCVvOo?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2><p>机器学习就是让机器具备找一个函数的能力。</p>
<p>例子：</p>
<ul>
<li>语音识别</li>
<li>图像识别</li>
<li>α GO</li>
</ul>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031514843.png" alt="image-20220303151401751"></p>
<h2 id="不同类型的函数"><a href="#不同类型的函数" class="headerlink" title="不同类型的函数"></a>不同类型的函数</h2><ul>
<li>Regression: The function outputs a scalar.</li>
<li>Classification: Given options(classes),the function outputs the correct one,</li>
<li>Structured Learning, create something with structure(image,document)</li>
</ul>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031517026.png" alt="image-20220303151702930"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031518554.png" alt="image-20220303151817393"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031520115.png" alt="image-20220303152026894"></p>
<h2 id="How-to-find-a-function-A-Case-Study"><a href="#How-to-find-a-function-A-Case-Study" class="headerlink" title="How to find a function? A Case Study"></a>How to find a function? A Case Study</h2><p><strong>输入Youtube历史资料输出是第二天的浏览人数</strong></p>
<ul>
<li>Function with Unknown Parameters</li>
<li>Define Loss from Training Data</li>
<li>Optimization</li>
</ul>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031527089.png" alt="image-20220303152741986"> i</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031535689.png" alt="image-20220303153527593"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031536619.png" alt="image-20220303153641363"></p>
<p>这个图是error surface</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031542558.png" alt="image-20220303154220441"></p>
<p>步伐取决于斜率和learningrate</p>
<p>Hyperparameters 超参数</p>
<p><strong>Gradient descent</strong>并不是总能停在global minima 而是停在了local minima.</p>
<p>该问题可以被解决，并不是gradient descent真正的通点(插眼，我猜是计算量太大，引出随机梯度下降)</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031551963.png" alt="image-20220303155114875"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031554659.png" alt="image-20220303155404537"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031559165.png" alt="image-20220303155902077"></p>
<h3 id="写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）"><a href="#写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）" class="headerlink" title="写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）"></a>写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031606327.png" alt="image-20220303160601224"></p>
<p>似乎观看人数的循环规律止于7之28天之间</p>
<h1 id="預測本頻道觀看人數-下-深度學習基本概念簡介"><a href="#預測本頻道觀看人數-下-深度學習基本概念簡介" class="headerlink" title="預測本頻道觀看人數 (下) - 深度學習基本概念簡介"></a>預測本頻道觀看人數 (下) - 深度學習基本概念簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/bHcJCp2Fyxs?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="线性model太简单了"><a href="#线性model太简单了" class="headerlink" title="线性model太简单了"></a>线性model太简单了</h2><p>这种情况叫做Model Bias</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031619385.png" alt="image-20220303161928270"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031626802.png" alt="image-20220303162651714"></p>
<h2 id="Sigmoid-Function"><a href="#Sigmoid-Function" class="headerlink" title="Sigmoid Function"></a>Sigmoid Function</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031628608.png" alt="image-20220303162856520"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031630037.png" alt="image-20220303162959828"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031632307.png" alt="image-20220303163216198"></p>
<p>用多个feature加到一起去近似</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031634320.png" alt="image-20220303163431237"></p>
<p>引入离散数学：</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031641696.png" alt="image-20220303164128593"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031641091.png" alt="image-20220303164146976"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031643189.png" alt="image-20220303164345044"></p>
<p>最终得到<img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031644291.png" alt="image-20220303164410178"></p>
<h2 id="重新定义一些符号。。。"><a href="#重新定义一些符号。。。" class="headerlink" title="重新定义一些符号。。。"></a>重新定义一些符号。。。</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031646522.png" alt="image-20220303164649426"></p>
<h2 id="至此我们改进了前面提到的机器学习框架的第一步：Function-with-unknown"><a href="#至此我们改进了前面提到的机器学习框架的第一步：Function-with-unknown" class="headerlink" title="至此我们改进了前面提到的机器学习框架的第一步：Function with unknown"></a>至此我们改进了前面提到的机器学习框架的第一步：Function with unknown</h2><p>课外知识：Hard Sigmoid</p>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031653085.png" alt="image-20220303165346995"></p>
<p>先随机找一组θ初始值，以后可以有更好的方法，而不是随机的。之后根据梯度不断更新。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031657021.png" alt="image-20220303165751938"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031658809.png" alt="image-20220303165812728"></p>
<h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>将data随机分为多个batch，每次学习一个batch</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031700638.png" alt="image-20220303170034535"></p>
<p>每更新一次参数（学习一个batch）叫一次update，每更新完一轮data（学习了多个batch）叫一个epoch。</p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706785.png" alt="image-20220303170611709"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706753.png" alt="image-20220303170642672"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706502.png" alt="image-20220303170650433"></p>
<h2 id="实战效果"><a href="#实战效果" class="headerlink" title="实战效果"></a>实战效果</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031708375.png" alt="image-20220303170853283"></p>
<h2 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031709367.png" alt="image-20220303170931236"></p>
<h3 id="实战效果-1"><a href="#实战效果-1" class="headerlink" title="实战效果"></a>实战效果</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031711887.png" alt="image-20220303171108801"></p>
<h2 id="此即深度学习"><a href="#此即深度学习" class="headerlink" title="此即深度学习"></a>此即深度学习</h2><p>Deep &#x3D; Many hidden layers</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031716390.png" alt="image-20220303171659257"></p>
<h2 id="为什么不将网络变胖而是把它变深，-留待讲解，插眼。"><a href="#为什么不将网络变胖而是把它变深，-留待讲解，插眼。" class="headerlink" title="为什么不将网络变胖而是把它变深， 留待讲解，插眼。"></a>为什么不将网络变胖而是把它变深， 留待讲解，插眼。</h2><h2 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h2><p>训练数据loss减少，测试数据loss增大</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031720430.png" alt="image-20220303172014330"></p>
<h1 id="機器學習任務攻略"><a href="#機器學習任務攻略" class="headerlink" title="機器學習任務攻略"></a>機器學習任務攻略</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/WeHM2xpYQpw?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Framework-of-ML"><a href="#Framework-of-ML" class="headerlink" title="Framework of ML"></a>Framework of ML</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031738785.png" alt="image-20220303173837677"></p>
<h2 id="General-Guide"><a href="#General-Guide" class="headerlink" title="General Guide"></a>General Guide</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031739014.png" alt="image-20220303173913887"></p>
<h2 id="Model-bias"><a href="#Model-bias" class="headerlink" title="Model bias"></a>Model bias</h2><p>函数弹性不够大</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031742234.png" alt="image-20220303174220131"></p>
<h2 id="Optimization-Issue"><a href="#Optimization-Issue" class="headerlink" title="Optimization Issue"></a>Optimization Issue</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031744637.png" alt="image-20220303174412541"></p>
<h2 id="如何判断是model-Bias-还是Optimization-Issue的原因？"><a href="#如何判断是model-Bias-还是Optimization-Issue的原因？" class="headerlink" title="如何判断是model Bias 还是Optimization Issue的原因？"></a>如何判断是model Bias 还是Optimization Issue的原因？</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031746633.png" alt="image-20220303174638510"></p>
<p><strong>注意training data上的效果， 多出来的层数不进行操作都可以达到20层的效果，弹性应该比他大得多， 说明优化有问题</strong></p>
<p><strong>test data上出现这种情况可能是由于过拟合，但一定要在training data上验证了才可以确定</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031752014.png" alt="image-20220303175225883"></p>
<h2 id="Overfitting-1"><a href="#Overfitting-1" class="headerlink" title="Overfitting"></a>Overfitting</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031755366.png" alt="image-20220303175509274"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031756385.png" alt="image-20220303175647299"></p>
<p>测试数据过少，模型预测函数的自由度太大（由于弹性太大）。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>增加训练资料</li>
<li>Data augmentation<img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031800246.png" alt="image-20220303180005066"></li>
<li>Constrained model(根据实际情况降低model的弹性)，限制要适量，过度的话就拟合不出来了。<img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031808217.png" alt="image-20220303180822114"></li>
</ol>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031809367.png" alt="image-20220303180949271"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031816811.png" alt="image-20220303181623713"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031820371.png" alt="image-20220303182048257"></p>
<p>选mse最低的不一定就是最好的model</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031824145.png" alt="image-20220303182438942"></p>
<h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031830775.png" alt="image-20220303183009660"></p>
<h2 id="N-fold-Cross-Validation"><a href="#N-fold-Cross-Validation" class="headerlink" title="N-fold Cross Validation"></a>N-fold Cross Validation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031833724.png" alt="image-20220303183314584"></p>
<h2 id="Mismatch"><a href="#Mismatch" class="headerlink" title="Mismatch"></a>Mismatch</h2><p>由于没有将一些情况考虑进去，比如春节，data中不包含春节的经验，所以模型在考虑结果时当然不会考虑到春节的影响。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031837920.png" alt="image-20220303183747747"></p>
<h1 id="類神經網路訓練不起來怎麼辦-一-：-局部最小值-local-minima-與鞍點-saddle-point"><a href="#類神經網路訓練不起來怎麼辦-一-：-局部最小值-local-minima-與鞍點-saddle-point" class="headerlink" title="類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)"></a>類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)</h1><p>Optimization Fails because……</p>
<h2 id="当-gradient-接近零，学习速度也就接近0，其原因有可能为："><a href="#当-gradient-接近零，学习速度也就接近0，其原因有可能为：" class="headerlink" title="当 gradient 接近零，学习速度也就接近0，其原因有可能为："></a>当 gradient 接近零，学习速度也就接近0，其原因有可能为：</h2><ol>
<li>local minima</li>
<li>saddle point</li>
<li>critical point</li>
</ol>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031858346.png" alt="image-20220303185828184"></p>
<h2 id="如何确定到底是哪个原因？"><a href="#如何确定到底是哪个原因？" class="headerlink" title="如何确定到底是哪个原因？"></a>如何确定到底是哪个原因？</h2><h3 id="Tayler-Series-Approximation"><a href="#Tayler-Series-Approximation" class="headerlink" title="Tayler Series Approximation"></a>Tayler Series Approximation</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031902082.png" alt="image-20220303190237983"></p>
<p>可以根据二阶导数来判断：[ToL]</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031903553.png" alt="image-20220303190333409"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031906974.png" alt="image-20220303190611878"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031907993.png" alt="image-20220303190754882"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031921036.png" alt="image-20220303192157924"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031923676.png" alt="image-20220303192301531"></p>
<p><strong>实际上用到的机会少，因为随着模型规模的增大，二阶倒数太难算了</strong></p>
<h2 id="Saddle-Point-v-s-Local-Minima"><a href="#Saddle-Point-v-s-Local-Minima" class="headerlink" title="Saddle Point v.s. Local Minima"></a>Saddle Point v.s. Local Minima</h2><p>低维的local minima很有可能是高维的saddle point</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031930955.png" alt="image-20220303193046843"></p>
<p>Eigen value 为负的话还是有路可以降低loss</p>
<h1 id="類神經網路訓練不起來怎麼辦-二-：-批次-batch-與動量-momentum"><a href="#類神經網路訓練不起來怎麼辦-二-：-批次-batch-與動量-momentum" class="headerlink" title="類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)"></a>類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/zzbr1h9sF54?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041030179.png" alt="image-20220304103024053"></p>
<p>每次epoch重新分batch，每次这样的操作叫一次epoch</p>
<h2 id="Small-Batch-vs-Large-Batch"><a href="#Small-Batch-vs-Large-Batch" class="headerlink" title="Small Batch vs Large Batch"></a>Small Batch vs Large Batch</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041033664.png" alt="image-20220304103318420"></p>
<h2 id="考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多"><a href="#考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多" class="headerlink" title="考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多"></a>考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041046728.png" alt="image-20220304104656601"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041048088.png" alt="image-20220304104858844"></p>
<h2 id="更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。"><a href="#更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。" class="headerlink" title="更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。"></a>更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041054516.png" alt="image-20220304105415406"></p>
<h2 id="即使train-data效果差不多，在test-data里小的batch-size也会得到更好的效果。"><a href="#即使train-data效果差不多，在test-data里小的batch-size也会得到更好的效果。" class="headerlink" title="即使train data效果差不多，在test data里小的batch size也会得到更好的效果。"></a>即使train data效果差不多，在test data里小的batch size也会得到更好的效果。</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041059093.png" alt="image-20220304105932975"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041101148.png" alt="image-20220304110100032"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041101633.png" alt="image-20220304110140510"></p>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041103317.png" alt="image-20220304110343178"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041129131.png" alt="image-20220304112920970"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041129992.png" alt="image-20220304112957929"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041131368.png" alt="image-20220304113126319"></p>
<p>所以有种说法说惯性受过去所有运动的影响。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041133673.png" alt="image-20220304113311573"></p>
<h1 id="類神經網路訓練不起來怎麼辦-三-：自動調整學習速率-Learning-Rate"><a href="#類神經網路訓練不起來怎麼辦-三-：自動調整學習速率-Learning-Rate" class="headerlink" title="類神經網路訓練不起來怎麼辦 (三)：自動調整學習速率 (Learning Rate)"></a>類神經網路訓練不起來怎麼辦 (三)：自動調整學習速率 (Learning Rate)</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/HYUXEeh3kwY?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="训练卡住了，loss不再下降，并不意味着到了local-minima-或者鞍点之类的"><a href="#训练卡住了，loss不再下降，并不意味着到了local-minima-或者鞍点之类的" class="headerlink" title="训练卡住了，loss不再下降，并不意味着到了local minima 或者鞍点之类的"></a>训练卡住了，loss不再下降，并不意味着到了local minima 或者鞍点之类的</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041136807.png" alt="image-20220304113647688"></p>
<p>这样的点叫Critical point</p>
<h2 id="But-training-can-be-difficult-even-without-critical-points"><a href="#But-training-can-be-difficult-even-without-critical-points" class="headerlink" title="But training can be difficult even without critical points"></a>But training can be difficult even without critical points</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041142539.png" alt="image-20220304114234366"></p>
<p>步伐(Learning rite)太大会在两边回荡，即critical point, 但是步伐太小又会使学习缓慢</p>
<h2 id="Different-Parameters-needs-different-learning-rate"><a href="#Different-Parameters-needs-different-learning-rate" class="headerlink" title="Different Parameters needs different learning rate"></a>Different Parameters needs different learning rate</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041148187.png" alt="image-20220304114813007"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041151498.png" alt="image-20220304115102390"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041151816.png" alt="image-20220304115136720"></p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041155229.png" alt="image-20220304115536101"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041357009.png" alt="image-20220304135729901"></p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041445576.png" alt="image-20220304144525383"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041450266.png" alt="image-20220304145033090"></p>
<h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><p>随着终点的临近让学习率下降（Learning rate decay）</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041452632.png" alt="image-20220304145205529"></p>
<h2 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h2><p>在transformer中引用了warm up的方法</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041501503.png" alt="image-20220304150125342"></p>
<h2 id="Summary-of-Optimization"><a href="#Summary-of-Optimization" class="headerlink" title="Summary of Optimization"></a>Summary of Optimization</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041505473.png" alt="image-20220304150534374"></p>
<p>两个都考虑所有历史，但是一个更注重方向，一个只注重大小。</p>
<h2 id="Next-Time"><a href="#Next-Time" class="headerlink" title="Next Time"></a>Next Time</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041509834.png" alt="image-20220304150952610"></p>
<h1 id="類神經網路訓練不起來怎麼辦-四-：損失函數-Loss-也可能有影響"><a href="#類神經網路訓練不起來怎麼辦-四-：損失函數-Loss-也可能有影響" class="headerlink" title="類神經網路訓練不起來怎麼辦 (四)：損失函數 (Loss) 也可能有影響"></a>類神經網路訓練不起來怎麼辦 (四)：損失函數 (Loss) 也可能有影響</h1><h2 id="To-learn-more"><a href="#To-learn-more" class="headerlink" title="To learn more"></a>To learn more</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041510324.png" alt="image-20220304151032225"></p>
<h2 id="Classification-as-Regression"><a href="#Classification-as-Regression" class="headerlink" title="Classification as Regression?"></a>Classification as Regression?</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041516201.png" alt="image-20220304151647092"></p>
<p>暗示12关系比较近，13比较远，所以不是很可行，所以选择one-hot编码。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041518549.png" alt="image-20220304151854421"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041520094.png" alt="image-20220304152006992"></p>
<p>SoftMax 将可以为任何值的数值映射到0～1之间</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041523578.png" alt="image-20220304152306438"></p>
<p>当只有两类时softmax和sigmoid是相同的 （插眼，没太懂）</p>
<h2 id="Loss-of-Classification"><a href="#Loss-of-Classification" class="headerlink" title="Loss of Classification"></a>Loss of Classification</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041526528.png" alt="image-20220304152656424"></p>
<p><strong>Minimizing cross-entropy is equivalent to maximizing likelihood.</strong></p>
<p>Pytorch Cross-entropy 内含Softmax</p>
<h2 id="为什么相较于MSE-Cross-entropy更常被用到"><a href="#为什么相较于MSE-Cross-entropy更常被用到" class="headerlink" title="为什么相较于MSE Cross-entropy更常被用到"></a>为什么相较于MSE Cross-entropy更常被用到</h2><p>MSE计算loss不容易从loss大的地方走下来，因为那里梯度太小了</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041535884.png" alt="image-20220304153548703"></p>
<h1 id="類神經網路訓練不起來怎麼辦-五-：-批次標準化-Batch-Normalization-簡介"><a href="#類神經網路訓練不起來怎麼辦-五-：-批次標準化-Batch-Normalization-簡介" class="headerlink" title="類神經網路訓練不起來怎麼辦 (五)： 批次標準化 (Batch Normalization) 簡介"></a>類神經網路訓練不起來怎麼辦 (五)： 批次標準化 (Batch Normalization) 簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/BABPWOkSbLE?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Changing-Landscape"><a href="#Changing-Landscape" class="headerlink" title="Changing Landscape"></a>Changing Landscape</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041546974.png" alt="image-20220304154632827"></p>
<p>上图很6</p>
<h2 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h2><p>Feature Normalization是上图的解决办法，以下是Feature Normalization的一种方法</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041551595.png" alt="image-20220304155117462"></p>
<p>In general, feature normalization makes gradient scent converge faster.</p>
<h2 id="Considering-Deep-Learning"><a href="#Considering-Deep-Learning" class="headerlink" title="Considering Deep Learning"></a>Considering Deep Learning</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041558809.png" alt="image-20220304155830694"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041600231.png" alt="image-20220304160019106"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041603772.png" alt="image-20220304160308639"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041607876.png" alt="image-20220304160723726"></p>
<h2 id="Batch-Normalization-插眼，没看太懂"><a href="#Batch-Normalization-插眼，没看太懂" class="headerlink" title="Batch Normalization[插眼，没看太懂]"></a>Batch Normalization[插眼，没看太懂]</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041610821.png" alt="image-20220304161028697"></p>
<h3 id="BN-in-Test"><a href="#BN-in-Test" class="headerlink" title="BN in Test"></a>BN in Test</h3><p>在训练时先将测试时没有的参数算出来</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041612417.png" alt="image-20220304161252307"></p>
<h2 id="Internal-Covariate-Shift"><a href="#Internal-Covariate-Shift" class="headerlink" title="Internal Covariate Shift?"></a>Internal Covariate Shift?</h2><p><strong>How Does Batch Normalization help Optimization</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041618922.png" alt="image-20220304161800822"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041621787.png" alt="image-20220304162115627"></p>
<h1 id="卷積神經網路-Convolutional-Neural-Networks-CNN"><a href="#卷積神經網路-Convolutional-Neural-Networks-CNN" class="headerlink" title="卷積神經網路 (Convolutional Neural Networks, CNN)"></a>卷積神經網路 (Convolutional Neural Networks, CNN)</h1><h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041626754.png" alt="image-20220304162622583"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041627457.png" alt="image-20220304162756344"></p>
<h2 id="Observation-1-x2F-x2F-引出receptive-field"><a href="#Observation-1-x2F-x2F-引出receptive-field" class="headerlink" title="Observation 1 &#x2F;&#x2F;引出receptive field"></a>Observation 1 &#x2F;&#x2F;引出receptive field</h2><p>y隐藏层一个节点观测图片的一小部分</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041630573.png" alt="image-20220304163005423"></p>
<h2 id="Simplification-1"><a href="#Simplification-1" class="headerlink" title="Simplification 1"></a>Simplification 1</h2><h3 id="receptive-field"><a href="#receptive-field" class="headerlink" title="receptive field"></a>receptive field</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041634243.png" alt="image-20220304163438134"></p>
<ul>
<li>Can different neurons have different sizes of receptive field?</li>
<li>Cover only some channels.</li>
<li>Not square receptive field?</li>
</ul>
<h3 id="Typical-Setting"><a href="#Typical-Setting" class="headerlink" title="Typical Setting"></a>Typical Setting</h3><p><strong>Kernel size</strong></p>
<p><strong>stride</strong></p>
<p><strong>overlap</strong></p>
<p><strong>padding</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041643682.png" alt="image-20220304164301547"></p>
<h2 id="Observation-2-x2F-x2F-引出filter"><a href="#Observation-2-x2F-x2F-引出filter" class="headerlink" title="Observation 2 &#x2F;&#x2F;引出filter"></a>Observation 2 &#x2F;&#x2F;引出filter</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041644756.png" alt="image-20220304164435601"></p>
<h2 id="Simplification-2"><a href="#Simplification-2" class="headerlink" title="Simplification 2"></a>Simplification 2</h2><p>两个节点照顾的位置不一样，但是参数是一样的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041647931.png" alt="image-20220304164731795"></p>
<h3 id="Typical-Setting-1"><a href="#Typical-Setting-1" class="headerlink" title="Typical Setting"></a>Typical Setting</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041649596.png" alt="image-20220304164923467"></p>
<h2 id="Benefit-of-Convolutional-Layer"><a href="#Benefit-of-Convolutional-Layer" class="headerlink" title="Benefit of Convolutional Layer"></a>Benefit of Convolutional Layer</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041651892.png" alt="image-20220304165101777"></p>
<p>弹性逐渐减小</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041651701.png" alt="image-20220304165134571"></p>
<h2 id="Convolutional-layer-x2F-x2F-另一种说法"><a href="#Convolutional-layer-x2F-x2F-另一种说法" class="headerlink" title="Convolutional layer &#x2F;&#x2F;另一种说法"></a>Convolutional layer &#x2F;&#x2F;另一种说法</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041656607.png" alt="image-20220304165611474"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041656649.png" alt="image-20220304165653532"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041657119.png" alt="image-20220304165700992"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041658075.png" alt="image-20220304165828912"></p>
<p>虽然只有3*3，但是后面的层的节点考虑到的会更大</p>
<h2 id="Comparison-of-Two-Stories"><a href="#Comparison-of-Two-Stories" class="headerlink" title="Comparison of Two Stories"></a>Comparison of Two Stories</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041701162.png" alt="image-20220304170144042"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041702290.png" alt="image-20220304170236195"></p>
<h2 id="Observation-3-x2F-x2F-引出pooling"><a href="#Observation-3-x2F-x2F-引出pooling" class="headerlink" title="Observation 3 &#x2F;&#x2F;引出pooling"></a>Observation 3 &#x2F;&#x2F;引出pooling</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041704770.png" alt="image-20220304170412626"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041705375.png" alt="image-20220304170500275"></p>
<p>Pooling 把图片变小</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041705189.png" alt="image-20220304170540035"></p>
<p>最主要的理由是减少运算量</p>
<h2 id="The-Whole-CNN"><a href="#The-Whole-CNN" class="headerlink" title="The Whole CNN"></a>The Whole CNN</h2><h3 id="Flatten-把所有数值拉直变成向量"><a href="#Flatten-把所有数值拉直变成向量" class="headerlink" title="Flatten 把所有数值拉直变成向量"></a>Flatten 把所有数值拉直变成向量</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041707777.png" alt="image-20220304170715646"></p>
<h2 id="Application-Playing-Go"><a href="#Application-Playing-Go" class="headerlink" title="Application: Playing Go"></a>Application: Playing Go</h2><p>下围棋是一个分类的问题</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041709589.png" alt="image-20220304170916451"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041710880.png" alt="image-20220304171007739"></p>
<p>α Go每个棋盘上的位置都有48个属性</p>
<h2 id="Why-CNN-for-GO-playing"><a href="#Why-CNN-for-GO-playing" class="headerlink" title="Why CNN for GO playing"></a>Why CNN for GO playing</h2><p>上面讲的observation跟围棋有相似性。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041712147.png" alt="image-20220304171251950"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041713448.png" alt="image-20220304171339209"></p>
<p>但要注意下围棋不适合用pooling</p>
<h2 id="More-Applications"><a href="#More-Applications" class="headerlink" title="More Applications"></a>More Applications</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041714210.png" alt="image-20220304171414066"></p>
<h2 id="To-learn-more-1"><a href="#To-learn-more-1" class="headerlink" title="To learn more"></a>To learn more</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041714142.png" alt="image-20220304171451982"></p>
<h1 id="自注意力機制-Self-attention-上"><a href="#自注意力機制-Self-attention-上" class="headerlink" title="自注意力機制 (Self-attention) (上)"></a>自注意力機制 (Self-attention) (上)</h1><p>regression输出是一个数值 输入是一个向量</p>
<p>classification 输出是一个类别 输入是一个向量</p>
<p>如果更复杂？</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071043556.png" alt="image-20220307104316456"></p>
<h2 id="Vector-as-Input"><a href="#Vector-as-Input" class="headerlink" title="Vector as Input"></a>Vector as Input</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071045288.png" alt="image-20220307104507177"></p>
<p>语音，社交网络，分子结构等可以转化为多个向量作为输入</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071047811.png" alt="image-20220307104723704"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071047867.png" alt="image-20220307104742682"></p>
<h2 id="What-is-the-output"><a href="#What-is-the-output" class="headerlink" title="What is the output?"></a>What is the output?</h2><h3 id="输入数量与输出数量一致"><a href="#输入数量与输出数量一致" class="headerlink" title="输入数量与输出数量一致"></a>输入数量与输出数量一致</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071051455.png" alt="image-20220307105157313"></p>
<h3 id="输入输出数量不一致"><a href="#输入输出数量不一致" class="headerlink" title="输入输出数量不一致"></a>输入输出数量不一致</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071054236.png" alt="image-20220307105424097"></p>
<h2 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="Sequence Labeling"></a>Sequence Labeling</h2><p>输入与输出一样多</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071058945.png" alt="image-20220307105846809"></p>
<p><strong>I saw a saw</strong></p>
<p>不能用fully-connected network，因为同一个词汇出现两次对于fully-connected network 来说是一样的,所以要用窗口，</p>
<p>但是由于输入长度不一定，窗口也就不一定，由此引出self -attention</p>
<h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071111335.png" alt="image-20220307111131085"></p>
<h2 id="Part-of-attention-network"><a href="#Part-of-attention-network" class="headerlink" title="Part of attention network"></a>Part of attention network</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071117302.png" alt="image-20220307111704195"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071125941.png" alt="image-20220307112506872"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071125982.png" alt="image-20220307112523817"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071127259.png" alt="image-20220307112724128"></p>
<p>谁的关联性更大，其向量就会更占支配地位，b1就会更像谁</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071131405.png" alt="image-20220307113107052"></p>
<h1 id="自注意力機制-Self-attention-下"><a href="#自注意力機制-Self-attention-下" class="headerlink" title="自注意力機制 (Self-attention) (下)"></a>自注意力機制 (Self-attention) (下)</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071137892.png" alt="image-20220307113754724"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071146043.png" alt="image-20220307114609872"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071149976.png" alt="image-20220307114954832"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071354645.png" alt="image-20220307135416518"></p>
<h2 id="Multi-head-self-attention"><a href="#Multi-head-self-attention" class="headerlink" title="Multi-head self-attention"></a>Multi-head self-attention</h2><p>得到q<sup>i</sup>,k<sup>i</sup>,v<sup>i</sup>后再乘两个矩阵得到两个结果。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071400284.png" alt="image-20220307140025135"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071401579.png" alt="image-20220307140123414"></p>
<h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>之前的公式没有结合位置信息</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071408609.png" alt="image-20220307140832441"></p>
<p>这里每个位置的向量是订好的</p>
<p>后来有了新的动态生成的办法</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071410740.png" alt="image-20220307141038425"></p>
<h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071411275.png" alt="image-20220307141125110"></p>
<h3 id="Speech"><a href="#Speech" class="headerlink" title="Speech"></a>Speech</h3><p>用于语音识别时要有所更改，因为语音识别所生成的向量太大了，如果结合所有输入的话计算量可能接受不了。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071414502.png" alt="image-20220307141400333"></p>
<h3 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071415634.png" alt="image-20220307141521417"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071415451.png" alt="image-20220307141535227"></p>
<h3 id="Self-attention-for-Graph"><a href="#Self-attention-for-Graph" class="headerlink" title="Self-attention for Graph"></a>Self-attention for Graph</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071433516.png" alt="image-20220307143348377"></p>
<h4 id="To-Learn-more-about-GNN"><a href="#To-Learn-more-about-GNN" class="headerlink" title="To Learn more about GNN"></a>To Learn more about GNN</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071434204.png" alt="image-20220307143445063"></p>
<h2 id="Self-attention-v-s-CNN"><a href="#Self-attention-v-s-CNN" class="headerlink" title="Self-attention v.s. CNN"></a>Self-attention v.s. CNN</h2><p>CNN 可以看作Self-attention的子集，</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071418941.png" alt="image-20220307141830783"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071418164.png" alt="image-20220307141815004"></p>
<p>资料少时用CNN，多时用self-attention，因为self-attention弹性更大（插眼，为啥？），需要的资料更多。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071421128.png" alt="image-20220307142129968"></p>
<h2 id="Self-attention-vs-RNN"><a href="#Self-attention-vs-RNN" class="headerlink" title="Self-attention vs RNN"></a>Self-attention vs RNN</h2><p>RNN：</p>
<ul>
<li>很难考虑远处的信息</li>
<li>不是平行的</li>
</ul>
<p>self-attention:</p>
<ul>
<li>相反</li>
</ul>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071430856.png" alt="image-20220307143053684"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071431403.png" alt="image-20220307143107347"></p>
<h3 id="To-learn-more-about-RNN"><a href="#To-learn-more-about-RNN" class="headerlink" title="To learn more about RNN"></a>To learn more about RNN</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071431895.png" alt="image-20220307143122783"></p>
<h2 id="To-Learn-More"><a href="#To-Learn-More" class="headerlink" title="To Learn More"></a>To Learn More</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071435335.png" alt="image-20220307143509187"></p>
<h1 id="Transformer-上-Encoder"><a href="#Transformer-上-Encoder" class="headerlink" title="Transformer(上) Encoder"></a>Transformer(上) Encoder</h1><h2 id="Sequence-to-sequence’s-application"><a href="#Sequence-to-sequence’s-application" class="headerlink" title="Sequence-to-sequence’s application"></a>Sequence-to-sequence’s application</h2><p>transformer 是一个Sequence-to-sequence(Swq2seq) model</p>
<p>输出长度是由模型决定的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071509244.png" alt="image-20220307150909089"></p>
<p>由闽南语音直接转为汉字</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071510052.png" alt="image-20220307151048819"></p>
<p>在翻译倒装句时错误率会更高</p>
<h3 id="Seq2seq-for-Chatbot"><a href="#Seq2seq-for-Chatbot" class="headerlink" title="Seq2seq for Chatbot"></a>Seq2seq for Chatbot</h3><p>Question Answering 可以理解为Seq2seq model 的问题</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071519000.png" alt="image-20220307151925810"></p>
<h3 id="Seq2seq-for-Syntactic-parsing"><a href="#Seq2seq-for-Syntactic-parsing" class="headerlink" title="Seq2seq for Syntactic parsing"></a>Seq2seq for Syntactic parsing</h3><p>输入句子输出文法分析树</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071523121.png" alt="image-20220307152313995"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071523984.png" alt="image-20220307152348890"></p>
<p>将文法视作一种语言用翻译的模型得到结果</p>
<h3 id="seq2seq-for-multi-label-classification"><a href="#seq2seq-for-multi-label-classification" class="headerlink" title="seq2seq for multi-label classification"></a>seq2seq for multi-label classification</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071527897.png" alt="image-20220307152715773"></p>
<h3 id="Seq2Seq-for-Object-Detection"><a href="#Seq2Seq-for-Object-Detection" class="headerlink" title="Seq2Seq for Object Detection"></a>Seq2Seq for Object Detection</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071527752.png" alt="image-20220307152749508"></p>
<h2 id="Seq2seq"><a href="#Seq2seq" class="headerlink" title="Seq2seq"></a>Seq2seq</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071529867.png" alt="image-20220307152903671"></p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071530886.png" alt="image-20220307153008711"></p>
<p>先讲个其他的，再回来进行比对</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071531592.png" alt="image-20220307153109367"></p>
<p>Block原来更加复杂：</p>
<p>batch normalization:对不同example 不同feature同一dimension 计算mean 和 standard deviation，在这里没有用到，用到的是layer normalization,他是对不同统一example 同一feature的不同dimension计算mean 和standard deviation.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071540252.png" alt="image-20220307154059043"></p>
<p>最后回到encoder的结构，其实是一样的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071542817.png" alt="image-20220307154250587"></p>
<h2 id="To-learn-more-2"><a href="#To-learn-more-2" class="headerlink" title="To learn more"></a>To learn more</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071543029.png" alt="image-20220307154339897"></p>
<h1 id="Transformer-下-Decoder"><a href="#Transformer-下-Decoder" class="headerlink" title="Transformer (下) Decoder"></a>Transformer (下) Decoder</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071545979.png" alt="image-20220307154510783"></p>
<h2 id="Autoregressive-Speech-Recognition-as-example-AT"><a href="#Autoregressive-Speech-Recognition-as-example-AT" class="headerlink" title="Autoregressive(Speech Recognition as example)(AT)"></a>Autoregressive(Speech Recognition as example)(AT)</h2><p>一步错步步错</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071602817.png" alt="image-20220307160214593"></p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071602020.png" alt="image-20220307160257798"></p>
<p>除了篮框这部分其他的和encoder很像，除了multi-attention 加了mask</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071604306.png" alt="image-20220307160410167"></p>
<h3 id="Masked-multi-head-attention"><a href="#Masked-multi-head-attention" class="headerlink" title="Masked multi-head attention"></a>Masked multi-head attention</h3><p>在计算b2时没办法把考虑a3，a4，因为还没生成出来，模型是从左至右计算的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071607166.png" alt="image-20220307160750850"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071608463.png" alt="image-20220307160804347"></p>
<h3 id="Stop-Token-We-don’t-know-the-correct-output-length"><a href="#Stop-Token-We-don’t-know-the-correct-output-length" class="headerlink" title="Stop Token: We don’t know the correct output length"></a>Stop Token: We don’t know the correct output length</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071614100.png" alt="image-20220307161457882"></p>
<h2 id="Non-autoregressive-NAT"><a href="#Non-autoregressive-NAT" class="headerlink" title="Non-autoregressive(NAT)"></a>Non-autoregressive(NAT)</h2><p>优势在于平行输出，所以时间会变快。而且可以控制输出长度。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071621756.png" alt="image-20220307162150521"></p>
<h3 id="To-learn-more-about-nat"><a href="#To-learn-more-about-nat" class="headerlink" title="To learn more about nat"></a>To learn more about nat</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071622824.png" alt="image-20220307162208729"></p>
<h2 id="Encode-Decoder"><a href="#Encode-Decoder" class="headerlink" title="Encode-Decoder"></a>Encode-Decoder</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071623270.png" alt="image-20220307162308131"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071627857.png" alt="image-20220307162714666"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071629321.png" alt="image-20220307162926098"></p>
<h3 id="Cross-Attention"><a href="#Cross-Attention" class="headerlink" title="Cross Attention"></a>Cross Attention</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071634484.png" alt="image-20220307163404206"></p>
<h3 id="train"><a href="#train" class="headerlink" title="train"></a>train</h3><p>使用已经有结果的数据</p>
<p>给正确答案，希望输出越接近越好</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071643365.png" alt="image-20220307164309157"></p>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071729215.png" alt="image-20220307172946935"></p>
<h2 id="tips-about-train-seq2seq"><a href="#tips-about-train-seq2seq" class="headerlink" title="tips about train seq2seq"></a>tips about train seq2seq</h2><h3 id="Copy-Mechanism"><a href="#Copy-Mechanism" class="headerlink" title="Copy Mechanism"></a>Copy Mechanism</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071732280.png" alt="image-20220307173231148"></p>
<h4 id="To-learn-more-3"><a href="#To-learn-more-3" class="headerlink" title="To learn more"></a>To learn more</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071734723.png" alt="image-20220307173455607"></p>
<h3 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071733236.png" alt="image-20220307173304080"></p>
<h3 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h3><p>强迫attention有一定固定的行为，比如语音识别必须由左向右</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071743328.png" alt="image-20220307174338215"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071745616.png" alt="image-20220307174550435"></p>
<h2 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h2><p>尝试多种可能性</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071754641.png" alt="image-20220307175417463"></p>
<p>有争议，很多人说很烂</p>
<p>因为有可能说重复的话，但是加入一点杂音反而会好很多，说明分数最高的路不一定就是最好的答案。</p>
<p>有明确答案的任务效果更好，需要发散思路的问题可能更需要加入杂音。</p>
<p>另外，tts需要加入杂音才能更好的产生结果</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101537685.png" alt="image-20220310153700434"></p>
<h2 id="Optimizing-Evaluation-Metrics"><a href="#Optimizing-Evaluation-Metrics" class="headerlink" title="Optimizing Evaluation Metrics?"></a>Optimizing Evaluation Metrics?</h2><p>训练用Cross entry评价用BLEU score.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101540023.png" alt="image-20220310154040833"></p>
<h2 id="训练和测试不一致（Exposure-bias）"><a href="#训练和测试不一致（Exposure-bias）" class="headerlink" title="训练和测试不一致（Exposure bias）"></a>训练和测试不一致（Exposure bias）</h2><p>训练永远看到的是正确的东西,测试会有错的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101546322.png" alt="image-20220310154657069"></p>
<h3 id="Scheduled-Sampling"><a href="#Scheduled-Sampling" class="headerlink" title="Scheduled Sampling"></a>Scheduled Sampling</h3><p>训练时给点错误的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101547120.png" alt="image-20220310154734903"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-一-–-基本概念介紹"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-一-–-基本概念介紹" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (一) – 基本概念介紹"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (一) – 基本概念介紹</h1><h2 id="Network-as-Generator"><a href="#Network-as-Generator" class="headerlink" title="Network as Generator"></a>Network as Generator</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101610056.png" alt="image-20220310161015930"></p>
<p>两个结合输出一个新的分布。</p>
<h2 id="为什么要输出一个分布？"><a href="#为什么要输出一个分布？" class="headerlink" title="为什么要输出一个分布？"></a>为什么要输出一个分布？</h2><p>由于问题的发散产生了分支（过于发散），这时往往会需要输出一个分支</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101614894.png" alt="image-20220310161428703"></p>
<p>训练中可能会出现同时向左向右转的现象</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101616626.png" alt="image-20220310161619452"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101619793.png" alt="image-20220310161925614"></p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><h3 id="Anime-Face-Generation"><a href="#Anime-Face-Generation" class="headerlink" title="Anime Face Generation"></a>Anime Face Generation</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101623774.png" alt="image-20220310162322633"></p>
<h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101625320.png" alt="image-20220310162507160"></p>
<h3 id="Basic-Idea-of-GAN"><a href="#Basic-Idea-of-GAN" class="headerlink" title="Basic Idea of GAN"></a>Basic Idea of GAN</h3><p>两相竞争</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101630765.png" alt="image-20220310163007559"></p>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>discriminator不断的将生成的和实际的图片分类出来，generator为了不被分辨出来儿不断进步</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101633177.png" alt="image-20220310163311970"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101637180.png" alt="image-20220310163731041"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101639482.png" alt="image-20220310163904307"></p>
<h2 id="Progressive-GAN"><a href="#Progressive-GAN" class="headerlink" title="Progressive GAN"></a>Progressive GAN</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101644579.png" alt="image-20220310164410293"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-二-–-理論介紹與WGAN"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-二-–-理論介紹與WGAN" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (二) – 理論介紹與WGAN"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (二) – 理論介紹與WGAN</h1><h2 id="Our-Objective"><a href="#Our-Objective" class="headerlink" title="Our Objective"></a>Our Objective</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111401553.png" alt="image-20220311140158414"></p>
<p><strong>But it is too hard to compute the divergence</strong></p>
<h2 id="How-to-solve-the-problem-of-divergency-sample-and-discriminator"><a href="#How-to-solve-the-problem-of-divergency-sample-and-discriminator" class="headerlink" title="How to solve the problem of divergency(sample and discriminator)"></a>How to solve the problem of divergency(sample and discriminator)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111407430.png" alt="image-20220311140722260"></p>
<h3 id="Discriminator-1"><a href="#Discriminator-1" class="headerlink" title="Discriminator"></a>Discriminator</h3><p>D<sup>*</sup> 与divergence 相关</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111414252.png" alt="image-20220311141404996"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111417233.png" alt="image-20220311141710097"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111419204.png" alt="image-20220311141916086"></p>
<h2 id="can-we-use-other-divergence"><a href="#can-we-use-other-divergence" class="headerlink" title="can we use other divergence?"></a>can we use other divergence?</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111420998.png" alt="image-20220311142056838"></p>
<h2 id="Tips-of-gan"><a href="#Tips-of-gan" class="headerlink" title="Tips of gan"></a>Tips of gan</h2><h3 id="JS-divergence-is-not-suitable"><a href="#JS-divergence-is-not-suitable" class="headerlink" title="JS divergence is not suitable"></a>JS divergence is not suitable</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111427871.png" alt="image-20220311142740738"></p>
<p>如果取样太少的话，命名generator已经取得了进步但是无法在discriminator 体现不出来</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111428345.png" alt="image-20220311142826197"></p>
<p>只要没有相交js divergence就为log2，但是有可能已经进步了，只不过没有达到那个程度。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111434806.png" alt="image-20220311143400651"></p>
<h2 id="Wasserstein-distance"><a href="#Wasserstein-distance" class="headerlink" title="Wasserstein distance"></a>Wasserstein distance</h2><p>让一个分布与另一个分布重合所用的精力</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111439317.png" alt="image-20220311143947176"></p>
<p>但是当分布复杂时，想让它们重合有不同的moving plan,所以需要穷举。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111442061.png" alt="image-20220311144159911"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111445703.png" alt="image-20220311144501598"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111447842.png" alt="image-20220311144703645"></p>
<h2 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111454545.png" alt="image-20220311145434422"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111459051.png" alt="image-20220311145930884"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-三-–-生成器效能評估與條件式生成"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-三-–-生成器效能評估與條件式生成" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (三) – 生成器效能評估與條件式生成"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (三) – 生成器效能評估與條件式生成</h1><h2 id="GAN-is-still-challenging"><a href="#GAN-is-still-challenging" class="headerlink" title="GAN is still challenging"></a>GAN is still challenging</h2><p>如果一方停下了，没办法再前进的话，另一方也会停下。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111503152.png" alt="image-20220311150342006"></p>
<h2 id="GAN-for-Sequence-Generation"><a href="#GAN-for-Sequence-Generation" class="headerlink" title="GAN for Sequence Generation"></a>GAN for Sequence Generation</h2><p>如果有多个输出且去max的话，那么其他输出的参数因参数的变化而增长是无法体现出来的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111511598.png" alt="image-20220311151119409"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111512967.png" alt="image-20220311151243838"></p>
<h3 id="For-more"><a href="#For-more" class="headerlink" title="For more"></a>For more</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111514047.png" alt="image-20220311151415941"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111514548.png" alt="image-20220311151423436"></p>
<h2 id="为什么用GAN"><a href="#为什么用GAN" class="headerlink" title="为什么用GAN"></a>为什么用GAN</h2><p>因为GAN目前效果比VAE FLOW好。。。即使是它比较难train也比其他的方法也不会难太多</p>
<h2 id="Possible-Solution"><a href="#Possible-Solution" class="headerlink" title="Possible Solution"></a>Possible Solution</h2><p>Train一个输入向量，输出图片的模型</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111518742.png" alt="image-20220311151853551"></p>
<h2 id="Quality-of-Image"><a href="#Quality-of-Image" class="headerlink" title="Quality of Image"></a>Quality of Image</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111520886.png" alt="image-20220311152042659"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111522292.png" alt="image-20220311152253198"></p>
<h2 id="Diversity-Mode-Collapse"><a href="#Diversity-Mode-Collapse" class="headerlink" title="Diversity - Mode Collapse"></a>Diversity - Mode Collapse</h2><p>Discriminator万一有弱点被generator抓到的话。。。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111524890.png" alt="image-20220311152459572"></p>
<h2 id="Diversity-Mode-Dropping"><a href="#Diversity-Mode-Dropping" class="headerlink" title="Diversity - Mode Dropping"></a>Diversity - Mode Dropping</h2><p>看似分布和质量都合理，但是其实真实数据比这更大</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111527252.png" alt="image-20220311152716994"></p>
<p>用分类器分类的结果如果过去集中则可能是这个问题</p>
<p>如果够平均则可能没有这个问题。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111529302.png" alt="image-20220311152928194"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111529694.png" alt="image-20220311152935580"></p>
<h2 id="Frechet-inception-Distance-FID-插眼"><a href="#Frechet-inception-Distance-FID-插眼" class="headerlink" title="Frechet inception Distance(FID)(插眼)"></a>Frechet inception Distance(FID)(插眼)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111538202.png" alt="image-20220311153848062"></p>
<h2 id="We-don’t-want-memory-GAN"><a href="#We-don’t-want-memory-GAN" class="headerlink" title="We don’t want memory GAN"></a>We don’t want memory GAN</h2><p>产生的跟训练资料的一模一样是不行的</p>
<h2 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h2><h3 id="Text-to-image"><a href="#Text-to-image" class="headerlink" title="Text to image"></a>Text to image</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111546613.png" alt="image-20220311154649317"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111549517.png" alt="image-20220311154918368"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111551107.png" alt="image-20220311155116997"></p>
<h2 id="Application-1"><a href="#Application-1" class="headerlink" title="Application"></a>Application</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111555415.png" alt="image-20220311155544191"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111556838.png" alt="image-20220311155633673"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111558823.png" alt="image-20220311155821568"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-四-–-Cycle-GAN"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-四-–-Cycle-GAN" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (四) – Cycle GAN"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (四) – Cycle GAN</h1><h2 id="Learning-from-Unpaired-Data（无监督）"><a href="#Learning-from-Unpaired-Data（无监督）" class="headerlink" title="Learning from Unpaired Data（无监督）"></a>Learning from Unpaired Data（无监督）</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111609272.png" alt="image-20220311160950161"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111612339.png" alt="image-20220311161251161"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111613065.png" alt="image-20220311161332878"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111615863.png" alt="image-20220311161525671"></p>
<p>没有成对的资料来训练</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111617412.png" alt="image-20220311161726234"></p>
<p>由于有了还原，产生的图片就不能和输入差太多（保证有一些关系（即使很奇怪（暂时还没啥好解法）））</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111619453.png" alt="image-20220311161900285"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111624332.png" alt="image-20220311162411169"></p>
<h2 id="more"><a href="#more" class="headerlink" title="more"></a>more</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111624254.png" alt="image-20220311162435070"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111625776.png" alt="image-20220311162524575"></p>
<h2 id="SELFIE2ANIME"><a href="#SELFIE2ANIME" class="headerlink" title="SELFIE2ANIME"></a>SELFIE2ANIME</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111626226.png" alt="image-20220311162646942"></p>
<h2 id="Text-Style-Transfer"><a href="#Text-Style-Transfer" class="headerlink" title="Text Style Transfer"></a>Text Style Transfer</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111629172.png" alt="image-20220311162931032"></p>
<p>Other</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111631772.png" alt="image-20220311163122634"></p>
<h1 id="自督導式學習-Self-supervised-Learning-一-–-芝麻街與進擊的巨人"><a href="#自督導式學習-Self-supervised-Learning-一-–-芝麻街與進擊的巨人" class="headerlink" title="自督導式學習 (Self-supervised Learning) (一) – 芝麻街與進擊的巨人"></a>自督導式學習 (Self-supervised Learning) (一) – 芝麻街與進擊的巨人</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111636506.png" alt="image-20220311163636334"></p>
<h1 id="自督導式學習-Self-supervised-Learning-二-–-BERT簡介"><a href="#自督導式學習-Self-supervised-Learning-二-–-BERT簡介" class="headerlink" title="自督導式學習 (Self-supervised Learning) (二) – BERT簡介"></a>自督導式學習 (Self-supervised Learning) (二) – BERT簡介</h1><h2 id="Self-supervised-Learning"><a href="#Self-supervised-Learning" class="headerlink" title="Self-supervised Learning"></a>Self-supervised Learning</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111653796.png" alt="image-20220311165359636"></p>
<h2 id="Masking-Input"><a href="#Masking-Input" class="headerlink" title="Masking Input"></a>Masking Input</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111700481.png" alt="image-20220311170046338"></p>
<h2 id="Next-Sentence-Prediction"><a href="#Next-Sentence-Prediction" class="headerlink" title="Next Sentence Prediction"></a>Next Sentence Prediction</h2><p>分辨两个句子是不是该接在一起</p>
<p>被认为不是很有用，model没有学到很多东西</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111706915.png" alt="image-20220311170618799"></p>
<h2 id="Downstream-Tasks-将前面的训练结果用在其他训练上"><a href="#Downstream-Tasks-将前面的训练结果用在其他训练上" class="headerlink" title="Downstream Tasks 将前面的训练结果用在其他训练上"></a>Downstream Tasks 将前面的训练结果用在其他训练上</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111709607.png" alt="image-20220311170912465"></p>
<h2 id="GLUE"><a href="#GLUE" class="headerlink" title="GLUE"></a>GLUE</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111710742.png" alt="image-20220311171023561"></p>
<h2 id="How-to-use-BERT"><a href="#How-to-use-BERT" class="headerlink" title="How to use BERT"></a>How to use BERT</h2><h3 id="Case-1-input-asq-output-class"><a href="#Case-1-input-asq-output-class" class="headerlink" title="Case 1 input asq output class"></a>Case 1 input asq output class</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111717475.png" alt="image-20220311171722364"></p>
<h3 id="Case-2-input-seq-output-same-as-seq"><a href="#Case-2-input-seq-output-same-as-seq" class="headerlink" title="Case 2 input seq output same as seq"></a>Case 2 input seq output same as seq</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111722660.png" alt="image-20220311172214528"></p>
<h3 id="Case-3-input-two-seq-output-class"><a href="#Case-3-input-two-seq-output-class" class="headerlink" title="Case 3 input two seq output class"></a>Case 3 input two seq output class</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111725901.png" alt="image-20220311172540773"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111725457.png" alt="image-20220311172558350"></p>
<h3 id="Case-4-input-document-and-query-output-answer"><a href="#Case-4-input-document-and-query-output-answer" class="headerlink" title="Case 4 input document and query output  answer"></a>Case 4 input document and query output  answer</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111728498.png" alt="image-20220311172832343"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111732272.png" alt="image-20220311173255130"></p>
<h2 id="Training-BERT-is-challenging"><a href="#Training-BERT-is-challenging" class="headerlink" title="Training BERT is challenging"></a>Training BERT is challenging</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111738014.png" alt="image-20220311173804867"></p>
<h2 id="BERT-Embryology-胚胎学"><a href="#BERT-Embryology-胚胎学" class="headerlink" title="BERT Embryology(胚胎学)"></a>BERT Embryology(胚胎学)</h2><p>了解BERT学习到知识的细节</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111739932.png" alt="image-20220311173936718"></p>
<h2 id="Pre-training-a-seq2seq-model"><a href="#Pre-training-a-seq2seq-model" class="headerlink" title="Pre-training a seq2seq model"></a>Pre-training a seq2seq model</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111740402.png" alt="image-20220311174051298"></p>
<p>输入encoder弄坏的数据，decoder输出没坏的数据</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111741904.png" alt="image-20220311174144788"></p>
<h1 id="自督導式學習-Self-supervised-Learning-三-–-BERT的奇聞軼事"><a href="#自督導式學習-Self-supervised-Learning-三-–-BERT的奇聞軼事" class="headerlink" title="自督導式學習 (Self-supervised Learning) (三) – BERT的奇聞軼事"></a>自督導式學習 (Self-supervised Learning) (三) – BERT的奇聞軼事</h1><h2 id="Why-does-BERT-work"><a href="#Why-does-BERT-work" class="headerlink" title="Why does BERT work"></a>Why does BERT work</h2><p>同一个字有不同的意义</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141054271.png" alt="image-20220314105449128"></p>
<p>一个词汇的意思取决于它的上下文</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141103522.png" alt="image-20220314110345369"></p>
<h2 id="Applying-BERT-to-protein-DNA-music-classification"><a href="#Applying-BERT-to-protein-DNA-music-classification" class="headerlink" title="Applying BERT to protein,DNA,music classification"></a>Applying BERT to protein,DNA,music classification</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141115093.png" alt="image-20220314111554974"> </p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141116489.png" alt="image-20220314111616272"></p>
<h2 id="Multi-lingual-BERT"><a href="#Multi-lingual-BERT" class="headerlink" title="Multi-lingual BERT"></a>Multi-lingual BERT</h2><p>训练在英文反而在中文的test上取得了进步</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141119777.png" alt="image-20220314111954632"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141120398.png" alt="image-20220314112004247"></p>
<h3 id="Cross-lingual-Alignment-一种解释"><a href="#Cross-lingual-Alignment-一种解释" class="headerlink" title="Cross-lingual Alignment(一种解释)"></a>Cross-lingual Alignment(一种解释)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141122448.png" alt="image-20220314112242298"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141127924.png" alt="image-20220314112701789"></p>
<p>似乎不同语言向量的差异就是语言的信息？</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141128385.png" alt="image-20220314112843223"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141130116.png" alt="image-20220314113023958"></p>
<h1 id="自督導式學習-Self-supervised-Learning-四-–-GPT的野望"><a href="#自督導式學習-Self-supervised-Learning-四-–-GPT的野望" class="headerlink" title="自督導式學習 (Self-supervised Learning) (四) – GPT的野望"></a>自督導式學習 (Self-supervised Learning) (四) – GPT的野望</h1><p>如下，只不过是数据量特别大</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141135977.png" alt="image-20220314113548845"></p>
<h2 id="How-to-use-GPT"><a href="#How-to-use-GPT" class="headerlink" title="How to use GPT"></a>How to use GPT</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141142869.png" alt="image-20220314114228746"></p>
<h2 id="Few-shot-learning-no-gradient-descent-“In-context”-Learning"><a href="#Few-shot-learning-no-gradient-descent-“In-context”-Learning" class="headerlink" title="Few-shot learning (no gradient descent) “In-context” Learning"></a>Few-shot learning (no gradient descent) “In-context” Learning</h2><p>只用很少的资料去训练。效果见仁见智</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141144552.png" alt="image-20220314114438407"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141145793.png" alt="image-20220314114526420"></p>
<h2 id="Beyond-Text"><a href="#Beyond-Text" class="headerlink" title="Beyond  Text"></a>Beyond  Text</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141147297.png" alt="image-20220314114700178"></p>
<h3 id="Image-1"><a href="#Image-1" class="headerlink" title="Image"></a>Image</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141148087.png" alt="image-20220314114801920"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141148727.png" alt="image-20220314114841612"></p>
<h3 id="Speech-1"><a href="#Speech-1" class="headerlink" title="Speech"></a>Speech</h3><p>语音方面暂时没有公认的像GLUE的资料库</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141149764.png" alt="image-20220314114939626"></p>
<p>他自己做了一个</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141150897.png" alt="image-20220314115057788"></p>
<h2 id="Application-of-self-supervised"><a href="#Application-of-self-supervised" class="headerlink" title="Application of self supervised"></a>Application of self supervised</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141153415.png" alt="image-20220314115333201"></p>
<h1 id="自編碼器-Auto-encoder-上-–-基本概念"><a href="#自編碼器-Auto-encoder-上-–-基本概念" class="headerlink" title="自編碼器 (Auto-encoder) (上) – 基本概念"></a>自編碼器 (Auto-encoder) (上) – 基本概念</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141342822.png" alt="image-20220314134255650"></p>
<h2 id="review-of-self-supervised-learning-frame-work"><a href="#review-of-self-supervised-learning-frame-work" class="headerlink" title="review of self-supervised learning frame work"></a>review of self-supervised learning frame work</h2><p>学习没有标注资料的任务，在有bert gpt之前，就有了auto-encoder。</p>
<h2 id="auto-encoder-in-image"><a href="#auto-encoder-in-image" class="headerlink" title="auto-encoder in image"></a>auto-encoder in image</h2><h3 id="Dimension-reduction"><a href="#Dimension-reduction" class="headerlink" title="Dimension reduction"></a>Dimension reduction</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141347670.png" alt="image-20220314134751495"></p>
<h3 id="for-more"><a href="#for-more" class="headerlink" title="for more"></a>for more</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141348069.png" alt="image-20220314134822953"></p>
<h2 id="Why-auto-encoder"><a href="#Why-auto-encoder" class="headerlink" title="Why auto-encoder?"></a>Why auto-encoder?</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141355167.png" alt="image-20220314135524915"></p>
<p>并不是3*3的向量都是图片，其形式是有限的，所以可以用更小的维度表示3*3的图片。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141354951.png" alt="image-20220314135442811"></p>
<h2 id="Auto-encoder-is-not-a-new-idea"><a href="#Auto-encoder-is-not-a-new-idea" class="headerlink" title="Auto-encoder is not a new idea"></a>Auto-encoder is not a new idea</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141356898.png" alt="image-20220314135619740"></p>
<h2 id="De-noising-Auto-encoder"><a href="#De-noising-Auto-encoder" class="headerlink" title="De-noising Auto-encoder"></a>De-noising Auto-encoder</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141400008.png" alt="image-20220314140040870"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141403569.png" alt="image-20220314140324449"></p>
<h1 id="自編碼器-Auto-encoder-下-–-領結變聲器與更多應用"><a href="#自編碼器-Auto-encoder-下-–-領結變聲器與更多應用" class="headerlink" title="自編碼器 (Auto-encoder) (下) – 領結變聲器與更多應用"></a>自編碼器 (Auto-encoder) (下) – 領結變聲器與更多應用</h1><h2 id="Feature-Disentangle"><a href="#Feature-Disentangle" class="headerlink" title="Feature Disentangle"></a>Feature Disentangle</h2><p>分解中间向量，理解其信息</p>
<h3 id="Representation-includes-information-of-different-aspects"><a href="#Representation-includes-information-of-different-aspects" class="headerlink" title="Representation includes information of different aspects"></a>Representation includes information of different aspects</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141405093.png" alt="image-20220314140525936"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141406091.png" alt="image-20220314140612916"></p>
<h2 id="Application-voice-conversion"><a href="#Application-voice-conversion" class="headerlink" title="Application: voice conversion"></a>Application: voice conversion</h2><p>不需要资料库中两个人说一样的话。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141410469.png" alt="image-20220314141012317"></p>
<h2 id="discrete-representation"><a href="#discrete-representation" class="headerlink" title="discrete representation"></a>discrete representation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141414058.png" alt="image-20220314141405868"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141417025.png" alt="image-20220314141736842"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141418141.png" alt="image-20220314141833087"></p>
<p>固定输出的可能性，不是无限的而是离散的</p>
<h2 id="Text-as-representation"><a href="#Text-as-representation" class="headerlink" title="Text as representation"></a>Text as representation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141421620.png" alt="image-20220314142133471"></p>
<p>强迫encoder train出人话一样的中间向量。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141423309.png" alt="image-20220314142307092"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141424328.png" alt="image-20220314142410154"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141424637.png" alt="image-20220314142442444"></p>
<h2 id="Tree-as-Embedding"><a href="#Tree-as-Embedding" class="headerlink" title="Tree as Embedding"></a>Tree as Embedding</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141425516.png" alt="image-20220314142514373"></p>
<h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141426358.png" alt="image-20220314142624201"></p>
<h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141427873.png" alt="image-20220314142742720"></p>
<h2 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141429280.png" alt="image-20220314142932175"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141430974.png" alt="image-20220314143015788"></p>
<p>用来探测异常交易，异常请求，异常病情等</p>
<p>和分类器还是有区别的，因为训练资料大多数只有一类</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141433311.png" alt="image-20220314143326176"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141434235.png" alt="image-20220314143418074"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141434870.png" alt="image-20220314143443674"></p>
<h2 id="For-More"><a href="#For-More" class="headerlink" title="For More"></a>For More</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141435726.png" alt="image-20220314143556606"></p>
<h1 id="來自人類的惡意攻擊-Adversarial-Attack-上-–-基本概念"><a href="#來自人類的惡意攻擊-Adversarial-Attack-上-–-基本概念" class="headerlink" title="來自人類的惡意攻擊 (Adversarial Attack) (上) – 基本概念"></a>來自人類的惡意攻擊 (Adversarial Attack) (上) – 基本概念</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>需要在有人试图欺骗他的情况下正常工作</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141438923.png" alt="image-20220314143801762"></p>
<h2 id="How-to-arrack"><a href="#How-to-arrack" class="headerlink" title="How to arrack"></a>How to arrack</h2><h3 id="Example-of-attack"><a href="#Example-of-attack" class="headerlink" title="Example of attack"></a>Example of attack</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141441623.png" alt="image-20220314144113467"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141443616.png" alt="image-20220314144315367"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141443785.png" alt="image-20220314144325514"></p>
<p>正常的错误应该是这样的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141445644.png" alt="image-20220314144533270"></p>
<h3 id="含恶意的噪音"><a href="#含恶意的噪音" class="headerlink" title="含恶意的噪音"></a>含恶意的噪音</h3><p>尽量让正确的目标概率变小，让目标概率变大，同时尽量让差距小于人类能感知的差异的最小值</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141510206.png" alt="image-20220314151015068"></p>
<h3 id="Non-perceivable"><a href="#Non-perceivable" class="headerlink" title="Non-perceivable"></a>Non-perceivable</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141514554.png" alt="image-20220314151407433"></p>
<h2 id="Attack-Approach"><a href="#Attack-Approach" class="headerlink" title="Attack Approach"></a>Attack Approach</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141525745.png" alt="image-20220314152519619"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141529038.png" alt="image-20220314152905906"></p>
<h1 id="來自人類的惡意攻擊-Adversarial-Attack-下-–-類神經網路能否躲過人類深不見底的惡意？"><a href="#來自人類的惡意攻擊-Adversarial-Attack-下-–-類神經網路能否躲過人類深不見底的惡意？" class="headerlink" title="來自人類的惡意攻擊 (Adversarial Attack) (下) – 類神經網路能否躲過人類深不見底的惡意？"></a>來自人類的惡意攻擊 (Adversarial Attack) (下) – 類神經網路能否躲過人類深不見底的惡意？</h1><h2 id="White-Box-vs-Black-Box"><a href="#White-Box-vs-Black-Box" class="headerlink" title="White Box vs Black Box"></a>White Box vs Black Box</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141532903.png" alt="image-20220314153222740"></p>
<h2 id="Black-Box"><a href="#Black-Box" class="headerlink" title="Black Box"></a>Black Box</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141534392.png" alt="image-20220314153412201"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141540185.png" alt="image-20220314154050031"></p>
<p>不同的数据产生的结果截然不同</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141545777.png" alt="image-20220314154500629"></p>
<h2 id="One-pixel-attack"><a href="#One-pixel-attack" class="headerlink" title="One pixel attack"></a>One pixel attack</h2><p>只改变一点导致结果改变</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141548038.png" alt="image-20220314154808782"></p>
<h2 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141548715.png" alt="image-20220314154841529"></p>
<h2 id="Beyond-Images"><a href="#Beyond-Images" class="headerlink" title="Beyond Images"></a>Beyond Images</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141552567.png" alt="image-20220314155241385"></p>
<h2 id="Attack-in-the-Physical-World"><a href="#Attack-in-the-Physical-World" class="headerlink" title="Attack in the Physical World"></a>Attack in the Physical World</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141556837.png" alt="image-20220314155630581"></p>
<h2 id="Backdoor-in-Model"><a href="#Backdoor-in-Model" class="headerlink" title="Backdoor in Model"></a>Backdoor in Model</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141604162.png" alt="image-20220314160459014"></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>模糊化，让攻击信号被改变</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141609473.png" alt="image-20220314160922185"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141609675.png" alt="image-20220314160910483"></p>
<p>但是如果被知道了使用了这种方法，攻击时也可以加上这个，所以可以加上随机性</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141612937.png" alt="image-20220314161213775"></p>
<h2 id="Proactive-Defense"><a href="#Proactive-Defense" class="headerlink" title="Proactive Defense"></a>Proactive Defense</h2><p>自己攻击自己然后把攻击数据学习进去</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141618546.png" alt="image-20220314161820428"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141621045.png" alt="image-20220314162136755"></p>
<h1 id="機器學習模型的可解釋性-Explainable-ML-上-–-為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？"><a href="#機器學習模型的可解釋性-Explainable-ML-上-–-為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？" class="headerlink" title="機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？"></a>機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？</h1><h2 id="Why-we-need-Explainable-ML"><a href="#Why-we-need-Explainable-ML" class="headerlink" title="Why we need Explainable ML?"></a>Why we need Explainable ML?</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141628250.png" alt="image-20220314162821135"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141628765.png" alt="image-20220314162835563"></p>
<h2 id="Interpretable-vs-powerful"><a href="#Interpretable-vs-powerful" class="headerlink" title="Interpretable vs powerful"></a>Interpretable vs powerful</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141630592.png" alt="image-20220314163028426"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141631242.png" alt="image-20220314163111887"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141633544.png" alt="image-20220314163334420"></p>
<h2 id="Goal-of-Explainable-ML"><a href="#Goal-of-Explainable-ML" class="headerlink" title="Goal of Explainable ML"></a>Goal of Explainable ML</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141639423.png" alt="image-20220314163927285"></p>
<p>人们只是需要一个理由去接受 - .- </p>
<h2 id="Explainable-ML"><a href="#Explainable-ML" class="headerlink" title="Explainable ML"></a>Explainable ML</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141641803.png" alt="image-20220314164155673"></p>
<h3 id="Local-Exception"><a href="#Local-Exception" class="headerlink" title="Local Exception"></a>Local Exception</h3><p>改造或删除某部分导致结论错误，那么它就是原因</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141644885.png" alt="image-20220314164414637"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141646771.png" alt="image-20220314164642441"></p>
<p>更改向量的值，计算偏导数，得出是哪个参数更重要</p>
<p>Saliency Map</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141649365.png" alt="image-20220314164936108"></p>
<h3 id="A-test"><a href="#A-test" class="headerlink" title="A test"></a>A test</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141652938.png" alt="image-20220314165245766"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141652541.png" alt="image-20220314165232008"></p>
<p>结果是由于数据错误，，，背景问题</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141654709.png" alt="image-20220314165405405"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141654791.png" alt="image-20220314165415412"></p>
<p>因为介绍文字而判断图片</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141655165.png" alt="image-20220314165519831"></p>
<h3 id="SmoothGrad"><a href="#SmoothGrad" class="headerlink" title="SmoothGrad"></a>SmoothGrad</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141656110.png" alt="image-20220314165641944"></p>
<h3 id="Gradient-Saturation"><a href="#Gradient-Saturation" class="headerlink" title="Gradient Saturation"></a>Gradient Saturation</h3><p>如果在平滑处取导数的话会得出鼻子长度与判读大象无关的结论</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141658849.png" alt="image-20220314165857732"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141659780.png" alt="image-20220314165946718"></p>
<h2 id="How-a-net-work-process-the-input-data"><a href="#How-a-net-work-process-the-input-data" class="headerlink" title="How a net work process the input data"></a>How a net work process the input data</h2><h3 id="为了观察过程压缩中间向量的维度"><a href="#为了观察过程压缩中间向量的维度" class="headerlink" title="为了观察过程压缩中间向量的维度"></a>为了观察过程压缩中间向量的维度</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141701305.png" alt="image-20220314170144183"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141705435.png" alt="image-20220314170511238"></p>
<h3 id="很多问题尚待研究。。"><a href="#很多问题尚待研究。。" class="headerlink" title="很多问题尚待研究。。"></a>很多问题尚待研究。。</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141706839.png" alt="image-20220314170659716"></p>
<h3 id="用探针处理中间向量"><a href="#用探针处理中间向量" class="headerlink" title="用探针处理中间向量"></a>用探针处理中间向量</h3><p>但注意Classifier的正确情况</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141708280.png" alt="image-20220314170851046"></p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141712792.png" alt="image-20220314171208635"></p>
<p>在不同层加探针看语音到底在那里失去了性别信息，或者杂音。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141715485.png" alt="image-20220314171551251"></p>
<h1 id="機器學習模型的可解釋性-Explainable-ML-下-–機器心中的貓長什麼樣子？"><a href="#機器學習模型的可解釋性-Explainable-ML-下-–機器心中的貓長什麼樣子？" class="headerlink" title="機器學習模型的可解釋性 (Explainable ML) (下) –機器心中的貓長什麼樣子？"></a>機器學習模型的可解釋性 (Explainable ML) (下) –機器心中的貓長什麼樣子？</h1><h2 id="What-does-a-filter-detect-（插眼，他在说什么）"><a href="#What-does-a-filter-detect-（插眼，他在说什么）" class="headerlink" title="What does a filter detect?（插眼，他在说什么）"></a>What does a filter detect?（插眼，他在说什么）</h2><p>通过filter观察模型在观察什么</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141754322.png" alt="image-20220314175448144"></p>
<p>图示是某个filter</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141756789.png" alt="image-20220314175637568"></p>
<p>下图是被攻击了，命名看不出来是什么，机器却觉得是0123456789。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141758118.png" alt="image-20220314175821937"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141814729.png" alt="image-20220314181454529"></p>
<p>要得到如下的结果要大量的知识和处理。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141815852.png" alt="image-20220314181543310"></p>
<p>或者通过generator达到目的（插眼，他在说什么）</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141818899.png" alt="image-20220314181845733"></p>
<p>并不是在乎机器真正的注意点，而是将注意点转成人能理解的形式</p>
<h2 id="Outlook"><a href="#Outlook" class="headerlink" title="Outlook"></a>Outlook</h2><p>用简单的linear模型模拟复杂的deep learning模型，再用简单的模型理解复杂的模型</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141823945.png" alt="image-20220314182334820"></p>
<h1 id="概述領域自適應-Domain-Adaptation"><a href="#概述領域自適應-Domain-Adaptation" class="headerlink" title="概述領域自適應 (Domain Adaptation)"></a>概述領域自適應 (Domain Adaptation)</h1><h2 id="Domain-shift"><a href="#Domain-shift" class="headerlink" title="Domain shift"></a>Domain shift</h2><p>有一些改变就会犯错</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151038867.png" alt="image-20220315103810740"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151043678.png" alt="image-20220315104344563"></p>
<p>需要考虑两种情况</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151046869.png" alt="image-20220315104603745"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151048770.png" alt="image-20220315104805665"></p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151049494.png" alt="image-20220315104903362"></p>
<h2 id="Domain-Adversarial-Training"><a href="#Domain-Adversarial-Training" class="headerlink" title="Domain Adversarial Training"></a>Domain Adversarial Training</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151051102.png" alt="image-20220315105143945"></p>
<p>Domain Classifier用来分辨是黑白的还是彩色的，训练到它分别不出来且loss不再下降</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151111252.png" alt="image-20220315111113121"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151112339.png" alt="image-20220315111225175"></p>
<h2 id="Limitation-插眼"><a href="#Limitation-插眼" class="headerlink" title="Limitation(插眼)"></a>Limitation(插眼)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151116059.png" alt="image-20220315111608905"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151117838.png" alt="image-20220315111724707"></p>
<h2 id="Outlook-1"><a href="#Outlook-1" class="headerlink" title="Outlook"></a>Outlook</h2><p>有两者数据不完全重合的情况</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151118787.png" alt="image-20220315111818652"></p>
<h2 id="More-condition-in-domain-Adaptation"><a href="#More-condition-in-domain-Adaptation" class="headerlink" title="More condition in domain Adaptation"></a>More condition in domain Adaptation</h2><h3 id="little-unlabel"><a href="#little-unlabel" class="headerlink" title="little unlabel"></a>little unlabel</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151120389.png" alt="image-20220315112056270"></p>
<h3 id="Know-nothing"><a href="#Know-nothing" class="headerlink" title="Know nothing"></a>Know nothing</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151121979.png" alt="image-20220315112136861"></p>
<h4 id="Domain-Generation"><a href="#Domain-Generation" class="headerlink" title="Domain Generation"></a>Domain Generation</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151122277.png" alt="image-20220315112247065"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-一-–-增強式學習跟機器學習一樣都是三個步驟"><a href="#概述增強式學習-Reinforcement-Learning-RL-一-–-增強式學習跟機器學習一樣都是三個步驟" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (一) – 增強式學習跟機器學習一樣都是三個步驟"></a>概述增強式學習 (Reinforcement Learning, RL) (一) – 增強式學習跟機器學習一樣都是三個步驟</h1><h2 id="Supervised-learning-gt-RL"><a href="#Supervised-learning-gt-RL" class="headerlink" title="Supervised learning -&gt; RL"></a>Supervised learning -&gt; RL</h2><p>收集正确答案很困难的时候</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241704421.png" alt="image-20220324170448289"></p>
<h2 id="Outline-1"><a href="#Outline-1" class="headerlink" title="Outline"></a>Outline</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241704171.png" alt="image-20220324170459063"></p>
<h1 id="Mache-learning-≈-looking-for-a-function"><a href="#Mache-learning-≈-looking-for-a-function" class="headerlink" title="Mache learning ≈ looking for a function"></a>Mache learning ≈ looking for a function</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241708673.png" alt="image-20220324170828552"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241710102.png" alt="image-20220324171016982"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241712929.png" alt="image-20220324171238799"></p>
<p>在围棋中只有游戏结束时才能获得reward</p>
<h2 id="Mache-Learning-is-so-simple"><a href="#Mache-Learning-is-so-simple" class="headerlink" title="Mache Learning is so simple"></a>Mache Learning is so simple</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241716360.png" alt="image-20220324171600228"></p>
<h3 id="Step-1-Function-with-Unknown"><a href="#Step-1-Function-with-Unknown" class="headerlink" title="Step 1: Function with Unknown"></a>Step 1: Function with Unknown</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241719016.png" alt="image-20220324171952880"></p>
<h3 id="Step-2-Define-“Loss”"><a href="#Step-2-Define-“Loss”" class="headerlink" title="Step 2: Define “Loss”"></a>Step 2: Define “Loss”</h3><p>reward 是一次的 return是总和</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241724187.png" alt="image-20220324172437043"></p>
<h3 id="Step-3-Optimization"><a href="#Step-3-Optimization" class="headerlink" title="Step 3: Optimization"></a>Step 3: Optimization</h3><p>环境和reward有随机性,相比gan，env和reward它们不是神经网络，这两者的随机性是rn很重要的特性</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241731122.png" alt="image-20220324173149984"></p>
<h2 id="How-to-control-your-actor"><a href="#How-to-control-your-actor" class="headerlink" title="How to control your actor"></a>How to control your actor</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241747874.png" alt="image-20220324174707771"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241748455.png" alt="image-20220324174814337"></p>
<p>这其中还可以区分程度</p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-二-–-Policy-Gradient-與修課心情"><a href="#概述增強式學習-Reinforcement-Learning-RL-二-–-Policy-Gradient-與修課心情" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (二) – Policy Gradient 與修課心情"></a>概述增強式學習 (Reinforcement Learning, RL) (二) – Policy Gradient 與修課心情</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241832203.png" alt="image-20220324183243087"></p>
<h2 id="version0"><a href="#version0" class="headerlink" title="version0"></a>version0</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241832432.png" alt="image-20220324183257305"></p>
<p>但是这样是短视的，行动会影响后面的很多reward，还有要先失去一些分数才能获得更多的分数的情况。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241836897.png" alt="image-20220324183659769"></p>
<h2 id="version-1-Cumulated-reward"><a href="#version-1-Cumulated-reward" class="headerlink" title="version 1 Cumulated reward"></a>version 1 Cumulated reward</h2><p>缺点在于如果很长的话，第一个有可能不至于影响到最后一个</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241838997.png" alt="image-20220324183844901"></p>
<h2 id="version-2"><a href="#version-2" class="headerlink" title="version 2"></a>version 2</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241842182.png" alt="image-20220324184203073"></p>
<h2 id="version-3"><a href="#version-3" class="headerlink" title="version 3"></a>version 3</h2><p>做一下标准化，因为好和坏是相对的，有可能在这一把得10分很高了，下一把10分很低。当全是正的时，差一些的就是坏的。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241848169.png" alt="image-20220324184809057"></p>
<h2 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h2><h3 id="on-policy"><a href="#on-policy" class="headerlink" title="on-policy"></a>on-policy</h3><p>收集资料在for循环里</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241851523.png" alt="image-20220324185137430"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241852874.png" alt="image-20220324185218772"></p>
<p>原因：</p>
<p>围棋中，同样的行为对不同预判能力的玩家来说是不一样好的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241857743.png" alt="image-20220324185724629"></p>
<h3 id="off-policy"><a href="#off-policy" class="headerlink" title="off policy"></a>off policy</h3><p>用一些办法使其可以收集;上几步的资料</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241900132.png" alt="image-20220324190004012"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241901280.png" alt="image-20220324190151089"></p>
<h2 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h2><p>有些action没被执行过就不知道到底好不好，所以想让它尽可能的大一点。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241903671.png" alt="image-20220324190349538"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-四-回饋非常罕見的時候怎麼辦？機器的望梅止渴"><a href="#概述增強式學習-Reinforcement-Learning-RL-四-回饋非常罕見的時候怎麼辦？機器的望梅止渴" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (四) - 回饋非常罕見的時候怎麼辦？機器的望梅止渴"></a>概述增強式學習 (Reinforcement Learning, RL) (四) - 回饋非常罕見的時候怎麼辦？機器的望梅止渴</h1><h2 id="Sparse-Reward"><a href="#Sparse-Reward" class="headerlink" title="Sparse Reward"></a>Sparse Reward</h2><p>如果reward好多都是零只有一两个极大或其他类似情况应该怎么办？比如让机器栓螺丝</p>
<p>所以需要定义一些额外的reward 这就叫reward shaping</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251435534.png" alt="image-20220325143505402"></p>
<h2 id="Examples-of-Reward-Shaping"><a href="#Examples-of-Reward-Shaping" class="headerlink" title="Examples of Reward Shaping"></a>Examples of Reward Shaping</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251444112.png" alt="image-20220325144419946"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-五-如何從示範中學習？逆向增強式學習-Inverse-RL"><a href="#概述增強式學習-Reinforcement-Learning-RL-五-如何從示範中學習？逆向增強式學習-Inverse-RL" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (五) - 如何從示範中學習？逆向增強式學習 (Inverse RL)"></a>概述增強式學習 (Reinforcement Learning, RL) (五) - 如何從示範中學習？逆向增強式學習 (Inverse RL)</h1><p>有的时候就没有reward，</p>
<h1 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251456210.png" alt="image-20220325145629061"></p>
<h2 id="Limitation-Learning"><a href="#Limitation-Learning" class="headerlink" title="Limitation Learning"></a>Limitation Learning</h2><p>引入人类行为资料</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251501455.png" alt="image-20220325150105295"></p>
<h2 id="Isn’t-it-Supervised-Learning-？"><a href="#Isn’t-it-Supervised-Learning-？" class="headerlink" title="Isn’t it Supervised Learning ？"></a>Isn’t it Supervised Learning ？</h2><p>并不是，因为有些事是人类不会做的，但是是机器需要考虑的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251508011.png" alt="image-20220325150839883"></p>
<h2 id="More-problem"><a href="#More-problem" class="headerlink" title="More problem"></a>More problem</h2><p>可能会学一些坏习惯。。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251511665.png" alt="image-20220325151142335"></p>
<h2 id="Inverse-Reinforcement-Learning"><a href="#Inverse-Reinforcement-Learning" class="headerlink" title="Inverse Reinforcement Learning"></a>Inverse Reinforcement Learning</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251517890.png" alt="image-20220325151713780"></p>
<h2 id="Framework-of-IRL"><a href="#Framework-of-IRL" class="headerlink" title="Framework of IRL"></a>Framework of IRL</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251527503.png" alt="image-20220325152712378"></p>
<h1 id="機器終身學習-Life-Long-Learning-LL-一-為什麼今日的人工智慧無法成為天網？災難性遺忘-Catastrophic-Forgetting"><a href="#機器終身學習-Life-Long-Learning-LL-一-為什麼今日的人工智慧無法成為天網？災難性遺忘-Catastrophic-Forgetting" class="headerlink" title="機器終身學習 (Life Long Learning, LL) (一) - 為什麼今日的人工智慧無法成為天網？災難性遺忘(Catastrophic Forgetting)"></a>機器終身學習 (Life Long Learning, LL) (一) - 為什麼今日的人工智慧無法成為天網？災難性遺忘(Catastrophic Forgetting)</h1><h3 id="LLL"><a href="#LLL" class="headerlink" title="LLL"></a>LLL</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251531491.png" alt="image-20220325153108319"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251536194.png" alt="image-20220325153641075"></p>
<h2 id="模型会遗忘"><a href="#模型会遗忘" class="headerlink" title="模型会遗忘"></a>模型会遗忘</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281347107.png" alt="image-20220328134715016"></p>
<p>但其实是可以同时学到任务一任务二的。。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281347005.png" alt="image-20220328134740922"></p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281352687.png" alt="image-20220328135201610"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281356046.png" alt="image-20220328135624974"></p>
<h2 id="同时训练好多任务缺陷明显，而且一点都不像终身学习"><a href="#同时训练好多任务缺陷明显，而且一点都不像终身学习" class="headerlink" title="同时训练好多任务缺陷明显，而且一点都不像终身学习"></a>同时训练好多任务缺陷明显，而且一点都不像终身学习</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281400020.png" alt="image-20220328140029927"></p>
<h2 id="为每一个任务储存模型缺点依然明显"><a href="#为每一个任务储存模型缺点依然明显" class="headerlink" title="为每一个任务储存模型缺点依然明显"></a>为每一个任务储存模型缺点依然明显</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281403147.png" alt="image-20220328140310068"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281406944.png" alt="image-20220328140640856"></p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281408113.png" alt="image-20220328140852027"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281415267.png" alt="image-20220328141536175"></p>
<h1 id="機器終身學習-Life-Long-Learning-LL-二-災難性遺忘-Catastrophic-Forgetting-的克服之道"><a href="#機器終身學習-Life-Long-Learning-LL-二-災難性遺忘-Catastrophic-Forgetting-的克服之道" class="headerlink" title="機器終身學習 (Life Long Learning, LL) (二) - 災難性遺忘(Catastrophic Forgetting)的克服之道"></a>機器終身學習 (Life Long Learning, LL) (二) - 災難性遺忘(Catastrophic Forgetting)的克服之道</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281417826.png" alt="image-20220328141752746"></p>
<p>第一种方法是比较常见的方法</p>
<h2 id="为什么这种情况会发生？"><a href="#为什么这种情况会发生？" class="headerlink" title="为什么这种情况会发生？"></a>为什么这种情况会发生？</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281422113.png" alt="image-20220328142228026"></p>
<h2 id="Selective-Synaptic-Plasticity"><a href="#Selective-Synaptic-Plasticity" class="headerlink" title="Selective Synaptic Plasticity"></a>Selective Synaptic Plasticity</h2><p>更改损失函数确保尽量少对<strong>重要参数</strong>进行修改：</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281429623.png" alt="image-20220328142900542"></p>
<p>对于参数重要度的参数很重要，小了失去了效果，大了不容易学到新的,它是根据情况算出来的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281431771.png" alt="image-20220328143125690"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281437603.png" alt="image-20220328143717529"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281440882.png" alt="image-20220328144001796"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281447839.png" alt="image-20220328144757763"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281448073.png" alt="image-20220328144828004"></p>
<h2 id="Gradient-Episodic-Memory-GEM"><a href="#Gradient-Episodic-Memory-GEM" class="headerlink" title="Gradient Episodic Memory(GEM)"></a>Gradient Episodic Memory(GEM)</h2><p>但是这个方法需要存少量的以前的资料</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281452218.png" alt="image-20220328145254126"></p>
<h2 id="Addition-Neural-Resource-Allocation"><a href="#Addition-Neural-Resource-Allocation" class="headerlink" title="Addition Neural Resource Allocation"></a>Addition Neural Resource Allocation</h2><h3 id="Progressive-Neural-Networks"><a href="#Progressive-Neural-Networks" class="headerlink" title="Progressive Neural Networks"></a>Progressive Neural Networks</h3><p>没新加一个任务就新加一套参数</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281457758.png" alt="image-20220328145732673"></p>
<h3 id="PackNet"><a href="#PackNet" class="headerlink" title="PackNet"></a>PackNet</h3><p>提前预备出任务需要的参数位置，给后来的任务使用</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281500141.png" alt="image-20220328150025009"></p>
<h3 id="Generating-Data"><a href="#Generating-Data" class="headerlink" title="Generating Data"></a>Generating Data</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281502765.png" alt="image-20220328150202679"></p>
<h2 id="More-scenarios"><a href="#More-scenarios" class="headerlink" title="More scenarios"></a>More scenarios</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281503628.png" alt="image-20220328150332554"></p>
<h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h2><p>学习的顺序也很重要</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281506747.png" alt="image-20220328150636666"></p>
<h1 id="神經網路壓縮-Network-Compression-一-類神經網路剪枝-Pruning-與大樂透假說-Lottery-Ticket-Hypothesis"><a href="#神經網路壓縮-Network-Compression-一-類神經網路剪枝-Pruning-與大樂透假說-Lottery-Ticket-Hypothesis" class="headerlink" title="神經網路壓縮 (Network Compression) (一) - 類神經網路剪枝 (Pruning) 與大樂透假說 (Lottery Ticket Hypothesis)"></a>神經網路壓縮 (Network Compression) (一) - 類神經網路剪枝 (Pruning) 與大樂透假說 (Lottery Ticket Hypothesis)</h1><h2 id="Need-smaller-model"><a href="#Need-smaller-model" class="headerlink" title="Need smaller model"></a>Need smaller model</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281507130.png" alt="image-20220328150756022"></p>
<p>由于时间差或者隐私问题需要在小型设备上运行。</p>
<h2 id="Outline-2"><a href="#Outline-2" class="headerlink" title="Outline"></a>Outline</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281509784.png" alt="image-20220328150941718"></p>
<h2 id="Network-can-be-pruned-network-pruning"><a href="#Network-can-be-pruned-network-pruning" class="headerlink" title="Network can be pruned(network pruning)"></a>Network can be pruned(network pruning)</h2><p>有些参数是没用或者用处不大的，可以扔了</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281512018.png" alt="image-20220328151209934"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281515911.png" alt="image-20220328151539828"></p>
<p>参数太怪异不利于定义和运算，实践发现虽然weight pruning虽然压缩了weight但是由于运算不规则导致运算没有加速</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281518707.png" alt="image-20220328151807624"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281520198.png" alt="image-20220328152016113"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281521829.png" alt="image-20220328152146743"></p>
<h2 id="为什么不直接训练一个小的network"><a href="#为什么不直接训练一个小的network" class="headerlink" title="为什么不直接训练一个小的network"></a>为什么不直接训练一个小的network</h2><p>小的network很难得到大的network的效果</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281525091.png" alt="image-20220328152531993"></p>
<p>有一个猜想是大的network就像买了更多的彩票，概率更大</p>
<p>如果小network用大network的参数开始训练就可以，所以可能是那些参数就是可以成功训练的参数</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281528959.png" alt="image-20220328152853855"></p>
<p>正 负号对于训练参数很重要</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281533112.png" alt="image-20220328153355025"></p>
<p>但是这种想法就不一定是对的，这人说小模型其实也是可以直接训练出来的，只要epoch多一点</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281535374.png" alt="image-20220328153502282"></p>
<h1 id="神經網路壓縮-Network-Compression-二-從各種不同的面向來壓縮神經網路"><a href="#神經網路壓縮-Network-Compression-二-從各種不同的面向來壓縮神經網路" class="headerlink" title="神經網路壓縮 (Network Compression) (二) - 從各種不同的面向來壓縮神經網路"></a>神經網路壓縮 (Network Compression) (二) - 從各種不同的面向來壓縮神經網路</h1><h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><p>学生以老师的输出为标准答案，为什么不直接训小的？因为小的不好训（插眼）</p>
<p>因为老师可以告诉学生其实小的1还是有点像7和9的</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281543007.png" alt="image-20220328154349925"></p>
<p>老师可以是n重的network</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281544302.png" alt="image-20220328154454222"></p>
<p>需要对老师的softmax进行一定的调整，以防可能小的情况被无视</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281552196.png" alt="image-20220328155208113"></p>
<h2 id="Parameter-Quantization"><a href="#Parameter-Quantization" class="headerlink" title="Parameter Quantization"></a>Parameter Quantization</h2><p>储存一个参数可能用64bits那改小点会不会好点？</p>
<p>或者可以将参数分类，每类一个值，简化存储</p>
<p>或者用哈夫曼编码？</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281558687.png" alt="image-20220328155851581"></p>
<h2 id="Binary-Weights"><a href="#Binary-Weights" class="headerlink" title="Binary Weights"></a>Binary Weights</h2><p>用一个bit存储参数</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281559770.png" alt="image-20220328155945690"></p>
<p>效果似乎还可以：</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281600609.png" alt="image-20220328160023499"></p>
<h2 id="Depthwise-separable-convolution-Architecture-Design"><a href="#Depthwise-separable-convolution-Architecture-Design" class="headerlink" title="Depthwise separable convolution __Architecture Design"></a>Depthwise separable convolution __Architecture Design</h2><h3 id="Review-Standard-CNN"><a href="#Review-Standard-CNN" class="headerlink" title="Review: Standard CNN"></a>Review: Standard CNN</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281606053.png" alt="image-20220328160639972"></p>
<h3 id="Depthwise-separable-Convolution"><a href="#Depthwise-separable-Convolution" class="headerlink" title="Depthwise separable Convolution"></a>Depthwise separable Convolution</h3><p>有几个channel就有几个filter</p>
<p>Channel之间没有互动，所以有了pointwise的，它限定filter大小为1</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281615768.png" alt="image-20220328161511681"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281616476.png" alt="image-20220328161657389"></p>
<p>（插眼）</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281620185.png" alt="image-20220328162041103"></p>
<h2 id="Low-rank-approximation"><a href="#Low-rank-approximation" class="headerlink" title="Low rank approximation"></a>Low rank approximation</h2><p>用矩阵乘法减少参数规模</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281624026.png" alt="image-20220328162440961"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281627610.png" alt="image-20220328162754516"></p>
<h3 id="To-learning-more"><a href="#To-learning-more" class="headerlink" title="To learning more"></a>To learning more</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281628956.png" alt="image-20220328162812895"></p>
<h2 id="Dynamic-Computation"><a href="#Dynamic-Computation" class="headerlink" title="Dynamic Computation"></a>Dynamic Computation</h2><p>根据需要自由的调整运算量，（同一模型应用到不同的硬件上，同一硬件的不同状态上）</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281630007.png" alt="image-20220328163037924"></p>
<h3 id="Dynamic-Depth"><a href="#Dynamic-Depth" class="headerlink" title="Dynamic Depth"></a>Dynamic Depth</h3><p>根据情况停止于不同的深度</p>
<p>只要在训练时考虑各层输出就可以了，但是效果一般还有更好的。</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281633533.png" alt="image-20220328163344459"></p>
<h3 id="Dynamic-Width"><a href="#Dynamic-Width" class="headerlink" title="Dynamic Width"></a>Dynamic Width</h3><p>根据需要选择宽度</p>
<p>但是其实也有问题，可以根据需要看引用的论文</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281634666.png" alt="image-20220328163450581"></p>
<h3 id="Computation-based-on-Sample-Difficulty"><a href="#Computation-based-on-Sample-Difficulty" class="headerlink" title="Computation based on Sample Difficulty"></a>Computation based on Sample Difficulty</h3><p>根据实际问题的困难程度来选择要应用的模型深度 </p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281637553.png" alt="image-20220328163708467"></p>
<h2 id="Concluding-Remarks"><a href="#Concluding-Remarks" class="headerlink" title="Concluding Remarks"></a>Concluding Remarks</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281638583.png" alt="image-20220328163851522"></p>
<h1 id="元學習-Meta-Learning-一-元學習跟機器學習一樣也是三個步驟"><a href="#元學習-Meta-Learning-一-元學習跟機器學習一樣也是三個步驟" class="headerlink" title="元學習 Meta Learning (一) - 元學習跟機器學習一樣也是三個步驟"></a>元學習 Meta Learning (一) - 元學習跟機器學習一樣也是三個步驟</h1><p>学习如何学习</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281654075.png" alt="image-20220328165427008"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281700477.png" alt="image-20220328170015356"></p>
<h2 id="review-of-machine-learning"><a href="#review-of-machine-learning" class="headerlink" title="review of machine learning"></a>review of machine learning</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281701080.png" alt="image-20220328170158993"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281702412.png" alt="image-20220328170251327"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281703842.png" alt="image-20220328170321764"></p>
<h2 id="introduction-of-meta-learning"><a href="#introduction-of-meta-learning" class="headerlink" title="introduction of meta learning"></a>introduction of meta learning</h2><h2 id="What-is-Meta-Learning"><a href="#What-is-Meta-Learning" class="headerlink" title="What is Meta Learning?"></a>What is Meta Learning?</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281705185.png" alt="image-20220328170555103"></p>
<p>用机器学习学习的方法</p>
<h2 id="Meta-Learning-Step-1"><a href="#Meta-Learning-Step-1" class="headerlink" title="Meta Learning Step 1"></a>Meta Learning Step 1</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281708732.png" alt="image-20220328170825653"></p>
<h2 id="Meta-learning-step-2-插眼，跟丢了"><a href="#Meta-learning-step-2-插眼，跟丢了" class="headerlink" title="Meta learning step 2(插眼，跟丢了)"></a>Meta learning step 2(插眼，跟丢了)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281710157.png" alt="image-20220328171027065"></p>
<p>分别在训练集和测试集训练</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281713059.png" alt="image-20220328171303974"></p>
<p>在很多任务上进行训练</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281715838.png" alt="image-20220328171550749"></p>
<p>meta learning用测试资计算loss</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281718025.png" alt="image-20220328171801876"></p>
<h2 id="Meta-learning-step-3"><a href="#Meta-learning-step-3" class="headerlink" title="Meta learning step 3"></a>Meta learning step 3</h2><p>如果gradient descent没办法算？</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281720514.png" alt="image-20220328172006437"> </p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281721024.png" alt="image-20220328172147926"></p>
<p>few shot learning不是meta learning</p>
<h2 id="ML-vs-Meta"><a href="#ML-vs-Meta" class="headerlink" title="ML vs Meta"></a>ML vs Meta</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281725934.png" alt="image-20220328172508853"></p>
<h3 id="Training-Data"><a href="#Training-Data" class="headerlink" title="Training Data"></a>Training Data</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281726785.png" alt="image-20220328172603692"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281727297.png" alt="image-20220328172712197"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281729076.png" alt="image-20220328172950986"></p>
<h3 id="Loss-1"><a href="#Loss-1" class="headerlink" title="Loss"></a>Loss</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281730873.png" alt="image-20220328173054796"></p>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281732443.png" alt="image-20220328173249349"></p>
<h3 id="共通之处"><a href="#共通之处" class="headerlink" title="共通之处"></a>共通之处</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281733890.png" alt="image-20220328173349819"></p>
<p>Meta meta meta meat …. leaning 学习如何去学习如何学习如何学习</p>
<h1 id="元學習-Meta-Learning-二-萬物皆可-Meta"><a href="#元學習-Meta-Learning-二-萬物皆可-Meta" class="headerlink" title="元學習 Meta Learning (二) - 萬物皆可 Meta"></a>元學習 Meta Learning (二) - 萬物皆可 Meta</h1><h2 id="Review-Gradient-Descent"><a href="#Review-Gradient-Descent" class="headerlink" title="Review: Gradient Descent"></a>Review: Gradient Descent</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281742066.png" alt="image-20220328174242980"></p>
<h2 id="Learning-to-initialize"><a href="#Learning-to-initialize" class="headerlink" title="Learning to initialize"></a>Learning to initialize</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281743464.png" alt="image-20220328174308374"></p>
<h3 id="How-to-train-you-Dragon-MAML"><a href="#How-to-train-you-Dragon-MAML" class="headerlink" title="How to train you Dragon MAML"></a>How to train you <del>Dragon</del> MAML</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281747862.png" alt="image-20220328174702768"></p>
<h2 id="Maml-vs-pretraining"><a href="#Maml-vs-pretraining" class="headerlink" title="Maml vs pretraining"></a>Maml vs pretraining</h2><p> domain adaptation 是个啥？（插眼）</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281750111.png" alt="image-20220328175020986"></p>
<h3 id="More"><a href="#More" class="headerlink" title="More"></a>More</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281749342.png" alt="image-20220328174902269"></p>
<h2 id="Maml-is-good-because。。。"><a href="#Maml-is-good-because。。。" class="headerlink" title="Maml is good because。。。"></a>Maml is good because。。。</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281751958.png" alt="image-20220328175152866"></p>
<h3 id="More-1"><a href="#More-1" class="headerlink" title="More"></a>More</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281753879.png" alt="image-20220328175310815"></p>
<h2 id="Learn-to-get-a-better-Optimizer"><a href="#Learn-to-get-a-better-Optimizer" class="headerlink" title="Learn to get a better Optimizer"></a>Learn to get a better Optimizer</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281754018.png" alt="image-20220328175407919"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281754836.png" alt="image-20220328175422752"></p>
<h2 id="Network-Architecture-Search-NAS"><a href="#Network-Architecture-Search-NAS" class="headerlink" title="Network Architecture Search (NAS)"></a>Network Architecture Search (NAS)</h2><p>学习模型的架构</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281757667.png" alt="image-20220328175745582"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281758513.png" alt="image-20220328175819434"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281800827.png" alt="image-20220328180023736"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281800052.png" alt="image-20220328180041964"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281801336.png" alt="image-20220328180117256"></p>
<h2 id="Learn-about-Data-Augmentation"><a href="#Learn-about-Data-Augmentation" class="headerlink" title="Learn about Data Augmentation"></a>Learn about Data Augmentation</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281802367.png" alt="image-20220328180204271"> </p>
<h2 id="Sample-Reweighting"><a href="#Sample-Reweighting" class="headerlink" title="Sample Reweighting"></a>Sample Reweighting</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281803971.png" alt="image-20220328180324890"></p>
<h2 id="Beyond-Gradient-Descent"><a href="#Beyond-Gradient-Descent" class="headerlink" title="Beyond Gradient Descent"></a>Beyond Gradient Descent</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281804643.png" alt="image-20220328180419562"></p>
<h2 id="Until-now-…"><a href="#Until-now-…" class="headerlink" title="Until now …"></a>Until now …</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281806017.png" alt="image-20220328180602923"></p>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="Few-shot-image-classification"><a href="#Few-shot-image-classification" class="headerlink" title="Few-shot image classification"></a>Few-shot image classification</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281807794.png" alt="image-20220328180754705"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281808353.png" alt="image-20220328180820253"></p>
<p>可以根据这个数据集制造出自己需要的数据集</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281811140.png" alt="image-20220328181140060"></p>
<h3 id="more-than-omniglot"><a href="#more-than-omniglot" class="headerlink" title="more than omniglot"></a>more than omniglot</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281812016.png" alt="image-20220328181213915"></p>
<h1 id="課程結語-最後的業配並改編《為學一首示子姪》作結"><a href="#課程結語-最後的業配並改編《為學一首示子姪》作結" class="headerlink" title="課程結語 - 最後的業配並改編《為學一首示子姪》作結"></a>課程結語 - 最後的業配並改編《為學一首示子姪》作結</h1><h2 id="What-do-we-learn"><a href="#What-do-we-learn" class="headerlink" title="What do we learn"></a>What do we learn</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281844280.png" alt="image-20220328184420187"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281845594.png" alt="image-20220328184549520"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281847986.png" alt="image-20220328184759889"></p>
<p>This is a long journey,It’s just the beginning not the end.</p>
<h2 id="What-to-Learn-Next"><a href="#What-to-Learn-Next" class="headerlink" title="What to Learn Next"></a>What to Learn Next</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281851699.png" alt="image-20220328185146622"></p>
<h1 id="爲學一-首示子侄"><a href="#爲學一-首示子侄" class="headerlink" title="爲學一 首示子侄"></a>爲學一 首示子侄</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281856990.png" alt="image-20220328185652915"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281858304.png" alt="image-20220328185835224"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/uncategorized/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/uncategorized/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 1970-01-01 08:00:00" itemprop="dateCreated datePublished" datetime="1970-01-01T08:00:00+08:00">1970-01-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-22 10:39:23" itemprop="dateModified" datetime="2022-03-22T10:39:23+08:00">2022-03-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">冀ICP备2021011397号-1 </a>
  </div>

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Juggler</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.12.1/dist/algoliasearch-lite.umd.js" integrity="sha256-gOvJ6W+j+t/cgnnl9iUU3cb6F1WFQGDdtTXhfPjU4bc=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4.39.0/dist/instantsearch.production.min.js" integrity="sha256-+ZlQZK9m82XOYGFZCIRrPOFh2kDdAGB6e7TjWGvoaSY=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js","integrity":"sha256-7wT34TI0pEBeEFoi4z+vhuSddGh6vUTMWdqJ2SDe2jg="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.2.0/dist/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://juggler.fun/page/4/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"LoveinSun","repo":"blog-comment","client_id":"40e1002206dc11748978","client_secret":"027043262cdf608cfa6b1c20173bc245b1cff702","admin_user":"LoveinSun","distraction_free_mode":true,"proxy":"https://proxy.juggler.fun:9013/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"dbb1aad0300bb8f37fa677175e85a293"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
