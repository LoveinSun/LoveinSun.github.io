<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"juggler.fun","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:type" content="website">
<meta property="og:title" content="JugglerDancing">
<meta property="og:url" content="https://juggler.fun/page/3/index.html">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Juggler">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://juggler.fun/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>JugglerDancing</title>
  





  <script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js" integrity="sha256-6Y7CJDaltoeNgk+ZftgCD9jLgmGv4xKUo8nQ0HgAwVo=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" integrity="sha256-uqQQGnDcmRKvhKwc5Vm4XT1GQ2oV6t1U0NR2N9tV+BQ=" crossorigin="anonymous" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
<div id="aplayer"></div>
<script type="text/javascript" src="/dist/music.js"></script>
	<div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">JugglerDancing</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Juggler is dancing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container">
  <div class="algolia-stats"><hr></div>
  <div class="algolia-hits"></div>
  <div class="algolia-pagination"></div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Juggler"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Juggler</p>
  <div class="site-description" itemprop="description">吾之生命如流星，誓要从全世界路过。</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/python-%E5%88%A9%E7%94%A8azcopy-%E4%BB%8Eazure-storage-%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%86%85%E5%AE%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/python-%E5%88%A9%E7%94%A8azcopy-%E4%BB%8Eazure-storage-%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%86%85%E5%AE%B9/" class="post-title-link" itemprop="url">python 利用azcopy 从azure storage 上下载内容</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:56:20 / Modified: 11:22:05" itemprop="dateCreated datePublished" datetime="2022-03-23T10:56:20+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> LRUCache <span class="keyword">import</span> LRUCache</span><br><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">model_path</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;get model&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> model_path == <span class="string">&quot;&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>;</span><br><span class="line">    model = cache.get(model_path)</span><br><span class="line">    <span class="keyword">if</span> model!=-<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> model</span><br><span class="line"> </span><br><span class="line">    local_path = head+model_path.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;input model_path:<span class="subst">&#123;model_path&#125;</span>\nlocal_path:<span class="subst">&#123;local_path&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    cmd_ret = <span class="literal">None</span></span><br><span class="line">    <span class="built_in">print</span>(os.path.exists(local_path))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(local_path):</span><br><span class="line">        index_cmd_return = subprocess.run([<span class="string">&quot;./azcopy&quot;</span>, <span class="string">&quot;copy&quot;</span>, url_template.<span class="built_in">format</span>(model_path),head,<span class="string">&quot;--recursive&quot;</span>])</span><br><span class="line">    model = load_model(local_path)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">    cache.<span class="built_in">set</span>(model_path,model)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"> </span><br><span class="line">get_model(<span class="string">&quot;ao/als/aia-tra/b/model_epoch5-it235-loss1.514&quot;</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/python-MongoDB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/python-MongoDB/" class="post-title-link" itemprop="url">python MongoDB</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:54:39 / Modified: 11:20:47" itemprop="dateCreated datePublished" datetime="2022-03-23T10:54:39+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>:</span><br><span class="line"> </span><br><span class="line">    FirstName = <span class="literal">None</span></span><br><span class="line">    LastName = <span class="literal">None</span></span><br><span class="line">    Email = <span class="literal">None</span></span><br><span class="line">    Password = <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,Email,Password,FirstName,LastName = <span class="string">&quot;&quot;</span></span>):</span><br><span class="line">        self.Email = Email</span><br><span class="line">        self.Password = Password</span><br><span class="line">        self.FirstName = FirstName</span><br><span class="line">        self.LastName = LastName</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">json</span>(<span class="params">self</span>):</span><br><span class="line">        json = &#123;</span><br><span class="line">                    <span class="string">&quot;Email&quot;</span>:self.Email,</span><br><span class="line">                    <span class="string">&quot;Password&quot;</span>:self.Password,</span><br><span class="line">                    <span class="string">&quot;FirstName&quot;</span>:self.FirstName,</span><br><span class="line">                    <span class="string">&quot;LastName&quot;</span>:self.LastName</span><br><span class="line">                &#125;</span><br><span class="line">        <span class="keyword">return</span> json</span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GameDB</span>:</span><br><span class="line"> </span><br><span class="line">    url = <span class="string">&quot;&quot;</span></span><br><span class="line">    client = <span class="literal">None</span></span><br><span class="line">    db = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,url = <span class="string">&quot;mongodb://jo:jokda@localhost&quot;</span></span>):</span><br><span class="line">        self.url = url</span><br><span class="line">        self.client = MongoClient(self.url)</span><br><span class="line">        self.db = self.client.game</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">insert</span>(<span class="params">self,user,flag=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            self.db.inventory.insert_many(user)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        select = self.select(&#123;<span class="string">&quot;Email&quot;</span>:user.Email&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(select) != <span class="number">0</span> :</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line">        json_user = user.json()</span><br><span class="line">        self.db.inventory.insert_one(json_user)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">select</span>(<span class="params">self,condition=&#123;&#125;</span>):</span><br><span class="line">        cursor = self.db.inventory.find(condition)</span><br><span class="line">        result = [doc <span class="keyword">for</span> doc <span class="keyword">in</span> cursor]</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self,user:User,flag=<span class="literal">True</span></span>):</span><br><span class="line">        select = self.select(&#123;<span class="string">&quot;Email&quot;</span>:user.Email&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(select)&lt;<span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> flag :</span><br><span class="line">            self.db.inventory.update_many(</span><br><span class="line">                &#123;<span class="string">&quot;Email&quot;</span>:user.Email&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;$set&quot;</span>:&#123;</span><br><span class="line">                    <span class="string">&quot;Password&quot;</span>:user.Password,</span><br><span class="line">                    <span class="string">&quot;FirstName&quot;</span>:user.FirstName,</span><br><span class="line">                    <span class="string">&quot;LastName&quot;</span>:user.LastName</span><br><span class="line">                &#125;&#125;,</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">        self.db.inventory.update_one(</span><br><span class="line">                &#123;<span class="string">&quot;Email&quot;</span>:user.Email&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;$set&quot;</span>:&#123;</span><br><span class="line">                    <span class="string">&quot;$Password&quot;</span>:user.Password,</span><br><span class="line">                    <span class="string">&quot;$FirstName&quot;</span>:user.FirstName,</span><br><span class="line">                    <span class="string">&quot;$LastName&quot;</span>:user.LastName</span><br><span class="line">                &#125;&#125;,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">self,condition,flag=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="keyword">if</span> flag :</span><br><span class="line">            self.db.inventory.delete_many(condition)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.db.inventory.delete_one(condtion)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#user = User(&quot;19@qq.com&quot;,&quot;password&quot;,&quot;pa&quot;,&quot;zika&quot;)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">#db = GameDB()</span></span><br><span class="line"><span class="comment">#db.add(user)</span></span><br><span class="line"><span class="comment">#db.printf()</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/python-LRUCache/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/python-LRUCache/" class="post-title-link" itemprop="url">python LRUCache</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:53:42 / Modified: 11:21:32" itemprop="dateCreated datePublished" datetime="2022-03-23T10:53:42+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span>(collections.OrderedDict):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, size=<span class="number">2</span></span>):</span><br><span class="line">        <span class="comment">#print(self.size)</span></span><br><span class="line"> </span><br><span class="line">        self.size = size,</span><br><span class="line">        <span class="built_in">print</span>(self.size)</span><br><span class="line">        self.cache = collections.OrderedDict()</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self, key</span>):</span><br><span class="line">        <span class="comment">#if self.cache.has_key(key):</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.cache:</span><br><span class="line">            val = self.cache.pop(key)</span><br><span class="line">            self.cache[key] = val</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            val = -<span class="number">1</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">set</span>(<span class="params">self, key, val</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;len <span class="subst">&#123;<span class="built_in">len</span>(self.cache)&#125;</span>,size<span class="subst">&#123;self.size&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment">#if self.cache.has_key(key):</span></span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">in</span> self.cache:</span><br><span class="line">            val = self.cache.pop(key)</span><br><span class="line">            self.cache[key] = val</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(self.cache) &gt;= self.size[<span class="number">0</span>]:</span><br><span class="line">                item = self.cache.popitem(last=<span class="literal">False</span>)</span><br><span class="line">                delete(item)</span><br><span class="line">            self.cache[key] = val</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">item</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;============================start delete=========================================&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br><span class="line">    <span class="comment">#del item[1]</span></span><br><span class="line">    path =<span class="string">&quot;/&quot;</span>.join(item[<span class="number">0</span>].split(<span class="string">&quot;/&quot;</span>)[:-<span class="number">3</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;delete path : &quot;</span>+path)</span><br><span class="line">    subprocess.run([<span class="string">&quot;rm&quot;</span>,<span class="string">&quot;-r&quot;</span>,path])</span><br><span class="line">    <span class="keyword">del</span> item</span><br><span class="line">    gc.collect()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;============================delete comlete=======================================&quot;</span>)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/%E5%AF%86%E7%A0%81%E5%AD%A6/C-AES%E5%8A%A0%E7%9B%90%E5%8A%A0%E5%AF%86-python-AES%E5%8A%A0%E7%9B%90%E8%A7%A3%E5%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/%E5%AF%86%E7%A0%81%E5%AD%A6/C-AES%E5%8A%A0%E7%9B%90%E5%8A%A0%E5%AF%86-python-AES%E5%8A%A0%E7%9B%90%E8%A7%A3%E5%AF%86/" class="post-title-link" itemprop="url">C# AES加盐加密 python AES加盐解密</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:51:46 / Modified: 11:25:15" itemprop="dateCreated datePublished" datetime="2022-03-23T10:51:46+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%AF%86%E7%A0%81%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">密码学</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>C# </p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="built_in">string</span> <span class="title">encrypt</span>(<span class="params"><span class="built_in">string</span> clearText = <span class="string">&quot;&quot;</span></span>)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (clearText == <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            clearText = <span class="string">&quot;&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="built_in">string</span> EncryptionKey = <span class="string">&quot;Saturday&quot;</span>;</span><br><span class="line">        <span class="built_in">byte</span>[] clearBytes = Encoding.UTF8.GetBytes(clearText);</span><br><span class="line">        <span class="keyword">using</span> (Aes encryptor = Aes.Create())</span><br><span class="line">        &#123;</span><br><span class="line">            Rfc2898DeriveBytes pdb = <span class="keyword">new</span> Rfc2898DeriveBytes(EncryptionKey, <span class="keyword">new</span> <span class="built_in">byte</span>[] &#123; <span class="number">0x49</span>, <span class="number">0x76</span>, <span class="number">0x61</span>, <span class="number">0x6e</span>, <span class="number">0x20</span>, <span class="number">0x4d</span>, <span class="number">0x65</span>, <span class="number">0x64</span>, <span class="number">0x76</span>, <span class="number">0x65</span>, <span class="number">0x64</span>, <span class="number">0x65</span>, <span class="number">0x76</span> &#125;, <span class="number">100000</span>, HashAlgorithmName.SHA1);</span><br><span class="line">            encryptor.Key = pdb.GetBytes(<span class="number">32</span>);</span><br><span class="line">            encryptor.IV = pdb.GetBytes(<span class="number">16</span>);</span><br><span class="line">            encryptor.Mode = CipherMode.CBC;</span><br><span class="line">            <span class="keyword">using</span> (MemoryStream ms = <span class="keyword">new</span> MemoryStream())</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">using</span> (CryptoStream cs = <span class="keyword">new</span> CryptoStream(ms, encryptor.CreateEncryptor(), CryptoStreamMode.Write))</span><br><span class="line">                &#123;</span><br><span class="line">                    cs.Write(clearBytes, <span class="number">0</span>, clearBytes.Length);</span><br><span class="line">                    cs.Close();</span><br><span class="line">                &#125;</span><br><span class="line">                clearText = Convert.ToBase64String(ms.ToArray());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> clearText;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Decryptstr</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> text <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            backend = default_backend()</span><br><span class="line">            EncryptionKey = <span class="string">&quot;Saturday&quot;</span></span><br><span class="line">            salt = <span class="built_in">bytes</span>([ <span class="number">0x49</span>, <span class="number">0x76</span>, <span class="number">0x61</span>, <span class="number">0x6e</span>, <span class="number">0x20</span>, <span class="number">0x4d</span>, <span class="number">0x65</span>, <span class="number">0x64</span>, <span class="number">0x76</span>, <span class="number">0x65</span>, <span class="number">0x64</span>, <span class="number">0x65</span>, <span class="number">0x76</span> ])</span><br><span class="line">            kdf = PBKDF2HMAC(algorithm=hashes.SHA1(),length=<span class="number">48</span>,salt=salt,iterations=<span class="number">100000</span>,backend=backend)</span><br><span class="line">            key_bytes = kdf.derive(<span class="built_in">bytes</span>(EncryptionKey, <span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">            key = key_bytes[<span class="number">0</span>:<span class="number">32</span>]</span><br><span class="line">            iv = key_bytes[<span class="number">32</span>:]</span><br><span class="line">            cipherbytes = base64.b64decode(text)</span><br><span class="line">            cipher = AES.new(key, AES.MODE_CBC, iv)</span><br><span class="line">            password = cipher.decrypt(cipherbytes).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">            <span class="keyword">return</span> password</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> err:</span><br><span class="line">        <span class="built_in">print</span>(err)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/nacos/fastapi-nacos/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/nacos/fastapi-nacos/" class="post-title-link" itemprop="url">fastapi nacos</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:25:44 / Modified: 11:26:29" itemprop="dateCreated datePublished" datetime="2022-03-23T10:25:44+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/nacos/" itemprop="url" rel="index"><span itemprop="name">nacos</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nacos_py</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> munch <span class="keyword">import</span> munchify</span><br><span class="line"><span class="keyword">from</span> starlette.requests <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> starlette.responses <span class="keyword">import</span> Response</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"> </span><br><span class="line">sys.tracebacklimit = <span class="number">3</span>  <span class="comment"># 限制打印错误行数</span></span><br><span class="line"><span class="comment"># 首先配置application.properties中nacos.core.auth.enabled=true</span></span><br><span class="line"><span class="comment"># 配置nacos 用户-角色-权限</span></span><br><span class="line"> </span><br><span class="line">app = FastAPI()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># async def catch_exceptions_middleware(request: Request, call_next):</span></span><br><span class="line"><span class="comment">#     try:</span></span><br><span class="line"><span class="comment">#         return await call_next(request)</span></span><br><span class="line"><span class="comment">#     except Exception as e:</span></span><br><span class="line"><span class="comment">#         # print(e)</span></span><br><span class="line"><span class="comment">#         # print(traceback.format_list())</span></span><br><span class="line"><span class="comment">#         return Response(&quot;Internal server error&quot;, status_code=500)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># app.middleware(&#x27;http&#x27;)(catch_exceptions_middleware)</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.exception_handler(<span class="params">Exception</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">custom_http_exception_handler</span>(<span class="params">request, exc</span>):</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="string">&quot;Internal server exception&quot;</span>, status_code=<span class="number">500</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.exception_handler(<span class="params">ZeroDivisionError</span>)  </span><span class="comment"># 统一处理某些错误</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">custom_http_exception_handler</span>(<span class="params">request, exc</span>):</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="string">&quot;Internal server error&quot;</span>, status_code=<span class="number">500</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">nacos</span>:</span><br><span class="line">    SERVER_ADDRESSES = <span class="string">&quot;127.0.0.1:8845&quot;</span></span><br><span class="line">    NAMESPACE = <span class="string">&quot;public&quot;</span></span><br><span class="line">    client = nacos_py.NacosClient(SERVER_ADDRESSES, namespace=NAMESPACE, username=<span class="string">&quot;pang&quot;</span>, password=<span class="string">&quot;pang&quot;</span>)</span><br><span class="line">    data_id = <span class="string">&quot;testDataId&quot;</span></span><br><span class="line">    group = <span class="string">&quot;testGroup&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_watcher</span>(<span class="params">self, methods</span>):</span><br><span class="line">        self.client.add_config_watchers(self.data_id, self.group, methods)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">self, data_id=<span class="literal">None</span>, group=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> data_id <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data_id = self.data_id</span><br><span class="line">        <span class="keyword">if</span> group <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            group = self.group</span><br><span class="line">        confi = self.client.get_config(data_id, group)</span><br><span class="line">        confi = yaml.safe_load(confi)</span><br><span class="line">        core_config = munchify(confi)</span><br><span class="line">        <span class="built_in">print</span>(core_config)</span><br><span class="line">        <span class="keyword">return</span> confi</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="keyword">global</span> config</span><br><span class="line">    config = a.get_config()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">a = nacos()</span><br><span class="line">config = a.get_config()</span><br><span class="line">a.add_watcher(&#123;call&#125;)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/print&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">root</span>():</span><br><span class="line">    var = <span class="number">1</span> / <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: config&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/prin&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">root</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: config&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/C/Azure-Service-Bus-%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E5%99%A8%E4%BB%A5%E5%8F%8A%E6%8C%89%E5%BA%8F%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/C/Azure-Service-Bus-%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E5%99%A8%E4%BB%A5%E5%8F%8A%E6%8C%89%E5%BA%8F%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/" class="post-title-link" itemprop="url">Azure Service Bus 实现定时器以及按序执行任务</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 18:50:13" itemprop="dateCreated datePublished" datetime="2022-03-22T18:50:13+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:20:09" itemprop="dateModified" datetime="2022-03-23T11:20:09+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C/" itemprop="url" rel="index"><span itemprop="name">C#</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"><span class="keyword">using</span> System.Threading.Tasks;</span><br><span class="line"><span class="keyword">using</span> Azure.Messaging.ServiceBus;</span><br><span class="line"><span class="keyword">using</span> System.Collections;</span><br><span class="line"><span class="keyword">using</span> Newtonsoft.Json.Linq;</span><br><span class="line"><span class="keyword">using</span> System.Collections.Generic;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">namespace</span> <span class="title">ServiceBusConsole</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">internal</span> <span class="keyword">class</span> <span class="title">Program</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// connection string to your Service Bus namespace</span></span><br><span class="line">        <span class="keyword">static</span> <span class="built_in">string</span> connectionString = <span class="string">&quot;Endpoint=sb://&quot;</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// name of your Service Bus topic</span></span><br><span class="line">        <span class="keyword">static</span> <span class="built_in">string</span> topicName = <span class="string">&quot;actieue&quot;</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">static</span> Queue&lt;<span class="built_in">string</span>&gt; a;</span><br><span class="line">        <span class="comment">// number of messages to be sent to the topic</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">const</span> <span class="built_in">int</span> taskNumber = <span class="number">8</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            Random random = <span class="keyword">new</span> Random();</span><br><span class="line">            a = <span class="keyword">new</span> Queue&lt;<span class="built_in">string</span>&gt;();</span><br><span class="line">            <span class="keyword">for</span>(<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; taskNumber; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                JObject jo = <span class="keyword">new</span> JObject();</span><br><span class="line">                jo[<span class="string">&quot;taskId&quot;</span>] = i;</span><br><span class="line">                jo[<span class="string">&quot;excutionTime&quot;</span>] = random.Next(<span class="number">10</span>);</span><br><span class="line">                a.Enqueue(jo.ToString());</span><br><span class="line">            &#125;</span><br><span class="line">            ArrayList b = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            b.Add(a.Dequeue());</span><br><span class="line">            sendMessage(b).Wait();</span><br><span class="line">            <span class="keyword">get</span>().Wait();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">sendMessage</span>(<span class="params">ArrayList msgs</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// the client that owns the connection and can be used to create senders and receivers</span></span><br><span class="line">            ServiceBusClient client;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// the sender used to publish messages to the topic</span></span><br><span class="line">            ServiceBusSender sender;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// The Service Bus client types are safe to cache and use as a singleton for the lifetime</span></span><br><span class="line">            <span class="comment">// of the application, which is best practice when messages are being published or read</span></span><br><span class="line">            <span class="comment">// regularly.</span></span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="comment">// Create the clients that we&#x27;ll use for sending and processing messages.</span></span><br><span class="line">            client = <span class="keyword">new</span> ServiceBusClient(connectionString);</span><br><span class="line">            sender = client.CreateSender(topicName);</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// create a batch </span></span><br><span class="line">            ServiceBusMessageBatch messageBatch = <span class="keyword">await</span> sender.CreateMessageBatchAsync();</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">foreach</span> (Object o <span class="keyword">in</span> msgs)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">string</span> msg = (<span class="built_in">string</span>)o;</span><br><span class="line">                <span class="comment">// try adding a message to the batch</span></span><br><span class="line">                ServiceBusMessage m = <span class="keyword">new</span> ServiceBusMessage(msg);</span><br><span class="line">                JObject j = JObject.Parse(msg);</span><br><span class="line">                <span class="built_in">double</span> d = <span class="built_in">double</span>.Parse(j[<span class="string">&quot;excutionTime&quot;</span>].ToString());</span><br><span class="line">                m.ScheduledEnqueueTime = DateTimeOffset.Now.AddSeconds(d);</span><br><span class="line">                <span class="keyword">if</span> (!messageBatch.TryAddMessage(m))</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">// if it is too large for the batch</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">$&quot;The message msg is too large to fit in the batch.&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Use the producer client to send the batch of messages to the Service Bus topic</span></span><br><span class="line">                <span class="keyword">await</span> sender.SendMessagesAsync(messageBatch);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">finally</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Calling DisposeAsync on client types is required to ensure that network</span></span><br><span class="line">                <span class="comment">// resources and other unmanaged objects are properly cleaned up.</span></span><br><span class="line">                messageBatch.Dispose();</span><br><span class="line">                <span class="keyword">await</span> sender.DisposeAsync();</span><br><span class="line">                <span class="keyword">await</span> client.DisposeAsync();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">get</span>()</span></span><br><span class="line">        &#123;</span><br><span class="line">            ServiceBusClient client;</span><br><span class="line">            ServiceBusProcessor processor;</span><br><span class="line">            client = <span class="keyword">new</span> ServiceBusClient(connectionString);</span><br><span class="line">            processor = client.CreateProcessor(topicName, <span class="keyword">new</span> ServiceBusProcessorOptions());</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// add handler to process messages</span></span><br><span class="line">                processor.ProcessMessageAsync += MessageHandler;</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// add handler to process any errors</span></span><br><span class="line">                processor.ProcessErrorAsync += ErrorHandler;</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// start processing </span></span><br><span class="line">                <span class="keyword">await</span> processor.StartProcessingAsync();</span><br><span class="line"> </span><br><span class="line">                Console.WriteLine(<span class="string">&quot;Start Task 0 is runing&quot;</span>);</span><br><span class="line">                Console.WriteLine(<span class="string">$&quot;It is <span class="subst">&#123;DateTimeOffset.Now&#125;</span> now&quot;</span>);</span><br><span class="line">                Console.ReadKey();</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// stop processing </span></span><br><span class="line">                Console.WriteLine(<span class="string">&quot;\nStopping the receiver...&quot;</span>);</span><br><span class="line">                <span class="keyword">await</span> processor.StopProcessingAsync();</span><br><span class="line">                Console.WriteLine(<span class="string">&quot;Stopped receiving messages&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">finally</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Calling DisposeAsync on client types is required to ensure that network</span></span><br><span class="line">                <span class="comment">// resources and other unmanaged objects are properly cleaned up.</span></span><br><span class="line">                <span class="keyword">await</span> processor.DisposeAsync();</span><br><span class="line">                <span class="keyword">await</span> client.DisposeAsync();</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">MessageHandler</span>(<span class="params">ProcessMessageEventArgs args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            ArrayList c = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            <span class="built_in">string</span> body = args.Message.Body.ToString();</span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                c.Add(a.Dequeue());</span><br><span class="line">                sendMessage(c).Wait();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">catch</span> (Exception ex)</span><br><span class="line">            &#123;</span><br><span class="line"> </span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            Console.WriteLine(<span class="string">$&quot;At <span class="subst">&#123;DateTimeOffset.Now&#125;</span>,This task is finished:\nReceived: <span class="subst">&#123;body&#125;</span> &quot;</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// complete the message. messages is deleted from the subscription. </span></span><br><span class="line">            <span class="keyword">await</span> args.CompleteMessageAsync(args.Message);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// handle any errors when receiving messages</span></span><br><span class="line">        <span class="function"><span class="keyword">static</span> Task <span class="title">ErrorHandler</span>(<span class="params">ProcessErrorEventArgs args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            Console.WriteLine(args.Exception.ToString());</span><br><span class="line">            <span class="keyword">return</span> Task.CompletedTask;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/%E6%9D%82%E8%AE%B0/%E7%A5%9D%E5%AE%89%E5%A5%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/%E6%9D%82%E8%AE%B0/%E7%A5%9D%E5%AE%89%E5%A5%BD/" class="post-title-link" itemprop="url">祝安好</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 11:17:52" itemprop="dateCreated datePublished" datetime="2022-03-22T11:17:52+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-04-02 17:39:06" itemprop="dateModified" datetime="2022-04-02T17:39:06+08:00">2022-04-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9D%82%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">杂记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我想在早 中 晚对你说 <br>早安 午安 晚安<br>可我早已无处寻你</p>
<p>就好像四季<br>春天我见不到你 我只能带着初醒的梦 和每一朵花对话。<br>夏天我见不到你 绿皮红瓤的季节 我只能剪一头短发 把蝉鸣收藏。<br>秋天我见不到你 黄昏细雨里 我只能回忆起你熟悉的味道 让你感知我最澄澈的眷恋。<br>冬天我见不到你 冬夜渐深 细碎过往已让回忆温柔很多 于是在漫天大雪里 绵延不绝的是我对你的祝福。</p>
<p>忘不掉的是夏夜的磅礴大雨<br>从前我享受飘摇其中的感觉<br>现在我想为谁撑起一把伞</p>
<p>可我如何前去寻你 <br>绝望疯长恣肆无所忌惮 <br>寂寞而眷恋着某个人 </p>
<p>如果此生再不能相见 <br>祝你早安 午安<br>和晚安</p>
<p>改自：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/34648905">https://www.zhihu.com/question/34648905</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/joy/%E9%A5%A5%E8%8D%92%E6%9C%8D%E5%8A%A1%E5%99%A8-docker-compose/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/joy/%E9%A5%A5%E8%8D%92%E6%9C%8D%E5%8A%A1%E5%99%A8-docker-compose/" class="post-title-link" itemprop="url">饥荒服务器_docker-compose</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:57:23" itemprop="dateCreated datePublished" datetime="2022-03-22T10:57:23+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:25:43" itemprop="dateModified" datetime="2022-03-23T11:25:43+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/joy/" itemprop="url" rel="index"><span itemprop="name">joy</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​<br>使用了大佬的代码</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Jamesits/docker-dst-server.git">https://github.com/Jamesits/docker-dst-server.git</a></p>
<p>但是在我的使用过程中一些mod总会报错，所以尝试将base-image改为ubuntu并解决相应错误后解决，由于我服务器的特殊配置，所以不得不将用户改为root：</p>
<p><a target="_blank" rel="noopener" href="https://gitee.com/dancingjoker/docker-dst-server">https://gitee.com/dancingjoker/docker-dst-server</a></p>
<p>我是使用的docker-compose up –build -d 启动，在docker-compose volumes中配置存档位置，其他方式可以视情况使用</p>
<p>另附定期备份命令：</p>
<p>在crontab -e中编写：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">13 4 * * * sudo bash /dir/dst/backup.sh</span><br></pre></td></tr></table></figure>
<p>定时可以参考网站：crontab.guru</p>
<p>backup.sh:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#/bin/bash</span></span><br><span class="line">tar -zcPvf /dir/dst/backup/b$(<span class="built_in">date</span> %Y%m%d%h%m%s).tar.gz /dir/dst/DoNotStarveTogether/Cluster_1</span><br></pre></td></tr></table></figure>
<p>​</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/NLP/NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/NLP/NLP/" class="post-title-link" itemprop="url">NLP</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:52" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:52+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:10" itemprop="dateModified" datetime="2022-03-23T11:23:10+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>[toc]</p>
<h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><table>
<thead>
<tr>
<th>-</th>
<th>-</th>
</tr>
</thead>
<tbody><tr>
<td>[ToL]</td>
<td>To learn</td>
</tr>
<tr>
<td>[ToLM]</td>
<td>To learn more</td>
</tr>
<tr>
<td>[ToLO]</td>
<td>To learn optionally</td>
</tr>
<tr>
<td>(0501)</td>
<td>05 min 01s</td>
</tr>
<tr>
<td>(h0501)</td>
<td>1 hour 05 min 01s</td>
</tr>
<tr>
<td>(hh0501)</td>
<td>2 hour 05 min 01s</td>
</tr>
</tbody></table>
<h1 id="Lecture-1-Introduction-and-Word-Vectors"><a href="#Lecture-1-Introduction-and-Word-Vectors" class="headerlink" title="Lecture 1 - Introduction and Word Vectors"></a>Lecture 1 - Introduction and Word Vectors</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/rmVRLeJRkl4?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214151948950.png" alt="image-20220214151948950"></p>
<h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><p>Convert one-hot encoding to distributed representitions</p>
<p>Ont hot can’t represent the relation between word vectors,it is too big</p>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>Ignore the position of word of context </p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135823259.png" alt="image-20220214135823259" style="zoom: 35%;" />

<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135951707.png" alt="image-20220214135951707" style="zoom:50%;" />

<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140036077.png" alt="image-20220214140036077" style="zoom:50%;" />

<h3 id="Use-two-vector-in-one-word-centor-word-context-word"><a href="#Use-two-vector-in-one-word-centor-word-context-word" class="headerlink" title="Use two vector in one word: centor word context word."></a>Use two vector in one word: centor word context word.</h3><h3 id="softmax-function"><a href="#softmax-function" class="headerlink" title="softmax function"></a>softmax function</h3><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140209594.png" alt="image-20220214140209594" style="zoom:50%;" />

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141232602.png" alt="image-20220214141232602"></p>
<h3 id="Train-the-model-gradient-descent"><a href="#Train-the-model-gradient-descent" class="headerlink" title="Train the model: gradient descent"></a>Train the model: gradient descent</h3><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141455212.png" alt="image-20220214141455212" style="zoom:50%;" />

<p><strong>There is a term to calculate the gradient descent. (39:50-56:40)</strong></p>
<p>result is :<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214143920015.png" alt="image-20220214143920015"></p>
<p><em><strong>ToL</strong></em></p>
<p>Review derivation and the following especially.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214142712551.png" alt="image-20220214142712551"></p>
<h2 id="Show-some-achievement-with-code-5640-h0516"><a href="#Show-some-achievement-with-code-5640-h0516" class="headerlink" title="Show some achievement with code(5640-h0516)"></a>Show some achievement with code(5640-h0516)</h2><ul>
<li>We can do vector addition, subtraction, multiplication and division, etc.</li>
</ul>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><p><strong>Why are there center word and context word(h0650)</strong></p>
<p>To avoid one vector dot product himself in some situation???? </p>
<p><strong>Even synonyms can be merged into a vector(h1215)</strong></p>
<p>Which is different from lee ,He says synonyms use different.</p>
<h1 id="Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers"><a href="#Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers" class="headerlink" title="Lecture 2 Word Vectors,Word Senses,and Neural Classifiers"></a>Lecture 2 Word Vectors,Word Senses,and Neural Classifiers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/gqaHkPEZAew?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152314870.png" alt="image-20220214152314870"></p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152611205.png" alt="image-20220214152611205" style="zoom:40%;" />

<h2 id="Bag-models-0245"><a href="#Bag-models-0245" class="headerlink" title="Bag models (0245)"></a>Bag models (0245)</h2><p>The model makes the same predictions at each position.</p>
<h2 id="Gradient-descent-0600"><a href="#Gradient-descent-0600" class="headerlink" title="Gradient descent (0600)"></a>Gradient descent (0600)</h2><p>Not usually use because of the big calculation.</p>
<p>step size: not too big nor too small</p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214153736035.png" alt="image-20220214153736035" style="zoom:33%;" />

<h3 id="stochastic-gradient-descent-SGD-TOBELM-0920"><a href="#stochastic-gradient-descent-SGD-TOBELM-0920" class="headerlink" title="stochastic gradient descent SGD  TOBELM (0920)"></a>stochastic gradient descent SGD  TOBELM (0920)</h3><p>Take part of the corpus</p>
<p>billion faster.</p>
<p>Maybe even get better result.</p>
<p>But it is stochastic, either you need sparse matrix update operations to only update certain rows of full embedding matrices U and V, or you need to keep around a hash for vectors.(1344)<em><strong>ToL</strong></em></p>
<h2 id="more-details-of-word2vec-1400"><a href="#more-details-of-word2vec-1400" class="headerlink" title="more details of word2vec(1400)"></a>more details of word2vec(1400)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214160400315.png" alt="image-20220214160400315"></p>
<h3 id="SG-use-center-to-predict-context"><a href="#SG-use-center-to-predict-context" class="headerlink" title="SG use center to predict context"></a>SG use center to predict context</h3><h4 id="SGNS-negative-sampling-ToBLO"><a href="#SGNS-negative-sampling-ToBLO" class="headerlink" title="SGNS negative sampling  [ToBLO]"></a>SGNS negative sampling  [ToBLO]</h4><p>use logistic function instead of softmax and take sampling of corpus</p>
<h3 id="CBOW-opposite"><a href="#CBOW-opposite" class="headerlink" title="CBOW opposite."></a>CBOW opposite.</h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214162201460.png" alt="image-20220214162201460" style="zoom:33%;" />

<h2 id="Why-use-two-vectors-1500"><a href="#Why-use-two-vectors-1500" class="headerlink" title="Why use two vectors(1500)"></a>Why use two vectors(1500)</h2><p>Sometime it will dot product with itself.</p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214165957190.png" alt="image-20220214165957190" style="zoom:40%;" />

<p><strong>[ToL]</strong></p>
<p>The first one is positive word and the last is negative word (2800)</p>
<p>negative word is being sampled cause the center word will turn up on other occasions, when it does, there will have other sampling, and it will learn step by step.</p>
<h2 id="Why-not-capture-co-occurrence-counts-directly-2337"><a href="#Why-not-capture-co-occurrence-counts-directly-2337" class="headerlink" title="Why not capture co-occurrence counts directly?(2337)"></a>Why not capture co-occurrence counts directly?(2337)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214171624671.png" alt="image-20220214171624671"></p>
<h2 id="SVD-3230-ToL"><a href="#SVD-3230-ToL" class="headerlink" title="SVD(3230) [ToL]"></a>SVD(3230) [ToL]</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29846048">https://zhuanlan.zhihu.com/p/29846048</a></p>
<p>use svd to get lower dimensional representations for words</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214172338354.png" alt="image-20220214172338354" style="zoom:33%;" />(3451)</p>
<h2 id="Count-based-vs-direct-prediction"><a href="#Count-based-vs-direct-prediction" class="headerlink" title="Count based vs direct prediction"></a>Count based vs direct prediction</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173136681.png" alt="image-20220214173136681" style="zoom:50%;" />(3900)</p>
<h2 id="Encoing-meaning-components-in-vector-differences-3948"><a href="#Encoing-meaning-components-in-vector-differences-3948" class="headerlink" title="Encoing meaning components in vector differences(3948)"></a>Encoing meaning components in vector differences(3948)</h2><p>This is to make addition subtraction available for word vectors.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173907221.png" alt="image-20220214173907221"></p>
<h2 id="GloVe-4313"><a href="#GloVe-4313" class="headerlink" title="GloVe (4313)"></a>GloVe (4313)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214174416350.png" alt="image-20220214174416350" style="zoom: 33%;" />

<p>let dot product minus log of the co-occurrence</p>
<h2 id="How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756"><a href="#How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756" class="headerlink" title="How to evaluate word vectors Intrinsic vs. extrinsic(4756)"></a>How to evaluate word vectors Intrinsic vs. extrinsic(4756)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214175746085.png" alt="image-20220214175746085" style="zoom:50%;" />

<h3 id="Analogy-evaluation-and-hyperparameters-intrinsic-5515"><a href="#Analogy-evaluation-and-hyperparameters-intrinsic-5515" class="headerlink" title="Analogy evaluation and hyperparameters (intrinsic)(5515)"></a>Analogy evaluation and hyperparameters (intrinsic)(5515)</h3><h3 id="Word-vector-distances-and-their-correlation-with-human-judgements-5640"><a href="#Word-vector-distances-and-their-correlation-with-human-judgements-5640" class="headerlink" title="Word vector distances and their correlation with human judgements(5640)"></a>Word vector distances and their correlation with human judgements(5640)</h3><h2 id="Data-shows-that-300-dimensional-word-vector-is-good-5536"><a href="#Data-shows-that-300-dimensional-word-vector-is-good-5536" class="headerlink" title="Data shows that 300 dimensional word vector is good(5536)"></a>Data shows that 300 dimensional word vector is good(5536)</h2><h2 id="The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739"><a href="#The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739" class="headerlink" title="The objective function for the GloVe model and What log-bilinear means(5739)"></a>The objective function for the GloVe model and What log-bilinear means(5739)</h2><h2 id="Word-senses-and-word-sense-ambiguity-h0353"><a href="#Word-senses-and-word-sense-ambiguity-h0353" class="headerlink" title="Word senses and word sense ambiguity(h0353)"></a>Word senses and word sense ambiguity(h0353)</h2><p>One word different mean different vector. </p>
<p>then a word can be the sum of them all</p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214184234513.png" alt="image-20220214184234513" style="zoom:33%;" />

<p>It will work good but not bad (h1200)</p>
<p>the vector is so sparse that you can separate out different senses  (h1402)</p>
<h1 id="Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning"><a href="#Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning" class="headerlink" title="Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning"></a>Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/X0Jw4kgaFlg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191638029.png" alt="image-20220214191638029"></p>
<h2 id="Need-to-be-learn-again-it-is-not-totally-understanded"><a href="#Need-to-be-learn-again-it-is-not-totally-understanded" class="headerlink" title="Need to be learn again, it is not totally understanded."></a>Need to be learn again, it is not totally understanded.</h2><h2 id="Named-Entity-Recognition-0530"><a href="#Named-Entity-Recognition-0530" class="headerlink" title="Named Entity Recognition(0530)"></a>Named Entity Recognition(0530)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214185926393.png" alt="image-20220214185926393"></p>
<h2 id="Simple-NER-0636"><a href="#Simple-NER-0636" class="headerlink" title="Simple NER (0636)"></a>Simple NER (0636)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190032048.png" alt="image-20220214190032048"></p>
<h3 id="How-the-sample-model-run-0836"><a href="#How-the-sample-model-run-0836" class="headerlink" title="How the sample model run (0836)"></a>How the sample model run (0836)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190306082.png" alt="image-20220214190306082"></p>
<h2 id="update-equation-1220"><a href="#update-equation-1220" class="headerlink" title="update equation(1220)"></a>update equation(1220)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191531863.png" alt="image-20220214191531863"></p>
<h2 id="jacobian-1811"><a href="#jacobian-1811" class="headerlink" title="jacobian(1811)"></a>jacobian(1811)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192319871.png" alt="image-20220214192319871"></p>
<h2 id="Chain-Rule-2015"><a href="#Chain-Rule-2015" class="headerlink" title="Chain Rule(2015)"></a>Chain Rule(2015)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192526698.png" alt="image-20220214192526698" style="zoom:50%;" />

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193151609.png" alt="image-20220214193151609"></p>
<h2 id="do-one-example-step-2650"><a href="#do-one-example-step-2650" class="headerlink" title="do one example step (2650)"></a>do one example step (2650)</h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193417520.png" alt="image-20220214193417520"></h2><p>hadamard product <a href="3200">ToL</a></p>
<h2 id="Reusing-Computation-3402"><a href="#Reusing-Computation-3402" class="headerlink" title="Reusing Computation(3402)"></a>Reusing Computation(3402)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215112833279.png" alt="image-20220215112833279" style="zoom:50%;" />

<h3 id="ds-x2F-dw"><a href="#ds-x2F-dw" class="headerlink" title="ds&#x2F;dw"></a>ds&#x2F;dw</h3><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113433454.png" alt="image-20220215113433454" style="zoom:50%;" />

<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113255573.png" alt="image-20220215113255573" style="zoom:50%;" />

<h2 id="Forward-and-backward-propagation-5000"><a href="#Forward-and-backward-propagation-5000" class="headerlink" title="Forward and backward propagation(5000)"></a>Forward and backward propagation(5000)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115109857.png" alt="image-20220215115109857" style="zoom:50%;" />

<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115507912.png" alt="image-20220215115507912" style="zoom:50%;" />

<h2 id="An-example-5507"><a href="#An-example-5507" class="headerlink" title="An example(5507)"></a>An example(5507)</h2><p>a &#x3D; x+y</p>
<p>b &#x3D; max(y,z)</p>
<p>f &#x3D; ab</p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215120119537.png" alt="image-20220215120119537" style="zoom:50%;" />

<h2 id="Compute-all-gradients-at-once-h0005"><a href="#Compute-all-gradients-at-once-h0005" class="headerlink" title="Compute all gradients at once (h0005)"></a>Compute all gradients at once (h0005)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145351805.png" alt="image-20220215145351805" style="zoom:50%;" />

<h2 id="Back-prop-in-general-computation-graph-h0800-ToL"><a href="#Back-prop-in-general-computation-graph-h0800-ToL" class="headerlink" title="Back-prop in general computation graph(h0800)[ToL]"></a>Back-prop in general computation graph(h0800)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145612746.png" alt="image-20220215145612746"></p>
<h2 id="Automatic-Differentiation-h1346"><a href="#Automatic-Differentiation-h1346" class="headerlink" title="Automatic Differentiation(h1346)"></a>Automatic Differentiation(h1346)</h2><p><strong>Many tools can calculate automaticly</strong>.<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215151328471.png" alt="image-20220215151328471"></p>
<h2 id="Manual-Gradient-checking-Numeric-Gradient-h1900"><a href="#Manual-Gradient-checking-Numeric-Gradient-h1900" class="headerlink" title="Manual Gradient checking : Numeric Gradient(h1900)"></a>Manual Gradient checking : Numeric Gradient(h1900)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152039987.png" alt="image-20220215152039987" style="zoom:50%;" />

<h1 id="Lecture-4-Dependency-Parsing"><a href="#Lecture-4-Dependency-Parsing" class="headerlink" title="Lecture 4 Dependency Parsing"></a>Lecture 4 Dependency Parsing</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PSGIodTN3KE?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152912089.png" alt="image-20220215152912089"></p>
<h2 id="Two-views-of-linguistic-structure"><a href="#Two-views-of-linguistic-structure" class="headerlink" title="Two views of linguistic structure"></a>Two views of linguistic structure</h2><h3 id="Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331"><a href="#Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331" class="headerlink" title="Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)"></a>Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)</h3><p><strong>Phrase structure organizes words into nested constituents</strong></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155446438.png" alt="image-20220215155446438"></p>
<h3 id="Dependency-structure-1449"><a href="#Dependency-structure-1449" class="headerlink" title="Dependency structure(1449)"></a>Dependency structure(1449)</h3><p><strong>Dependency structure shows which words depend on (modify, attach to,or are arguments of)</strong></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155924838.png" alt="image-20220215155924838"></p>
<h2 id="Why-do-we-need-sentence-structure-2205"><a href="#Why-do-we-need-sentence-structure-2205" class="headerlink" title="Why do  we need sentence structure?(2205)"></a>Why do  we need sentence structure?(2205)</h2><p><strong>Can not express meaning by just one word</strong>.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215160252254.png" alt="image-20220215160252254"></p>
<h2 id="Prepositional-phrase-attachment-ambiguity-2422"><a href="#Prepositional-phrase-attachment-ambiguity-2422" class="headerlink" title="Prepositional phrase attachment ambiguity.(2422)"></a>Prepositional phrase attachment ambiguity.(2422)</h2><p>There is some sentence to show it:</p>
<h3 id="San-Jose-cops-kill-man-with-knife"><a href="#San-Jose-cops-kill-man-with-knife" class="headerlink" title="San Jose cops kill man with knife"></a>San Jose cops kill man with knife</h3><p><strong>Scientists count whales from space</strong></p>
<p><strong>The board approved [its acquisition] [by Royal Trustco Ltd.] [of Toronto] [for $27 a share] [at its monthly meeting].</strong></p>
<h2 id="Coordination-scope-ambiguity-3614"><a href="#Coordination-scope-ambiguity-3614" class="headerlink" title="Coordination scope ambiguity(3614)"></a>Coordination scope ambiguity(3614)</h2><p>**Shuttle veteran and longtime NASA executive Fred Gregory appointed to board **</p>
<p><strong>Doctor: No heart, cognitive issues</strong></p>
<h2 id="Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755"><a href="#Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755" class="headerlink" title="Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)"></a>Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)</h2><p><strong>Students get [first hand job] experience</strong> <strong>Students get first [hand job] experience</strong></p>
<h2 id="Verb-Phrase-VP-attachment-ambiguity-4404"><a href="#Verb-Phrase-VP-attachment-ambiguity-4404" class="headerlink" title="Verb Phrase(VP) attachment ambiguity(4404)"></a>Verb Phrase(VP) attachment ambiguity(4404)</h2><p>Mutilated body washes up on Rio beach to be used for Olympics beach volleyball.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163226892.png" alt="image-20220215163226892"></p>
<h2 id="Dependency-Grammar-and-Dependency-structure-4355"><a href="#Dependency-Grammar-and-Dependency-structure-4355" class="headerlink" title="Dependency Grammar and Dependency structure(4355)"></a>Dependency Grammar and Dependency structure(4355)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163439157.png" alt="image-20220215163439157"></p>
<h3 id="Will-add-a-fake-ROOT-for-handy"><a href="#Will-add-a-fake-ROOT-for-handy" class="headerlink" title="Will add a fake ROOT for handy"></a>Will add a fake ROOT for handy</h3><h2 id="Dependency-Grammar-history-4742"><a href="#Dependency-Grammar-history-4742" class="headerlink" title="Dependency Grammar history(4742)"></a>Dependency Grammar history(4742)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163821573.png" alt="image-20220215163821573"> </p>
<h2 id="The-rise-of-annotated-data-Universal-Dependency-tree-5100"><a href="#The-rise-of-annotated-data-Universal-Dependency-tree-5100" class="headerlink" title="The rise of annotated data Universal Dependency tree(5100)"></a>The rise of annotated data Universal Dependency tree(5100)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215164213166.png" alt="image-20220215164213166"></p>
<h3 id="Tree-bank-5400"><a href="#Tree-bank-5400" class="headerlink" title="Tree bank(5400)"></a>Tree bank(5400)</h3><p><strong>Its too slow to write a grammar by hand but its still worth,cause it can used in another place but not only nlp</strong> .</p>
<h2 id="how-to-build-parser-with-dependency-5738"><a href="#how-to-build-parser-with-dependency-5738" class="headerlink" title="how to build parser with dependency(5738)"></a>how to build parser with dependency(5738)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165030760.png" alt="image-20220215165030760"></p>
<h2 id="Dependency-Parsing"><a href="#Dependency-Parsing" class="headerlink" title="Dependency Parsing"></a>Dependency Parsing</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165444250.png" alt="image-20220215165444250"></p>
<h3 id="Projectivity-h0416"><a href="#Projectivity-h0416" class="headerlink" title="Projectivity(h0416)"></a>Projectivity(h0416)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165801145.png" alt="image-20220215165801145"></p>
<h2 id="Methods-of-Dependency-Parsing-h0521"><a href="#Methods-of-Dependency-Parsing-h0521" class="headerlink" title="Methods of Dependency Parsing(h0521)"></a>Methods of Dependency Parsing(h0521)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170003800.png" alt="image-20220215170003800"></p>
<h2 id="Greedy-transition-based-parsing-h0621"><a href="#Greedy-transition-based-parsing-h0621" class="headerlink" title="Greedy transition-based parsing(h0621)"></a>Greedy transition-based parsing(h0621)</h2><h2 id="Basic-transition-based-dependency-parser-h0808"><a href="#Basic-transition-based-dependency-parser-h0808" class="headerlink" title="Basic transition-based dependency parser (h0808)"></a>Basic transition-based dependency parser (h0808)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170303720.png" alt="image-20220215170303720"></p>
<p><strong>[root] I ate fish</strong></p>
<p><strong>[root I ate] fish</strong></p>
<p><strong>[root ate] fish</strong></p>
<p><strong>[root ate fish]</strong></p>
<p><strong>[root ate]</strong></p>
<p><strong>[root]</strong></p>
<h2 id="MaltParser-h1351-ToL"><a href="#MaltParser-h1351-ToL" class="headerlink" title="MaltParser(h1351)[ToL]"></a>MaltParser(h1351)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215171511327.png" alt="image-20220215171511327"></p>
<h2 id="Evaluation-of-Dependency-Parsing-h1845-ToL"><a href="#Evaluation-of-Dependency-Parsing-h1845-ToL" class="headerlink" title="Evaluation of Dependency Parsing (h1845)[ToL]"></a>Evaluation of Dependency Parsing (h1845)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215172606079.png" alt="image-20220215172606079"></p>
<h1 id="Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs"><a href="#Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs" class="headerlink" title="Lecture-5 Languages models and Recurrent Neural Networks(RNNs)"></a>Lecture-5 Languages models and Recurrent Neural Networks(RNNs)</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PLryWeHPcBs?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215173841609.png" alt="image-20220215173841609"></p>
<h2 id="A-neural-dependency-parser-0624"><a href="#A-neural-dependency-parser-0624" class="headerlink" title="A neural dependency parser(0624)"></a>A neural dependency parser(0624)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215175916431.png" alt="image-20220215175916431"></p>
<h2 id="Distributed-Representations-0945"><a href="#Distributed-Representations-0945" class="headerlink" title="Distributed Representations(0945)"></a>Distributed Representations(0945)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180234046.png" alt="image-20220215180234046##"></p>
<h2 id="Deep-Learning-Classifier-are-non-linear-classifiers-1210"><a href="#Deep-Learning-Classifier-are-non-linear-classifiers-1210" class="headerlink" title="Deep Learning Classifier are non-linear classifiers(1210)"></a>Deep Learning Classifier are non-linear classifiers(1210)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180544369.png" alt="image-20220215180544369"></p>
<p>Deep Learning Classifier’s non-linear classifiers:</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180703045.png" alt="image-20220215180703045"></p>
<h2 id="Simple-feed-forward-neural-network-multi-class-classifier-1621"><a href="#Simple-feed-forward-neural-network-multi-class-classifier-1621" class="headerlink" title="Simple feed-forward neural network multi-class classifier (1621)"></a>Simple feed-forward neural network multi-class classifier (1621)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215181359982.png" alt="image-20220215181359982"></p>
<h2 id="Neural-Dependency-Parser-Model-Architecture-1730"><a href="#Neural-Dependency-Parser-Model-Architecture-1730" class="headerlink" title="Neural Dependency Parser Model Architecture(1730)"></a>Neural Dependency Parser Model Architecture(1730)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182714531.png" alt="image-20220215182714531"></p>
<h2 id="Graph-based-dependency-parsers-2044"><a href="#Graph-based-dependency-parsers-2044" class="headerlink" title="Graph-based dependency parsers (2044)"></a>Graph-based dependency parsers (2044)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182932684.png" alt="image-20220215182932684"></p>
<h2 id="Regularization-amp-amp-Overfitting-2529"><a href="#Regularization-amp-amp-Overfitting-2529" class="headerlink" title="Regularization &amp;&amp; Overfitting (2529)"></a>Regularization &amp;&amp; Overfitting (2529)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215183327050.png" alt="image-20220215183327050"></p>
<h2 id="Dropout-3100-ToL"><a href="#Dropout-3100-ToL" class="headerlink" title="Dropout (3100)[ToL]"></a>Dropout (3100)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184016985.png" alt="image-20220215184016985"></p>
<h2 id="Vectorization-3333"><a href="#Vectorization-3333" class="headerlink" title="Vectorization(3333)"></a>Vectorization(3333)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184453079.png" alt="image-20220215184453079"></p>
<h2 id="Non-linearities-4000"><a href="#Non-linearities-4000" class="headerlink" title="Non-linearities (4000)"></a>Non-linearities (4000)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185618924.png" alt="image-20220215185618924"></p>
<h2 id="Parameter-Initialization-4357"><a href="#Parameter-Initialization-4357" class="headerlink" title="Parameter Initialization (4357)"></a>Parameter Initialization (4357)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185707615.png" alt="image-20220215185707615"></p>
<h2 id="Optimizers-4617"><a href="#Optimizers-4617" class="headerlink" title="Optimizers(4617)"></a>Optimizers(4617)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185920518.png" alt="image-20220215185920518"></p>
<h2 id="Learning-Rates-4810"><a href="#Learning-Rates-4810" class="headerlink" title="Learning Rates(4810)"></a>Learning Rates(4810)</h2><p>It can be slow as the learning  go on.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190108626.png" alt="image-20220215190108626"></p>
<h2 id="Language-Modeling-5036"><a href="#Language-Modeling-5036" class="headerlink" title="Language Modeling (5036)"></a>Language Modeling (5036)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190413343.png" alt="image-20220215190413343"></p>
<h2 id="n-gram-Language-Models-5356"><a href="#n-gram-Language-Models-5356" class="headerlink" title="n-gram Language Models(5356)"></a>n-gram Language Models(5356)</h2><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190718037.png" alt="image-20220215190718037" style="zoom: 50%;" />

<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190841180.png" alt="image-20220215190841180" style="zoom:50%;" />

<h2 id="Sparsity-Problems-5922"><a href="#Sparsity-Problems-5922" class="headerlink" title="Sparsity Problems (5922)"></a>Sparsity Problems (5922)</h2><p><em>Many situation didn’t occur so it will be zero</em></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215191735246.png" alt="image-20220215191735246"></p>
<h2 id="Storage-Problems-h0117"><a href="#Storage-Problems-h0117" class="headerlink" title="Storage Problems(h0117)"></a>Storage Problems(h0117)</h2><h2 id="How-to-build-a-neural-language-model-h0609"><a href="#How-to-build-a-neural-language-model-h0609" class="headerlink" title="How to build a neural language model(h0609)"></a>How to build a neural language model(h0609)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215192255066.png" alt="image-20220215192255066"></p>
<h2 id="A-fixed-window-neural-Language-Model-h1100"><a href="#A-fixed-window-neural-Language-Model-h1100" class="headerlink" title="A fixed-window neural Language Model(h1100)"></a>A fixed-window neural Language Model(h1100)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216103904942.png" alt="image-20220216103904942"></p>
<h2 id="Recurrent-Neural-Network-RNN-h1250"><a href="#Recurrent-Neural-Network-RNN-h1250" class="headerlink" title="Recurrent Neural Network (RNN)(h1250)"></a>Recurrent Neural Network (RNN)(h1250)</h2><p>x1 -&gt; y1</p>
<p>Wx1 x2 -&gt; y1</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216105731982.png" alt="image-20220216105731982"></p>
<h2 id="A-Simple-RNN-Language-Model-h1430"><a href="#A-Simple-RNN-Language-Model-h1430" class="headerlink" title="A Simple RNN Language Model(h1430)"></a>A Simple RNN Language Model(h1430)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110248289.png" alt="image-20220216110248289"></p>
<img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110444328.png" alt="image-20220216110444328" style="zoom: 67%;" />

<h1 id="Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks"><a href="#Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks" class="headerlink" title="Lecture 6 Simple and LSTM Recurrent Neural Networks."></a>Lecture 6 Simple and LSTM Recurrent Neural Networks.</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/0LixFSa7yts?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110620895.png" alt="image-20220216110620895"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216111222942.png" alt="image-20220216111222942"></p>
<h2 id="The-Simple-RNN-Language-Model-0310"><a href="#The-Simple-RNN-Language-Model-0310" class="headerlink" title="The Simple RNN Language Model (0310)"></a>The Simple RNN Language Model (0310)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112005817.png" alt="image-20220216112005817"></p>
<h2 id="Training-an-RNN-Language-Model-0818"><a href="#Training-an-RNN-Language-Model-0818" class="headerlink" title="Training an RNN Language Model (0818)"></a>Training an RNN Language Model (0818)</h2><p>RNN takes more time.</p>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h3><p>penalize when dont take its advise</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112357329.png" alt="image-20220216112357329"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112814935.png" alt="image-20220216112814935"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113456552.png" alt="image-20220216113456552"></p>
<p>But how do we get the answer?</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113810612.png" alt="image-20220216113810612"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216114843011.png" alt="image-20220216114843011"></p>
<h2 id="Evaluating-Language-Models-2447-ToL"><a href="#Evaluating-Language-Models-2447-ToL" class="headerlink" title="Evaluating Language Models (2447)[ToL]"></a>Evaluating Language Models (2447)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216115442761.png" alt="image-20220216115442761"></p>
<h2 id="Language-Model-is-a-system-that-predicts-the-next-word-3130"><a href="#Language-Model-is-a-system-that-predicts-the-next-word-3130" class="headerlink" title="Language Model is a  system that predicts the next word(3130)"></a>Language Model is a  system that predicts the next word(3130)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120043119.png" alt="image-20220216120043119"></p>
<h2 id="Other-use-of-RNN-3229"><a href="#Other-use-of-RNN-3229" class="headerlink" title="Other use of RNN(3229)"></a>Other use of RNN(3229)</h2><h3 id="Tag-for-word"><a href="#Tag-for-word" class="headerlink" title="Tag for word"></a>Tag for word</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120154220.png" alt="image-20220216120154220"></p>
<h3 id="Used-for-classification-3420"><a href="#Used-for-classification-3420" class="headerlink" title="Used for classification(3420)"></a>Used for classification(3420)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120331039.png" alt="image-20220216120331039"></p>
<h3 id="Used-to-Language-encoder-module-3500"><a href="#Used-to-Language-encoder-module-3500" class="headerlink" title="Used to Language encoder module (3500)"></a>Used to Language encoder module (3500)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120515954.png" alt="image-20220216120515954"></p>
<h3 id="Used-to-generate-text-3600"><a href="#Used-to-generate-text-3600" class="headerlink" title="Used to generate text (3600)"></a>Used to generate text (3600)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120602654.png" alt="image-20220216120602654"></p>
<h2 id="Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT"><a href="#Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT" class="headerlink" title="Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]"></a>Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120728010.png" alt="image-20220216120728010"></p>
<p>[ToL]</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120836593.png" alt="image-20220216120836593"></p>
<h3 id="Why-This-is-a-problem-4400"><a href="#Why-This-is-a-problem-4400" class="headerlink" title="Why This is a  problem (4400)"></a>Why This is a  problem (4400)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121352667.png" alt="image-20220216121352667"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121537213.png" alt="image-20220216121537213"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121801767.png" alt="image-20220216121801767"></p>
<p>We can give him a limit.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121845504.png" alt="image-20220216121845504"></p>
<h2 id="Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL"><a href="#Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL" class="headerlink" title="Long Short Term Memory RNNS(LSTMS)(5000)[ToL]"></a>Long Short Term Memory RNNS(LSTMS)(5000)[ToL]</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216142509947.png" alt="image-20220216142509947"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143131901.png" alt="image-20220216143131901"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143953637.png" alt="image-20220216143953637"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216145201781.png" alt="image-20220216145201781"></p>
<h2 id="Bidirectional-RNN-h2000"><a href="#Bidirectional-RNN-h2000" class="headerlink" title="Bidirectional RNN (h2000)"></a>Bidirectional RNN (h2000)</h2><p>We need information from the word after</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150058982.png" alt="image-20220216150058982"></p>
<h1 id="Lecture-7-Translation-Seq2Seq-Attention"><a href="#Lecture-7-Translation-Seq2Seq-Attention" class="headerlink" title="Lecture-7 Translation, Seq2Seq, Attention"></a>Lecture-7 Translation, Seq2Seq, Attention</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/wzfWHP6SXxY?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150827060.png" alt="image-20220216150827060"></p>
<h2 id="Machine-Translation-0245"><a href="#Machine-Translation-0245" class="headerlink" title="Machine Translation(0245)"></a>Machine Translation(0245)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216152638415.png" alt="image-20220216152638415"></p>
<h3 id="What-do-you-need-1200"><a href="#What-do-you-need-1200" class="headerlink" title="What do you need (1200)"></a>What do you need (1200)</h3><p><strong>you need parallel corpus,Then you need alignment</strong></p>
<h2 id="Decoding-for-SMT-1748"><a href="#Decoding-for-SMT-1748" class="headerlink" title="Decoding for SMT(1748)"></a>Decoding for SMT(1748)</h2><p>Try many possible sequences.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216153938352.png" alt="image-20220216153938352"></p>
<h2 id="What-is-Neural-Machine-Translation-NMT-2130"><a href="#What-is-Neural-Machine-Translation-NMT-2130" class="headerlink" title="What is Neural Machine Translation(NMT)(2130)"></a>What is Neural Machine Translation(NMT)(2130)</h2><p>Neural Machine Translation(NMT) is a way to do Machine Translation with a single end-to-end neural net work.</p>
<p>The neural network architecture is called sequence-to-sequence model(aka seq2seq) and it involves RNNs</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216154743629.png" alt="image-20220216154743629"></p>
<h2 id="Seq2seq-is-more-than-MT-2600"><a href="#Seq2seq-is-more-than-MT-2600" class="headerlink" title="Seq2seq is more than MT(2600)"></a>Seq2seq is more than MT(2600)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216155851923.png" alt="image-20220216155851923"></p>
<h2 id="2732-ToL"><a href="#2732-ToL" class="headerlink" title="(2732)[ToL]"></a>(2732)[ToL]</h2><h2 id="Multi-layer-RNNs-3323"><a href="#Multi-layer-RNNs-3323" class="headerlink" title="Multi-layer RNNs(3323)"></a>Multi-layer RNNs(3323)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216160937711.png" alt="image-20220216160937711"></p>
<p>Lower-level basic meaning</p>
<p>Higher-level overall meaning</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161044182.png" alt="image-20220216161044182"></p>
<h2 id="Greedy-decoding-4000"><a href="#Greedy-decoding-4000" class="headerlink" title="Greedy decoding(4000)"></a>Greedy decoding(4000)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161822091.png" alt="image-20220216161822091"></p>
<h2 id="Exhaustive-search-decoding-4200"><a href="#Exhaustive-search-decoding-4200" class="headerlink" title="Exhaustive search decoding(4200)"></a>Exhaustive search decoding(4200)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161859032.png" alt="image-20220216161859032"></p>
<h2 id="beam-search-decoding-4400"><a href="#beam-search-decoding-4400" class="headerlink" title="beam search decoding(4400)"></a>beam search decoding(4400)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162108945.png" alt="image-20220216162108945"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162654834.png" alt="image-20220216162654834"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163345111.png" alt="image-20220216163345111"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163610037.png" alt="image-20220216163610037"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163703962.png" alt="image-20220216163703962"></p>
<h2 id="How-do-we-evaluate-Machine-Translation-5550"><a href="#How-do-we-evaluate-Machine-Translation-5550" class="headerlink" title="How do we evaluate Machine Translation(5550)"></a>How do we evaluate Machine Translation(5550)</h2><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163928786.png" alt="image-20220216163928786"></p>
<h2 id="NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000"><a href="#NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000" class="headerlink" title="NMT perhaps the biggest success story of NLP Deep Learning(h00000)"></a>NMT perhaps the biggest success story of NLP Deep Learning(h00000)</h2><h2 id="Attention-h1300"><a href="#Attention-h1300" class="headerlink" title="Attention(h1300)"></a>Attention(h1300)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165707869.png" alt="image-20220216165707869"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165937488.png" alt="image-20220216165937488"></p>
<h1 id="Lecture-8-Final-Projects-Practical-Tips"><a href="#Lecture-8-Final-Projects-Practical-Tips" class="headerlink" title="Lecture 8  Final Projects; Practical Tips"></a>Lecture 8  Final Projects; Practical Tips</h1><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216170053324.png" alt="image-20220216170053324"></p>
<h2 id="Sequence-to-Sequence-with-attention-0235"><a href="#Sequence-to-Sequence-with-attention-0235" class="headerlink" title="Sequence to Sequence with attention(0235)"></a>Sequence to Sequence with attention(0235)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216173442920.png" alt="image-20220216173442920"></p>
<h2 id="Attention-in-equations-0800"><a href="#Attention-in-equations-0800" class="headerlink" title="Attention: in equations(0800)"></a>Attention: in equations(0800)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174203323.png" alt="image-20220216174203323"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174430719.png" alt="image-20220216174430719"></p>
<h2 id="there-are-several-attention-variants-1500"><a href="#there-are-several-attention-variants-1500" class="headerlink" title="there are several attention variants(1500)"></a>there are several attention variants(1500)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174747222.png" alt="image-20220216174747222"></p>
<h2 id="Attention-is-a-general-Deep-Learning-technique-2240"><a href="#Attention-is-a-general-Deep-Learning-technique-2240" class="headerlink" title="Attention is a general Deep Learning technique(2240)"></a>Attention is a general Deep Learning technique(2240)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216175744427.png" alt="image-20220216175744427"></p>
<h2 id="Final-Project-3000"><a href="#Final-Project-3000" class="headerlink" title="Final Project(3000)"></a>Final Project(3000)</h2><h1 id="Lecture-9-Self-Attention-and-Transformers"><a href="#Lecture-9-Self-Attention-and-Transformers" class="headerlink" title="Lecture-9  Self- Attention and Transformers"></a>Lecture-9  Self- Attention and Transformers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/ptuGllU5SQQ?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Issues-with-recurrent-models-0434"><a href="#Issues-with-recurrent-models-0434" class="headerlink" title="Issues with recurrent models (0434)"></a>Issues with recurrent models (0434)</h2><h3 id="Linear-interaction-distance"><a href="#Linear-interaction-distance" class="headerlink" title="Linear interaction distance"></a>Linear interaction distance</h3><p>Sometimes it is too far too learn from the words.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184249889.png" alt="image-20220216184249889"></p>
<h3 id="Lack-of-parallelizability-0723"><a href="#Lack-of-parallelizability-0723" class="headerlink" title="Lack of parallelizability(0723)"></a>Lack of parallelizability(0723)</h3><p>GPU can count parallelizable but RNN lacks that.</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184542395.png" alt="image-20220216184542395"></p>
<h2 id="If-not-recurrence"><a href="#If-not-recurrence" class="headerlink" title="If not recurrence"></a>If not recurrence</h2><h3 id="Word-window-models-aggregate-local-contexts-1031"><a href="#Word-window-models-aggregate-local-contexts-1031" class="headerlink" title="Word window models aggregate local contexts (1031)"></a>Word window models aggregate local contexts (1031)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113153381.png" alt="image-20220217113153381"></p>
<h3 id="Attention-1406"><a href="#Attention-1406" class="headerlink" title="Attention(1406)"></a>Attention(1406)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113459930.png" alt="image-20220217113459930"></p>
<h2 id="Self-Attention-1638"><a href="#Self-Attention-1638" class="headerlink" title="Self-Attention(1638)"></a>Self-Attention(1638)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217114733959.png" alt="image-20220217114733959"></p>
<h2 id="Self-attention-as-an-nlp-building-block-2222"><a href="#Self-attention-as-an-nlp-building-block-2222" class="headerlink" title="Self-attention as an nlp building block(2222)"></a>Self-attention as an nlp building block(2222)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217115247771.png" alt="image-20220217115247771"></p>
<h2 id="Fix-the-first-self-attention-problem"><a href="#Fix-the-first-self-attention-problem" class="headerlink" title="Fix the first self-attention problem"></a>Fix the first self-attention problem</h2><h3 id="sequence-order-2423"><a href="#sequence-order-2423" class="headerlink" title="sequence order (2423)"></a>sequence order (2423)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120240889.png" alt="image-20220217120240889"></p>
<h4 id="Position-representation-vector-through-sinusoids-2624"><a href="#Position-representation-vector-through-sinusoids-2624" class="headerlink" title="Position representation vector through sinusoids(2624)"></a>Position representation vector through sinusoids(2624)</h4><h5 id="Sinusoidal-position-representations-2730"><a href="#Sinusoidal-position-representations-2730" class="headerlink" title="Sinusoidal position representations(2730)"></a>Sinusoidal position representations(2730)</h5><h5 id="Position-representation-vector-from-scratch-2830"><a href="#Position-representation-vector-from-scratch-2830" class="headerlink" title="Position representation vector from scratch(2830)"></a>Position representation vector from scratch(2830)</h5><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120619459.png" alt="image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459"></p>
<h3 id="Adding-nonlinearities-in-self-attention-2953"><a href="#Adding-nonlinearities-in-self-attention-2953" class="headerlink" title="Adding nonlinearities in self-attention(2953)"></a>Adding nonlinearities in self-attention(2953)</h3><h2 id="Barriers-and-solutions-for-Self-Attention-as-building-block-2945"><a href="#Barriers-and-solutions-for-Self-Attention-as-building-block-2945" class="headerlink" title="Barriers and solutions for Self-Attention as building block(2945)"></a>Barriers and solutions for Self-Attention as building block(2945)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185604333.png" alt="image-20220221185604333"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185720186.png" alt="image-20220221185720186"></p>
<p>(3040)</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185116405.png" alt="image-20220221185116405"></p>
<p>(3428)</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185521157.png" alt="image-20220221185521157"></p>
<h2 id="The-transformer-encoder-decoder-3638"><a href="#The-transformer-encoder-decoder-3638" class="headerlink" title="The transformer encoder-decoder(3638)"></a>The transformer encoder-decoder(3638)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185909509.png" alt="image-20220221185909509"></p>
<p>[ToL]</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190102912.png" alt="image-20220221190102912"></p>
<h3 id="key-query-value-4000"><a href="#key-query-value-4000" class="headerlink" title="key query value(4000)"></a>key query value(4000)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190217303.png" alt="image-20220221190217303"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190523039.png" alt="image-20220221190523039"></p>
<h3 id="Multi-headed-attention-4322"><a href="#Multi-headed-attention-4322" class="headerlink" title="Multi-headed attention (4322)"></a>Multi-headed attention (4322)</h3><p>(4450)</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190908268.png" alt="image-20220221190908268"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190957705.png" alt="image-20220221190957705"></p>
<h2 id="Residual-connections-4723"><a href="#Residual-connections-4723" class="headerlink" title="Residual connections(4723)"></a>Residual connections(4723)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191310743.png" alt="image-20220221191310743"></p>
<h2 id="Layer-normalization-5045"><a href="#Layer-normalization-5045" class="headerlink" title="Layer normalization(5045)"></a>Layer normalization(5045)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191749317.png" alt="image-20220221191749317"></p>
<h2 id="Scaled-fot-product-5415"><a href="#Scaled-fot-product-5415" class="headerlink" title="Scaled fot product(5415)"></a>Scaled fot product(5415)</h2><h1 id="Lecture-10-Transformers-and-Pretraining"><a href="#Lecture-10-Transformers-and-Pretraining" class="headerlink" title="Lecture 10 - Transformers and Pretraining"></a>Lecture 10 - Transformers and Pretraining</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/j9AcEI98C0o?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224134741859.png" alt="image-20220224134741859"></p>
<h2 id="Word-structure-and-subword-models-0300"><a href="#Word-structure-and-subword-models-0300" class="headerlink" title="Word structure and subword models(0300)"></a>Word structure and subword models(0300)</h2><p>transform transformerify</p>
<p>taaaasty</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224135937734.png" alt="image-20220224135937734"></p>
<h2 id="The-byte-pair-encoding-0659"><a href="#The-byte-pair-encoding-0659" class="headerlink" title="The byte-pair encoding(0659)"></a>The byte-pair encoding(0659)</h2><p>Subwords model learn the structure of word. The byte-pair between it and  dont learn structure.</p>
<p>(0943)</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145251761.png" alt="image-20220224145251761"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145105071.png" alt="image-20220224145105071"></p>
<h2 id="Motivating-word-meaning-and-context-1556"><a href="#Motivating-word-meaning-and-context-1556" class="headerlink" title="Motivating word meaning and context(1556)"></a>Motivating word meaning and context(1556)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145804570.png" alt="image-20220224145804570"></p>
<h2 id="Pretraining-whole-models-2000"><a href="#Pretraining-whole-models-2000" class="headerlink" title="Pretraining whole models(2000)"></a>Pretraining whole models(2000)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145922233.png" alt="image-20220224145922233"></p>
<p>Wordv2vec dont consider context but we can use LSTM to achieve that.</p>
<p><strong>Mask some data and pretrain the model with them.</strong></p>
<h2 id="this-model-haven’t-met-overfitting-now-you-can-save-some-data-to-test-it-2811"><a href="#this-model-haven’t-met-overfitting-now-you-can-save-some-data-to-test-it-2811" class="headerlink" title="this model haven’t met overfitting now, you can save some data to test it.(2811)"></a>this model haven’t met overfitting now, you can save some data to test it.(2811)</h2><h2 id="transformers-for-encoding-and-decoding-3030"><a href="#transformers-for-encoding-and-decoding-3030" class="headerlink" title="transformers for encoding and decoding (3030)"></a>transformers for encoding and decoding (3030)</h2><h2 id="Pretraining-through-language-modeling-3400"><a href="#Pretraining-through-language-modeling-3400" class="headerlink" title="Pretraining through language modeling(3400)"></a>Pretraining through language modeling(3400)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151624946.png" alt="image-20220224151624946"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151950866.png" alt="image-20220224151950866"></p>
<h2 id="Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740"><a href="#Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740" class="headerlink" title="Stochastic gradient descent and pretrain&#x2F;finetune(3740)"></a>Stochastic gradient descent and pretrain&#x2F;finetune(3740)</h2><h2 id="Model-pretraining-has-three-ways-4021"><a href="#Model-pretraining-has-three-ways-4021" class="headerlink" title="Model pretraining has three ways (4021)"></a>Model pretraining has three ways (4021)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152730308.png" alt="image-20220224152730308"></p>
<p><strong>Decoder can see the history, the Encoder can also the future.</strong></p>
<p>Encoder-Decoder maybe is the better.</p>
<h3 id="Decoder-4300"><a href="#Decoder-4300" class="headerlink" title="Decoder(4300)"></a>Decoder(4300)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152938046.png" alt="image-20220224152938046"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153716173.png" alt="image-20220224153716173"></p>
<h2 id="Generative-Pretrained-Transformer-GPT-4818"><a href="#Generative-Pretrained-Transformer-GPT-4818" class="headerlink" title="Generative Pretrained Transformer(GPT) (4818)"></a>Generative Pretrained Transformer(GPT) (4818)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153928012.png" alt="image-20220224153928012"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154243901.png" alt="image-20220224154243901"></p>
<h2 id="GPT2-5400"><a href="#GPT2-5400" class="headerlink" title="GPT2(5400)"></a>GPT2(5400)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154759716.png" alt="image-20220224154759716"></p>
<h2 id="Pretraining-Encoding-5545"><a href="#Pretraining-Encoding-5545" class="headerlink" title="Pretraining Encoding(5545)"></a>Pretraining Encoding(5545)</h2><h3 id="Bert-5654"><a href="#Bert-5654" class="headerlink" title="(Bert)(5654)"></a>(Bert)(5654)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241654601.png" alt="image-20220224165457421"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241652887.png" alt="image-20220224165235710"></p>
<p><strong>Bert will mask some words, ask what have I mask</strong></p>
<h2 id="Bidirectional-encoder-representations-from-transformers-h0100"><a href="#Bidirectional-encoder-representations-from-transformers-h0100" class="headerlink" title="Bidirectional encoder representations from transformers(h0100)"></a>Bidirectional encoder representations from transformers(h0100)</h2><p>[ToL]</p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241703566.png" alt="image-20220224170312332"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241704798.png" alt="image-20220224170413603"></p>
<h2 id="Limitations-of-pretrained-encoders-h0900"><a href="#Limitations-of-pretrained-encoders-h0900" class="headerlink" title="Limitations of pretrained encoders(h0900)"></a>Limitations of pretrained encoders(h0900)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241712192.png" alt="image-20220224171252011"></p>
<h2 id="Extensions-of-BERT-h1000"><a href="#Extensions-of-BERT-h1000" class="headerlink" title="Extensions of BERT(h1000)"></a>Extensions of BERT(h1000)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241714640.png" alt="image-20220224171454465"></p>
<h2 id="Pretraining-Encoder-Decoder-h1200"><a href="#Pretraining-Encoder-Decoder-h1200" class="headerlink" title="Pretraining Encoder-Decoder (h1200)"></a>Pretraining Encoder-Decoder (h1200)</h2><h3 id="T5-h1500"><a href="#T5-h1500" class="headerlink" title="T5(h1500)"></a>T5(h1500)</h3><p><strong>The model even dont know how many words are masked</strong></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241723663.png" alt="image-20220224172344435"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241725878.png" alt="image-20220224172541657"></p>
<p><strong>In the pretraining the model learned a lot, but it is not always good</strong></p>
<h2 id="GPT3-h1800"><a href="#GPT3-h1800" class="headerlink" title="GPT3(h1800)"></a>GPT3(h1800)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241727692.png" alt="image-20220224172754530"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241729302.png" alt="image-20220224172922203"></p>
<h2 id="Lecture-11-Question-Answering"><a href="#Lecture-11-Question-Answering" class="headerlink" title="Lecture 11 Question Answering"></a>Lecture 11 Question Answering</h2><iframe width="1217" height="685" src="https://www.youtube.com/embed/NcqfHa0_YmU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241741555.png" alt="image-20220224174146459"></p>
<h2 id="What-is-question-answering-0414"><a href="#What-is-question-answering-0414" class="headerlink" title="What is question answering(0414)"></a>What is question answering(0414)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241752253.png" alt="image-20220224175257101"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241753477.png" alt="image-20220224175334367"></p>
<p><strong>There are lots of practical applications(0629)</strong></p>
<h2 id="Beyond-textual-QA-problems-1100"><a href="#Beyond-textual-QA-problems-1100" class="headerlink" title="Beyond textual QA problems(1100)"></a>Beyond textual QA problems(1100)</h2><h2 id="Reading-comprehension-1223"><a href="#Reading-comprehension-1223" class="headerlink" title="Reading comprehension(1223)"></a>Reading comprehension(1223)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241801824.png" alt="image-20220224180147691"></p>
<p><strong>They are useful for many practical applications</strong></p>
<p>Reading comprehension is an important tested for evaluating how well computer systems understand human language</p>
<h2 id="Standord-question-answering-dataset-1815"><a href="#Standord-question-answering-dataset-1815" class="headerlink" title="Standord question answering dataset (1815)"></a>Standord question answering dataset (1815)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241808087.png" alt="image-20220224180828915"></p>
<h2 id="Neural-models-for-reading-comprehension-2428"><a href="#Neural-models-for-reading-comprehension-2428" class="headerlink" title="Neural models for reading comprehension(2428)"></a>Neural models for reading comprehension(2428)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241814453.png" alt="image-20220224181443258"></p>
<h2 id="LSTM-based-vs-BERT-models-2713"><a href="#LSTM-based-vs-BERT-models-2713" class="headerlink" title="LSTM-based vs BERT models (2713)"></a>LSTM-based vs BERT models (2713)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241815904.png" alt="image-20220224181551779"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818432.png" alt="image-20220224181815290"></p>
<h2 id="BiDAF-3200"><a href="#BiDAF-3200" class="headerlink" title="BiDAF(3200)"></a>BiDAF(3200)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818897.png" alt="image-20220224181853733"></p>
<h3 id="Encoding-3200"><a href="#Encoding-3200" class="headerlink" title="Encoding(3200)"></a>Encoding(3200)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241821498.png" alt="image-20220224182135349"></p>
<h3 id="Attention-3400"><a href="#Attention-3400" class="headerlink" title="Attention(3400)"></a>Attention(3400)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241824459.png" alt="image-20220224182405343"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241829033.png" alt="image-20220224182904883"></p>
<h3 id="Modeling-and-output-layers-4640"><a href="#Modeling-and-output-layers-4640" class="headerlink" title="Modeling and output layers(4640)"></a>Modeling and output layers(4640)</h3><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241836707.png" alt="image-20220224183615556"></p>
<p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241838035.png" alt="image-20220224183819872"></p>
<h2 id="BERT-for-reading-comprehension-5227"><a href="#BERT-for-reading-comprehension-5227" class="headerlink" title="BERT for reading comprehension (5227)"></a>BERT for reading comprehension (5227)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241840230.png" alt="image-20220224184028029"></p>
<h2 id="Comparisons-between-BiDAF-and-BERT-models-2734"><a href="#Comparisons-between-BiDAF-and-BERT-models-2734" class="headerlink" title="Comparisons between BiDAF and BERT models(2734)"></a>Comparisons between BiDAF and BERT models(2734)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241851401.png" alt="image-20220224185118280"></p>
<h2 id="Can-we-design-better-pre-training-objectives-h0000"><a href="#Can-we-design-better-pre-training-objectives-h0000" class="headerlink" title="Can we design better pre-training objectives(h0000)"></a>Can we design better pre-training objectives(h0000)</h2><p><img data-src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241855709.png" alt="image-20220224185550578"></p>
<h2 id="open-domain-question-answering-h1000"><a href="#open-domain-question-answering-h1000" class="headerlink" title="open domain question answering(h1000)"></a>open domain question answering(h1000)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251049797.png" alt="image-20220225104946631"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241912138.png" alt="image-20220224191246022"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251053842.png" alt="image-20220225105306708"></p>
<h2 id="DPR-H1400"><a href="#DPR-H1400" class="headerlink" title="DPR(H1400)"></a>DPR(H1400)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241926002.png" alt="image-20220224192658862"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251056150.png" alt="image-20220225105652971"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251057843.png" alt="image-20220225105747670"></p>
<h2 id="DensePhrase-Demo-h1800"><a href="#DensePhrase-Demo-h1800" class="headerlink" title="DensePhrase:Demo(h1800)"></a>DensePhrase:Demo(h1800)</h2><h1 id="Lecture-12-Natural-Language-Generation-ToL"><a href="#Lecture-12-Natural-Language-Generation-ToL" class="headerlink" title="Lecture 12 - Natural Language Generation[ToL]"></a>Lecture 12 - Natural Language Generation[ToL]</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/1uMo8olr5ng?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011431487.png" alt="image-20220301143159380"></p>
<h2 id="What-is-neural-language-generation-0300"><a href="#What-is-neural-language-generation-0300" class="headerlink" title="What is neural language generation?(0300)"></a>What is neural language generation?(0300)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011424191.png" alt="image-20220301142422083"></p>
<p><strong>Mache Translate</strong></p>
<p><strong>Dialogue Systems</strong> &#x2F;&#x2F;siri</p>
<p><strong>Summarization</strong></p>
<p><strong>Visual Description</strong></p>
<p><strong>Creative Generation</strong> &#x2F;&#x2F;story</p>
<h2 id="Components-of-NLG-Systems-0845"><a href="#Components-of-NLG-Systems-0845" class="headerlink" title="Components of NLG Systems(0845)"></a>Components of NLG Systems(0845)</h2><h3 id="Basic-of-natural-language-generation-0916"><a href="#Basic-of-natural-language-generation-0916" class="headerlink" title="Basic of natural language generation(0916)"></a>Basic of natural language generation(0916)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011433316.png" alt="image-20220301143317131"></p>
<h3 id="A-look-at-a-single-step-1024"><a href="#A-look-at-a-single-step-1024" class="headerlink" title="A look at a single step(1024)"></a>A look at a single step(1024)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011434716.png" alt="image-20220301143429583"></p>
<h3 id="then-select-and-train-1115"><a href="#then-select-and-train-1115" class="headerlink" title="then  select and train(1115)"></a>then  select and train(1115)</h3><p>teacher forcing need to be leaned</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011436047.png" alt="image-20220301143650876"></p>
<h2 id="Decoding-1317"><a href="#Decoding-1317" class="headerlink" title="Decoding(1317)"></a>Decoding(1317)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439775.png" alt="image-20220301143923558"></p>
<h3 id="Greedy-methods-1432"><a href="#Greedy-methods-1432" class="headerlink" title="Greedy methods(1432)"></a>Greedy methods(1432)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439087.png" alt="image-20220301143958990"></p>
<h3 id="Greedy-methods-get-repetitive-1545"><a href="#Greedy-methods-get-repetitive-1545" class="headerlink" title="Greedy methods get repetitive(1545)"></a>Greedy methods get repetitive(1545)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011441769.png" alt="image-20220301144123549"></p>
<h3 id="why-do-repetition-happen-1613"><a href="#why-do-repetition-happen-1613" class="headerlink" title="why do repetition happen(1613)"></a>why do repetition happen(1613)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011442409.png" alt="image-20220301144237210"></p>
<h3 id="How-can-we-reduce-repetition-1824-ToL"><a href="#How-can-we-reduce-repetition-1824-ToL" class="headerlink" title="How can we reduce repetition (1824)[ToL]"></a>How can we reduce repetition (1824)[ToL]</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011445898.png" alt="image-20220301144518763"></p>
<h3 id="People-is-not-always-choose-the-greedy-methods-1930"><a href="#People-is-not-always-choose-the-greedy-methods-1930" class="headerlink" title="People is not always choose the greedy methods(1930)"></a>People is not always choose the greedy methods(1930)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011446786.png" alt="image-20220301144630546"></p>
<h3 id="Time-to-get-random-Sampling-2047"><a href="#Time-to-get-random-Sampling-2047" class="headerlink" title="Time to get random: Sampling(2047)"></a>Time to get random: Sampling(2047)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011447561.png" alt="image-20220301144729442"></p>
<h3 id="Decoding-Top-k-sampling-2100"><a href="#Decoding-Top-k-sampling-2100" class="headerlink" title="Decoding : Top-k sampling(2100)"></a>Decoding : Top-k sampling(2100)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450298.png" alt="image-20220301145000174"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450273.png" alt="image-20220301145018125"></p>
<h3 id="Issues-with-Top-k-sampling-2339"><a href="#Issues-with-Top-k-sampling-2339" class="headerlink" title="Issues with Top-k sampling(2339)"></a>Issues with Top-k sampling(2339)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011451093.png" alt="image-20220301145153941"></p>
<h3 id="Decoding-Top-p-nucleus-sampling-2421"><a href="#Decoding-Top-p-nucleus-sampling-2421" class="headerlink" title="Decoding: Top-p(nucleus)sampling(2421)"></a>Decoding: Top-p(nucleus)sampling(2421)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011452969.png" alt="image-20220301145243854"></p>
<h3 id="Scaling-randomness-Softmax-temperature-2500-ToL"><a href="#Scaling-randomness-Softmax-temperature-2500-ToL" class="headerlink" title="Scaling randomness: Softmax temperature (2500)[ToL]"></a>Scaling randomness: Softmax temperature (2500)[ToL]</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011458368.png" alt="image-20220301145837161"></p>
<h3 id="improving-decoding-re-balancing-distributions-2710"><a href="#improving-decoding-re-balancing-distributions-2710" class="headerlink" title="improving decoding: re-balancing distributions(2710)"></a>improving decoding: re-balancing distributions(2710)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011500149.png" alt="image-20220301150002936"></p>
<h3 id="Backpropagation-based-distribution-re-balancing-3027"><a href="#Backpropagation-based-distribution-re-balancing-3027" class="headerlink" title="Backpropagation-based distribution re-balancing(3027)"></a>Backpropagation-based distribution re-balancing(3027)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011506509.png" alt="image-20220301150637319"></p>
<h3 id="Improving-Decoding-Re-ranking-3300-ToL"><a href="#Improving-Decoding-Re-ranking-3300-ToL" class="headerlink" title="Improving Decoding: Re-ranking(3300)[ToL]"></a>Improving Decoding: Re-ranking(3300)[ToL]</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011511660.png" alt="image-20220301151136510"></p>
<h3 id="Decoding-Takeaways-3540"><a href="#Decoding-Takeaways-3540" class="headerlink" title="Decoding: Takeaways(3540)"></a>Decoding: Takeaways(3540)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011512124.png" alt="image-20220301151258962"></p>
<h2 id="Training-NLG-models-4114"><a href="#Training-NLG-models-4114" class="headerlink" title="Training  NLG models(4114)"></a>Training  NLG models(4114)</h2><h3 id="Maximum-Likelihood-Training-4200"><a href="#Maximum-Likelihood-Training-4200" class="headerlink" title="Maximum Likelihood Training(4200)"></a>Maximum Likelihood Training(4200)</h3><p><strong>Are greedy decoders bad because of how they’re trained?</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011521846.png" alt="image-20220301152118621"></p>
<h3 id="Unlikelihood-Training-4427-ToL"><a href="#Unlikelihood-Training-4427-ToL" class="headerlink" title="Unlikelihood Training(4427)[ToL]"></a>Unlikelihood Training(4427)[ToL]</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011535301.png" alt="image-20220301153527149"></p>
<h3 id="Exposure-Bias-4513-ToL"><a href="#Exposure-Bias-4513-ToL" class="headerlink" title="Exposure Bias(4513)[ToL]"></a>Exposure Bias(4513)[ToL]</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011536542.png" alt="image-20220301153610391"></p>
<h3 id="Exposure-Bias-Solutions-4645"><a href="#Exposure-Bias-Solutions-4645" class="headerlink" title="Exposure Bias Solutions(4645)"></a>Exposure Bias Solutions(4645)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011537922.png" alt="image-20220301153742775"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539222.png" alt="image-20220301153907117"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539740.png" alt="image-20220301153919593"></p>
<h3 id="Reinforce-Basics-4900"><a href="#Reinforce-Basics-4900" class="headerlink" title="Reinforce Basics(4900)"></a>Reinforce Basics(4900)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011540129.png" alt="image-20220301154050890"></p>
<h3 id="Reward-Estimation-5020"><a href="#Reward-Estimation-5020" class="headerlink" title="Reward Estimation(5020)"></a>Reward Estimation(5020)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542624.png" alt="image-20220301154205522"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542000.png" alt="image-20220301154243893"></p>
<h3 id="reinforce’s-dark-side-5300"><a href="#reinforce’s-dark-side-5300" class="headerlink" title="reinforce’s dark side(5300)"></a>reinforce’s dark side(5300)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011544880.png" alt="image-20220301154452756"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011545691.png" alt="image-20220301154547630"></p>
<h3 id="Training-Takeways-5423"><a href="#Training-Takeways-5423" class="headerlink" title="Training: Takeways(5423)"></a>Training: Takeways(5423)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011547174.png" alt="image-20220301154732991"></p>
<h2 id="Evaluating-NLG-Systems-5613"><a href="#Evaluating-NLG-Systems-5613" class="headerlink" title="Evaluating NLG Systems(5613)"></a>Evaluating NLG Systems(5613)</h2><h2 id="Types-of-evaluation-methods-for-text-generation-5734"><a href="#Types-of-evaluation-methods-for-text-generation-5734" class="headerlink" title="Types of evaluation methods for text generation(5734)"></a>Types of evaluation methods for text generation(5734)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011557750.png" alt="image-20220301155705613"></p>
<h3 id="Content-Overlap-metrics-5800"><a href="#Content-Overlap-metrics-5800" class="headerlink" title="Content Overlap metrics(5800)"></a>Content Overlap metrics(5800)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011559304.png" alt="image-20220301155931178"></p>
<h3 id="A-simple-failure-case-5900"><a href="#A-simple-failure-case-5900" class="headerlink" title="A simple failure case(5900)"></a>A simple failure case(5900)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011600766.png" alt="image-20220301160050567"></p>
<h3 id="Semantic-overlap-metrics-h0100"><a href="#Semantic-overlap-metrics-h0100" class="headerlink" title="Semantic overlap metrics(h0100)"></a>Semantic overlap metrics(h0100)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011603407.png" alt="image-20220301160319080"></p>
<h3 id="Model-based-metrics-h0120"><a href="#Model-based-metrics-h0120" class="headerlink" title="Model-based metrics(h0120)"></a>Model-based metrics(h0120)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011604213.png" alt="image-20220301160406112"></p>
<h4 id="word-distance-functions-h0234"><a href="#word-distance-functions-h0234" class="headerlink" title="word distance functions(h0234)"></a>word distance functions(h0234)</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605672.png" alt="image-20220301160511479"></p>
<h4 id="Beyond-word-matching-h0350"><a href="#Beyond-word-matching-h0350" class="headerlink" title="Beyond word matching(h0350)"></a>Beyond word matching(h0350)</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605432.png" alt="image-20220301160556251"></p>
<h3 id="Human-evaluations-h0433"><a href="#Human-evaluations-h0433" class="headerlink" title="Human evaluations(h0433)"></a>Human evaluations(h0433)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011606672.png" alt="image-20220301160658568"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011607851.png" alt="image-20220301160747509"></p>
<h4 id="Issues-h0700"><a href="#Issues-h0700" class="headerlink" title="Issues(h0700)"></a>Issues(h0700)</h4><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011609267.png" alt="image-20220301160937146"></p>
<h3 id="Takeways-h0912"><a href="#Takeways-h0912" class="headerlink" title="Takeways(h0912)"></a>Takeways(h0912)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011614202.png" alt="image-20220301161428035"></p>
<h2 id="Ethical-Considerations-h1025"><a href="#Ethical-Considerations-h1025" class="headerlink" title="Ethical Considerations(h1025)"></a>Ethical Considerations(h1025)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011615331.png" alt="image-20220301161515113"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011616579.png" alt="image-20220301161639415"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011617673.png" alt="image-20220301161723483"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011618324.png" alt="image-20220301161839135"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011619216.png" alt="image-20220301161931109"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011621427.png" alt="image-20220301162101280"></p>
<h1 id="Lecture-13-Coreference-Resolution"><a href="#Lecture-13-Coreference-Resolution" class="headerlink" title="Lecture 13 - Coreference Resolution"></a>Lecture 13 - Coreference Resolution</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/FFRnDRcbQQU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011625743.png" alt="image-20220301162522611"></p>
<h2 id="What-is-Coreference-Resolution-0604"><a href="#What-is-Coreference-Resolution-0604" class="headerlink" title="What is Coreference Resolution?(0604)"></a>What is Coreference Resolution?(0604)</h2><p><strong>Identify all mentions that refer to the same entity in the world</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011654767.png" alt="image-20220301165446496"></p>
<h2 id="Applications-1712"><a href="#Applications-1712" class="headerlink" title="Applications (1712)"></a>Applications (1712)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011656858.png" alt="image-20220301165651721"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011658422.png" alt="image-20220301165822337"></p>
<h2 id="Coreference-Resolution-in-Two-steps-1947"><a href="#Coreference-Resolution-in-Two-steps-1947" class="headerlink" title="Coreference Resolution in Two steps(1947)"></a>Coreference Resolution in Two steps(1947)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011659852.png" alt="image-20220301165948737"></p>
<h2 id="Mention-Detection-2049"><a href="#Mention-Detection-2049" class="headerlink" title="Mention Detection(2049)"></a>Mention Detection(2049)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011700078.png" alt="image-20220301170016948"></p>
<h3 id="Not-quite-so-simple-2255"><a href="#Not-quite-so-simple-2255" class="headerlink" title="Not quite so simple(2255)"></a>Not quite so simple(2255)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011702656.png" alt="image-20220301170236541"></p>
<p>It is the best donut.</p>
<p>I want to find the best donut.</p>
<h2 id="Avoiding-a-traditional-pipeline-system-2811"><a href="#Avoiding-a-traditional-pipeline-system-2811" class="headerlink" title="Avoiding a traditional pipeline system(2811)"></a>Avoiding a traditional pipeline system(2811)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011705194.png" alt="image-20220301170543068"></p>
<p><strong>End to End[ToL]</strong></p>
<h2 id="Onto-Coreference-First-some-linguistics-3035"><a href="#Onto-Coreference-First-some-linguistics-3035" class="headerlink" title="Onto Coreference! First, some linguistics (3035)"></a>Onto Coreference! First, some linguistics (3035)</h2><p><strong>Coreference and Anaphor</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011712593.png" alt="image-20220301171220450"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011713580.png" alt="image-20220301171334445"></p>
<h3 id="not-all-anaphoric-relations-are-coreferential-3349"><a href="#not-all-anaphoric-relations-are-coreferential-3349" class="headerlink" title="not all anaphoric relations are coreferential (3349)"></a>not all anaphoric relations are coreferential (3349)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011715286.png" alt="image-20220301171524154"></p>
<h2 id="Anaphora-vs-Cataphora-3610"><a href="#Anaphora-vs-Cataphora-3610" class="headerlink" title="Anaphora vs Cataphora(3610)"></a>Anaphora vs Cataphora(3610)</h2><p>One look its reference before it the other is after it.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011717048.png" alt="image-20220301171753920"></p>
<h2 id="Taking-stock-3801"><a href="#Taking-stock-3801" class="headerlink" title="Taking stock (3801)"></a>Taking stock (3801)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011719341.png" alt="image-20220301171920183"></p>
<h2 id="Four-kinds-of-coreference-Models-4018"><a href="#Four-kinds-of-coreference-Models-4018" class="headerlink" title="Four kinds of coreference Models(4018)"></a>Four kinds of coreference Models(4018)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011721240.png" alt="image-20220301172140149"></p>
<h2 id="Traditional-pronominal-anaphora-resolution-Hobbs’s-naive-algorithm-4130"><a href="#Traditional-pronominal-anaphora-resolution-Hobbs’s-naive-algorithm-4130" class="headerlink" title="Traditional pronominal anaphora resolution:Hobbs’s naive algorithm(4130)"></a>Traditional pronominal anaphora resolution:Hobbs’s naive algorithm(4130)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723580.png" alt="image-20220301172320435"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723916.png" alt="image-20220301172342791"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011724568.png" alt="image-20220301172431380"></p>
<h2 id="Knowledge-based-Pronominal-Coreference-4820"><a href="#Knowledge-based-Pronominal-Coreference-4820" class="headerlink" title="Knowledge-based Pronominal Coreference(4820)"></a>Knowledge-based Pronominal Coreference(4820)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011727409.png" alt="image-20220301172732198"></p>
<p>Hobb’s method can not really solve the questions, the model should really understand the sentence.</p>
<h2 id="Coreference-Models-Mention-Pair-5624"><a href="#Coreference-Models-Mention-Pair-5624" class="headerlink" title="Coreference Models: Mention Pair(5624)"></a>Coreference Models: Mention Pair(5624)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738690.png" alt="image-20220301173814531"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738116.png" alt="image-20220301173826974"></p>
<h3 id="Mention-Pair-Test-Time-5800"><a href="#Mention-Pair-Test-Time-5800" class="headerlink" title="Mention Pair Test Time(5800)"></a>Mention Pair Test Time(5800)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011739666.png" alt="image-20220301173911539"></p>
<h3 id="Disadvantage-5953"><a href="#Disadvantage-5953" class="headerlink" title="Disadvantage(5953)"></a>Disadvantage(5953)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011741350.png" alt="image-20220301174101225"></p>
<h2 id="Coreference-Models-Mention-Ranking-h0050"><a href="#Coreference-Models-Mention-Ranking-h0050" class="headerlink" title="Coreference Models: Mention Ranking(h0050)"></a>Coreference Models: Mention Ranking(h0050)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743065.png" alt="image-20220301174326929"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743795.png" alt="image-20220301174335701"></p>
<h2 id="Convolutional-Neural-Nets-h0341"><a href="#Convolutional-Neural-Nets-h0341" class="headerlink" title="Convolutional Neural Nets(h0341)"></a>Convolutional Neural Nets(h0341)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011745334.png" alt="image-20220301174555163"></p>
<h2 id="What-is-convolution-anyway-h0452"><a href="#What-is-convolution-anyway-h0452" class="headerlink" title="What is convolution anyway?(h0452)"></a>What is convolution anyway?(h0452)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011842759.png" alt="image-20220301184216564"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011843829.png" alt="image-20220301184306662"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011844092.png" alt="image-20220301184445934"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011845881.png" alt="image-20220301184526687"></p>
<p><strong>Summarize what we have usually use pooling</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011846697.png" alt="image-20220301184655490"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011847112.png" alt="image-20220301184706063"></p>
<p>Max pooling is usually better.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011848032.png" alt="image-20220301184805861"></p>
<h2 id="End-to-End-Neural-Coref-Model-h1206"><a href="#End-to-End-Neural-Coref-Model-h1206" class="headerlink" title="End-to-End Neural Coref Model(h1206)"></a>End-to-End Neural Coref Model(h1206)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011849948.png" alt="image-20220301184935797"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850188.png" alt="image-20220301185015078"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850940.png" alt="image-20220301185022792"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011851616.png" alt="image-20220301185132395"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011852860.png" alt="image-20220301185213638"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853116.png" alt="image-20220301185316970"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853483.png" alt="image-20220301185347334"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011854783.png" alt="image-20220301185443640"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011855774.png" alt="image-20220301185551550"></p>
<h2 id="Conclusion-h2017"><a href="#Conclusion-h2017" class="headerlink" title="Conclusion (h2017)"></a>Conclusion (h2017)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011857080.png" alt="image-20220301185734941"></p>
<h1 id="Lecture-14-T5-and-Large-Language-Models"><a href="#Lecture-14-T5-and-Large-Language-Models" class="headerlink" title="Lecture 14 - T5 and Large Language Models"></a>Lecture 14 - T5 and Large Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/iHWkLvoSpTg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021447359.png" alt="image-20220302144735211"></p>
<p>(0243)</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021451322.png" alt="image-20220302145100222"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021453717.png" alt="image-20220302145356635"></p>
<h2 id="T5-with-a-task-prefix-0800"><a href="#T5-with-a-task-prefix-0800" class="headerlink" title="T5 with a task prefix(0800)"></a>T5 with a task prefix(0800)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021454368.png" alt="image-20220302145406303"></p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021455282.png" alt="image-20220302145536205"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456327.png" alt="image-20220302145606261"></p>
<h3 id="STSB"><a href="#STSB" class="headerlink" title="STSB"></a>STSB</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456444.png" alt="image-20220302145658323"></p>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456947.png" alt="image-20220302145646869"></p>
<h2 id="T5-change-little-from-original-transformer-1300"><a href="#T5-change-little-from-original-transformer-1300" class="headerlink" title="T5 change little from original transformer(1300)"></a>T5 change little from original transformer(1300)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021459690.png" alt="image-20220302145917510"></p>
<h2 id="what-should-my-pre-training-data-set-be-1325"><a href="#what-should-my-pre-training-data-set-be-1325" class="headerlink" title="what should my pre-training data set be?(1325)"></a>what should my pre-training data set be?(1325)</h2><p><strong>Get from open source data source and then wipe them and get c4 1500</strong></p>
<h2 id="Then-is-how-to-train-from-a-start-1659"><a href="#Then-is-how-to-train-from-a-start-1659" class="headerlink" title="Then is how to train from a start(1659)"></a>Then is how to train from a start(1659)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021511473.png" alt="image-20220302151128378"></p>
<h2 id="pretrain-1805"><a href="#pretrain-1805" class="headerlink" title="pretrain(1805)"></a>pretrain(1805)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021515266.png" alt="image-20220302151510138"></p>
<h2 id="choose-the-model-2412"><a href="#choose-the-model-2412" class="headerlink" title="choose the model(2412)"></a>choose the model(2412)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021520528.png" alt="image-20220302152005363"></p>
<p>They use the encoder-Decoder model, It turns out it works well.</p>
<p><strong>They dont change hyper paramenters because of the cost</strong></p>
<h2 id="pre-training-objective-2629"><a href="#pre-training-objective-2629" class="headerlink" title="pre-training objective(2629)"></a>pre-training objective(2629)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021539312.png" alt="image-20220302153925164"></p>
<p><strong>Choose different train method</strong></p>
<h2 id="different-structure-of-data-source-2822"><a href="#different-structure-of-data-source-2822" class="headerlink" title="different structure of data source(2822)"></a>different structure of data source(2822)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021546645.png" alt="image-20220302154612488"></p>
<h2 id="Multi-task-learning-3443"><a href="#Multi-task-learning-3443" class="headerlink" title="Multi task learning (3443)"></a>Multi task learning (3443)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021551343.png" alt="image-20220302155158191"></p>
<h2 id="close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621"><a href="#close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621" class="headerlink" title="close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)"></a>close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021557083.png" alt="image-20220302155756918"></p>
<h2 id="What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737"><a href="#What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737" class="headerlink" title="What if it happens there are four times computes as much as before  (3737)"></a>What if it happens there are four times computes as much as before  (3737)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021600593.png" alt="image-20220302160009440"></p>
<h2 id="Overview-3840"><a href="#Overview-3840" class="headerlink" title="Overview(3840)"></a>Overview(3840)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021601735.png" alt="image-20220302160104583"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021602559.png" alt="image-20220302160234452"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021605914.png" alt="image-20220302160555766"></p>
<p> <img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021606666.png" alt="image-20220302160612550"></p>
<h2 id="What-about-all-of-the-other-languages-mT5-4735"><a href="#What-about-all-of-the-other-languages-mT5-4735" class="headerlink" title="What about all of the other languages?(mT5)(4735)"></a>What about all of the other languages?(mT5)(4735)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021611309.png" alt="image-20220302161124160"></p>
<p>Same model different corpus.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021612178.png" alt="image-20220302161211041"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021613249.png" alt="image-20220302161358092"></p>
<h2 id="XTREME-5000"><a href="#XTREME-5000" class="headerlink" title="XTREME (5000)"></a>XTREME (5000)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021614579.png" alt="image-20220302161445454"></p>
<h2 id="How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225"><a href="#How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225" class="headerlink" title="How much knowledge does a language model pick up during pre-training?(5225)"></a>How much knowledge does a language model pick up during pre-training?(5225)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619700.png" alt="image-20220302161913596"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619203.png" alt="image-20220302161932089"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619946.png" alt="image-20220302161949876"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021620563.png" alt="image-20220302162028438"></p>
<h2 id="Salient-span-masking-5631"><a href="#Salient-span-masking-5631" class="headerlink" title="Salient span masking (5631)"></a>Salient span masking (5631)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021623948.png" alt="image-20220302162316816"></p>
<p><strong>Instead of mask randomly, it mask username please date, etc.</strong></p>
<h2 id="Do-large-language-models-memorize-their-training-data-h0100"><a href="#Do-large-language-models-memorize-their-training-data-h0100" class="headerlink" title="Do large language models memorize their training data(h0100)"></a>Do large language models memorize their training data(h0100)</h2><p><strong>It seems it did</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021629154.png" alt="image-20220302162918979"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021630287.png" alt="image-20220302163050189"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021631372.png" alt="image-20220302163113267"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635048.png" alt="image-20220302163505954"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635716.png" alt="image-20220302163519627"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021637986.png" alt="image-20220302163719877"></p>
<p>They need to see examples, they need to see particular examples fewer times in order!</p>
<h2 id="Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010"><a href="#Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010" class="headerlink" title="Can we close the gap between large and small models by improving the transformer architecture(h1010)"></a>Can we close the gap between large and small models by improving the transformer architecture(h1010)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021649670.png" alt="image-20220302164909562"></p>
<p>in these test, they change some architecture such as RELu. </p>
<p><strong>there actually were very few, if any modifications that improved performance meaningfully.</strong></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021652560.png" alt="image-20220302165203416"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021653903.png" alt="image-20220302165316814">(h1700)</p>
<h2 id="QA-h1915"><a href="#QA-h1915" class="headerlink" title="QA(h1915)"></a>QA(h1915)</h2><h1 id="Lecture-15-Add-Knowledge-to-Language-Models"><a href="#Lecture-15-Add-Knowledge-to-Language-Models" class="headerlink" title="Lecture 15 - Add Knowledge to Language Models"></a>Lecture 15 - Add Knowledge to Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/y68RJVfGoto?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021723936.png" alt="image-20220302172329814"></p>
<h2 id="Recap-LM-0232"><a href="#Recap-LM-0232" class="headerlink" title="Recap: LM(0232)"></a>Recap: LM(0232)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021726699.png" alt="image-20220302172634570"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727605.png" alt="image-20220302172712490"></p>
<h2 id="What-does-a-language-model-know-0423"><a href="#What-does-a-language-model-know-0423" class="headerlink" title="What does a language model know?(0423)"></a>What does a language model know?(0423)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727649.png" alt="image-20220302172753547"></p>
<p>Thing may right in logic but wrong in fact.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021729763.png" alt="image-20220302172916623"></p>
<h2 id="The-importance-of-know-ledge-aware-language-models-0700"><a href="#The-importance-of-know-ledge-aware-language-models-0700" class="headerlink" title="The importance of know ledge-aware language models(0700)"></a>The importance of know ledge-aware language models(0700)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733793.png" alt="image-20220302173300654"></p>
<h2 id="Query-traditional-knowledge-bases-0750"><a href="#Query-traditional-knowledge-bases-0750" class="headerlink" title="Query traditional knowledge bases(0750)"></a>Query traditional knowledge bases(0750)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733338.png" alt="image-20220302173336194"></p>
<h2 id="Query-language-models-as-knowledge-bases-0955"><a href="#Query-language-models-as-knowledge-bases-0955" class="headerlink" title="Query language models as knowledge bases(0955)"></a>Query language models as knowledge bases(0955)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021735054.png" alt="image-20220302173553905"></p>
<h2 id="Compare-and-disadvantage-1010"><a href="#Compare-and-disadvantage-1010" class="headerlink" title="Compare and disadvantage(1010)"></a>Compare and disadvantage(1010)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021738604.png" alt="image-20220302173820443"></p>
<h2 id="Techniques-to-add-knowledge-to-LMs-130"><a href="#Techniques-to-add-knowledge-to-LMs-130" class="headerlink" title="Techniques to add knowledge to LMs(130)"></a>Techniques to add knowledge to LMs(130)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021739919.png" alt="image-20220302173937785"></p>
<h2 id="Add-pretrained-embeddings-1403"><a href="#Add-pretrained-embeddings-1403" class="headerlink" title="Add pretrained embeddings(1403)"></a>Add pretrained embeddings(1403)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021743165.png" alt="image-20220302174313016"></p>
<h2 id="Aside-What-is-entity-linking-1516"><a href="#Aside-What-is-entity-linking-1516" class="headerlink" title="Aside: What is entity linking?(1516)"></a>Aside: What is entity linking?(1516)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021746116.png" alt="image-20220302174603921"></p>
<h2 id="Method-1-Add-pretrained-entity-embeddings-1815"><a href="#Method-1-Add-pretrained-entity-embeddings-1815" class="headerlink" title="Method 1: Add pretrained entity embeddings(1815)"></a>Method 1: Add pretrained entity embeddings(1815)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021747337.png" alt="image-20220302174729224"></p>
<h3 id="How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000"><a href="#How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000" class="headerlink" title="How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)"></a>How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021749944.png" alt="image-20220302174927805"></p>
<h2 id="ERNIE-Enhanced-language-representation-with-informative-entities-2143"><a href="#ERNIE-Enhanced-language-representation-with-informative-entities-2143" class="headerlink" title="ERNIE: Enhanced language representation with informative entities(2143)"></a>ERNIE: Enhanced language representation with informative entities(2143)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021752214.png" alt="image-20220302175236060"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021754765.png" alt="image-20220302175420597"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757296.png" alt="image-20220302175702140"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757888.png" alt="image-20220302175713761"></p>
<h3 id="strengths-amp-remaining-challenges-2610"><a href="#strengths-amp-remaining-challenges-2610" class="headerlink" title="strengths &amp; remaining challenges(2610)"></a>strengths &amp; remaining challenges(2610)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021758503.png" alt="image-20220302175826353"></p>
<h2 id="Jointly-learn-to-link-entities-with-KnowBERT-2958"><a href="#Jointly-learn-to-link-entities-with-KnowBERT-2958" class="headerlink" title="Jointly learn to link entities with KnowBERT(2958)"></a>Jointly learn to link entities with KnowBERT(2958)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021804637.png" alt="image-20220302180440491"></p>
<h2 id="Use-an-external-memory-3140"><a href="#Use-an-external-memory-3140" class="headerlink" title="Use an external memory(3140)"></a>Use an external memory(3140)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021807795.png" alt="image-20220302180727662"></p>
<h3 id="KGLM-3355"><a href="#KGLM-3355" class="headerlink" title="KGLM(3355)"></a>KGLM(3355)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021808462.png" alt="image-20220302180818299"></p>
<h3 id="Local-knowledge-and-full-knowledge"><a href="#Local-knowledge-and-full-knowledge" class="headerlink" title="Local knowledge and full knowledge"></a>Local knowledge and full knowledge</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021810608.png" alt="image-20220302181037473"></p>
<h3 id="When-should-the-model-use-the-external-knowledge-3600"><a href="#When-should-the-model-use-the-external-knowledge-3600" class="headerlink" title="When should the model use the external knowledge(3600)"></a>When should the model use the external knowledge(3600)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021811716.png" alt="image-20220302181146581"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021814810.png" alt="image-20220302181436660"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815905.png" alt="image-20220302181526770"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815447.png" alt="image-20220302181538323"></p>
<h2 id="Compare-to-the-others-4334"><a href="#Compare-to-the-others-4334" class="headerlink" title="Compare to the others(4334)"></a>Compare to the others(4334)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021818819.png" alt="image-20220302181801664"></p>
<h2 id="More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730"><a href="#More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730" class="headerlink" title="More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)"></a>More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021823462.png" alt="image-20220302182325290"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021825650.png" alt="image-20220302182507490"></p>
<h2 id="Modify-the-training-data-5230"><a href="#Modify-the-training-data-5230" class="headerlink" title="Modify the training data(5230)"></a>Modify the training data(5230)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021828456.png" alt="image-20220302182823268"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021829477.png" alt="image-20220302182959293"></p>
<h2 id="WKLM-5458"><a href="#WKLM-5458" class="headerlink" title="WKLM(5458)"></a>WKLM(5458)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021830774.png" alt="image-20220302183028613"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021831311.png" alt="image-20220302183142193"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021832124.png" alt="image-20220302183255968"></p>
<h2 id="Learn-inductive-biases-through-masking-5811"><a href="#Learn-inductive-biases-through-masking-5811" class="headerlink" title="Learn inductive biases through masking(5811)"></a>Learn inductive biases through masking(5811)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021833826.png" alt="image-20220302183351631"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834994.png" alt="image-20220302183427849"></p>
<h2 id="Salient-span-masking-5927"><a href="#Salient-span-masking-5927" class="headerlink" title="Salient span masking(5927)"></a>Salient span masking(5927)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834166.png" alt="image-20220302183458012"></p>
<h2 id="Recap-h0053"><a href="#Recap-h0053" class="headerlink" title="Recap(h0053)"></a>Recap(h0053)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021837032.png" alt="image-20220302183700886"></p>
<h2 id="Evaluating-knowledge-in-LMS-h0211"><a href="#Evaluating-knowledge-in-LMS-h0211" class="headerlink" title="Evaluating knowledge in LMS(h0211)"></a>Evaluating knowledge in LMS(h0211)</h2><h3 id="LAMA-h0250"><a href="#LAMA-h0250" class="headerlink" title="LAMA(h0250)"></a>LAMA(h0250)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021838823.png" alt="image-20220302183849664"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021839294.png" alt="image-20220302183927125"></p>
<h3 id="The-limitations-h0650"><a href="#The-limitations-h0650" class="headerlink" title="The limitations (h0650)"></a>The limitations (h0650)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021841791.png" alt="image-20220302184139639"></p>
<h2 id="LAMA-UnHelpful-Names-LAMA-UHN"><a href="#LAMA-UnHelpful-Names-LAMA-UHN" class="headerlink" title="LAMA_UnHelpful Names(LAMA-UHN)"></a>LAMA_UnHelpful Names(LAMA-UHN)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021842799.png" alt="image-20220302184226621"></p>
<p>** They delete something that may caused by co-occurrence **</p>
<h3 id="Developing-better-prompts-to-query-knowledge-in-LMS"><a href="#Developing-better-prompts-to-query-knowledge-in-LMS" class="headerlink" title="Developing better prompts to query knowledge in LMS"></a>Developing better prompts to query knowledge in LMS</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021844225.png" alt="image-20220302184443068"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021845853.png" alt="image-20220302184528706"></p>
<h3 id="Knowledge-driven-downstream-tasks-h1253"><a href="#Knowledge-driven-downstream-tasks-h1253" class="headerlink" title="Knowledge-driven downstream tasks(h1253)"></a>Knowledge-driven downstream tasks(h1253)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847354.png" alt="image-20220302184702209"></p>
<h2 id="Relation-extraction-performance-on-TACED-h1400"><a href="#Relation-extraction-performance-on-TACED-h1400" class="headerlink" title="Relation extraction performance on TACED(h1400)"></a>Relation extraction performance on TACED(h1400)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847359.png" alt="image-20220302184753193"></p>
<h2 id="Entity-typing-performance-on-Open-Entuty"><a href="#Entity-typing-performance-on-Open-Entuty" class="headerlink" title="Entity typing performance on Open Entuty"></a>Entity typing performance on Open Entuty</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021848691.png" alt="image-20220302184828514"></p>
<h2 id="Recap-Evaluating-knowledge-in-LMs-h1600"><a href="#Recap-Evaluating-knowledge-in-LMs-h1600" class="headerlink" title="Recap: Evaluating knowledge in LMs(h1600)"></a>Recap: Evaluating knowledge in LMs(h1600)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021849200.png" alt="image-20220302184929078"></p>
<h2 id="Other-exciting-progress-amp-what’s-next-h1652"><a href="#Other-exciting-progress-amp-what’s-next-h1652" class="headerlink" title="Other exciting progress &amp; what’s next?(h1652)"></a>Other exciting progress &amp; what’s next?(h1652)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021850845.png" alt="image-20220302185006721"></p>
<h1 id="Lecture-17-Model-Analysis-and-Explanation"><a href="#Lecture-17-Model-Analysis-and-Explanation" class="headerlink" title="Lecture 17 - Model Analysis and Explanation"></a>Lecture 17 - Model Analysis and Explanation</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/f_qmSSBWV_E?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031042434.png" alt="image-20220303104239293"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031043574.png" alt="image-20220303104308448"></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><h3 id="what-are-our-models-doing-0415"><a href="#what-are-our-models-doing-0415" class="headerlink" title="what are our models doing(0415)"></a>what are our models doing(0415)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031044256.png" alt="image-20220303104435113"></p>
<h3 id="how-do-we-make-tomorrow’s-model-0515"><a href="#how-do-we-make-tomorrow’s-model-0515" class="headerlink" title="how do we make tomorrow’s model?(0515)"></a>how do we make tomorrow’s model?(0515)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031046845.png" alt="image-20220303104651667"></p>
<h3 id="What-biases-are-built-into-model-0700"><a href="#What-biases-are-built-into-model-0700" class="headerlink" title="What biases are built into model?(0700)"></a>What biases are built into model?(0700)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031050696.png" alt="image-20220303105015554"></p>
<h3 id="how-do-we-make-in-the-following-25years-0800"><a href="#how-do-we-make-in-the-following-25years-0800" class="headerlink" title="how do we make in the following 25years(0800)"></a>how do we make in the following 25years(0800)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031051800.png" alt="image-20220303105141648"></p>
<h2 id="Model-analysis-at-varying-levels-of-abstraction-0904"><a href="#Model-analysis-at-varying-levels-of-abstraction-0904" class="headerlink" title="Model analysis at varying levels of abstraction(0904)"></a>Model analysis at varying levels of abstraction(0904)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031056169.png" alt="image-20220303105647998"></p>
<h2 id="Model-evaluation-as-model-analysis-1117"><a href="#Model-evaluation-as-model-analysis-1117" class="headerlink" title="Model evaluation as model analysis(1117)"></a>Model evaluation as model analysis(1117)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031059574.png" alt="image-20220303105924421"></p>
<h2 id="Model-evaluation-as-model-analysis-in-natural-language-inference-1344"><a href="#Model-evaluation-as-model-analysis-in-natural-language-inference-1344" class="headerlink" title="Model evaluation as model analysis in natural language inference(1344)"></a>Model evaluation as model analysis in natural language inference(1344)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031102348.png" alt="image-20220303110240168"></p>
<h3 id="What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558"><a href="#What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558" class="headerlink" title="What if the model is simple using heuristics to get good accuracy?(1558)"></a>What if the model is simple using heuristics to get good accuracy?(1558)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031108392.png" alt="image-20220303110832177"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031109573.png" alt="image-20220303110953359"></p>
<h2 id="Language-models-as-linguistic-test-subjects-2023"><a href="#Language-models-as-linguistic-test-subjects-2023" class="headerlink" title="Language models as linguistic test subjects(2023)"></a>Language models as linguistic test subjects(2023)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031117718.png" alt="image-20220303111752546"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031123611.png" alt="image-20220303112316410"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031126322.png" alt="image-20220303112622131"></p>
<h2 id="Careful-test-sets-as-unit-test-suites-CheckListing-3230"><a href="#Careful-test-sets-as-unit-test-suites-CheckListing-3230" class="headerlink" title="Careful  test sets as unit test suites: CheckListing(3230)"></a>Careful  test sets as unit test suites: CheckListing(3230)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031150003.png" alt="image-20220303115000790"></p>
<h2 id="Fitting-the-dataset-vs-learning-the-task-3500"><a href="#Fitting-the-dataset-vs-learning-the-task-3500" class="headerlink" title="Fitting the dataset vs learning the task(3500)"></a>Fitting the dataset vs learning the task(3500)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031151961.png" alt="image-20220303115116821"></p>
<h2 id="Knowledge-evaluation-as-model-analysis-3642"><a href="#Knowledge-evaluation-as-model-analysis-3642" class="headerlink" title="Knowledge evaluation as model analysis(3642)"></a>Knowledge evaluation as model analysis(3642)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031152782.png" alt="image-20220303115222614"></p>
<h2 id="Input-influence-does-my-model-really-use-long-distance-context-3822"><a href="#Input-influence-does-my-model-really-use-long-distance-context-3822" class="headerlink" title="Input influence: does my model really use long-distance context?(3822)"></a>Input influence: does my model really use long-distance context?(3822)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031154169.png" alt="image-20220303115456959"></p>
<h2 id="Prediction-explanations-what-in-the-input-led-to-this-output-4054"><a href="#Prediction-explanations-what-in-the-input-led-to-this-output-4054" class="headerlink" title="Prediction explanations: what in the input led to this output?(4054)"></a>Prediction explanations: what in the input led to this output?(4054)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031158656.png" alt="image-20220303115848462"></p>
<h2 id="Prediction-explanations-simple-saliency-maps-4230"><a href="#Prediction-explanations-simple-saliency-maps-4230" class="headerlink" title="Prediction explanations: simple saliency maps(4230)"></a>Prediction explanations: simple saliency maps(4230)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031201539.png" alt="image-20220303120124359"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031332993.png" alt="image-20220303133241797"></p>
<h2 id="Explanation-by-input-reduction-4607"><a href="#Explanation-by-input-reduction-4607" class="headerlink" title="Explanation by input reduction (4607)"></a>Explanation by input reduction (4607)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031341312.png" alt="image-20220303134148143"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031343962.png" alt="image-20220303134313746"></p>
<h2 id="Analyzing-models-by-breaking-them-5106"><a href="#Analyzing-models-by-breaking-them-5106" class="headerlink" title="Analyzing models by breaking them(5106)"></a>Analyzing models by breaking them(5106)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346413.png" alt="image-20220303134604267"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346603.png" alt="image-20220303134644433"></p>
<p>They add a nonsense sentence at the end and the prediction changed.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031347898.png" alt="image-20220303134756682"></p>
<p><strong>Change the Q also make the prediction changed</strong></p>
<h2 id="Are-models-robust-to-noise-in-their-input-5518"><a href="#Are-models-robust-to-noise-in-their-input-5518" class="headerlink" title="Are models robust to noise in their input?(5518)"></a>Are models robust to noise in their input?(5518)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031350084.png" alt="image-20220303135054871"></p>
<p>It seems not.</p>
<h2 id="Analysis-of-“interpretable”-architecture-components-5719"><a href="#Analysis-of-“interpretable”-architecture-components-5719" class="headerlink" title="Analysis of “interpretable” architecture components(5719)"></a>Analysis of “interpretable” architecture components(5719)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031356980.png" alt="image-20220303135659761"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031357241.png" alt="image-20220303135716017"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031400358.png" alt="image-20220303140006202"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031401626.png" alt="image-20220303140154452"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031403011.png" alt="image-20220303140306747"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031404517.png" alt="image-20220303140430315"></p>
<h2 id="Probing-supervised-analysis-of-neural-networks-h0408"><a href="#Probing-supervised-analysis-of-neural-networks-h0408" class="headerlink" title="Probing: supervised analysis of neural networks(h0408)"></a>Probing: supervised analysis of neural networks(h0408)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031407337.png" alt="image-20220303140720120"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031408146.png" alt="image-20220303140831970"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031410797.png" alt="image-20220303141059579"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413065.png" alt="image-20220303141301877"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413295.png" alt="image-20220303141354126"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031414069.png" alt="image-20220303141443881"></p>
<p>the most efficient layer is in the middlwe.</p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031415636.png" alt="image-20220303141554363"></p>
<p>deeper, more abstract</p>
<h2 id="Emergent-simple-structure-in-neural-networks-h1019"><a href="#Emergent-simple-structure-in-neural-networks-h1019" class="headerlink" title="Emergent simple structure in neural networks(h1019)"></a>Emergent simple structure in neural networks(h1019)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031417261.png" alt="image-20220303141709095"></p>
<h2 id="Probing-tress-simply-recoverable-from-BERT-representations-h1136"><a href="#Probing-tress-simply-recoverable-from-BERT-representations-h1136" class="headerlink" title="Probing: tress simply recoverable from BERT representations(h1136)"></a>Probing: tress simply recoverable from BERT representations(h1136)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031419210.png" alt="image-20220303141908032"></p>
<h2 id="Final-thoughts-on-probing-and-correlation-studies-h1341"><a href="#Final-thoughts-on-probing-and-correlation-studies-h1341" class="headerlink" title="Final thoughts on probing and correlation studies(h1341)"></a>Final thoughts on probing and correlation studies(h1341)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031421004.png" alt="image-20220303142155844"></p>
<p>Not causal study</p>
<h2 id="Recasting-model-tweaks-and-ablations-as-analysis-h1406"><a href="#Recasting-model-tweaks-and-ablations-as-analysis-h1406" class="headerlink" title="Recasting model tweaks and ablations as analysis(h1406)"></a>Recasting model tweaks and ablations as analysis(h1406)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031423815.png" alt="image-20220303142341661"></p>
<h3 id="Ablation-analysis-do-we-need-all-these-attension-heads-h1445"><a href="#Ablation-analysis-do-we-need-all-these-attension-heads-h1445" class="headerlink" title="Ablation analysis: do we need all these attension heads?(h1445)"></a>Ablation analysis: do we need all these attension heads?(h1445)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031424764.png" alt="image-20220303142453543"></p>
<h2 id="What’s-the-right-layer-order-for-a-transformer-h1537"><a href="#What’s-the-right-layer-order-for-a-transformer-h1537" class="headerlink" title="What’s the right layer order for a transformer?(h1537)"></a>What’s the right layer order for a transformer?(h1537)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031425391.png" alt="image-20220303142557160"></p>
<h2 id="Parting-thoughts-h1612"><a href="#Parting-thoughts-h1612" class="headerlink" title="Parting thoughts(h1612)"></a>Parting thoughts(h1612)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031426427.png" alt="image-20220303142651251"></p>
<h1 id="Lecture-18-Future-of-NLP-Deep-Learning"><a href="#Lecture-18-Future-of-NLP-Deep-Learning" class="headerlink" title="Lecture 18 - Future of NLP + Deep Learning"></a>Lecture 18 - Future of NLP + Deep Learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/2t7Q9WVUaf8?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456172.png" alt="image-20220303145634077"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456187.png" alt="image-20220303145648087"></p>
<h2 id="General-Representation-Learning-Recipe-0312"><a href="#General-Representation-Learning-Recipe-0312" class="headerlink" title="General Representation Learning Recipe(0312)"></a>General Representation Learning Recipe(0312)</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031458027.png" alt="image-20220303145813909"></p>
<p>Certain properties emerge only when we scale up the model size!</p>
<h2 id="Large-Language-Models-and-GPT-3-0358"><a href="#Large-Language-Models-and-GPT-3-0358" class="headerlink" title="Large Language Models and GPT-3(0358)"></a>Large Language Models and GPT-3(0358)</h2><h3 id="Large-Language-models-and-GPT-3-0514"><a href="#Large-Language-models-and-GPT-3-0514" class="headerlink" title="Large Language models and GPT-3(0514)"></a>Large Language models and GPT-3(0514)</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031501186.png" alt="image-20220303150148074"></p>
<h3 id="What’s-new-about-GPT-3"><a href="#What’s-new-about-GPT-3" class="headerlink" title="What’s new about GPT-3"></a>What’s new about GPT-3</h3><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502616.png" alt="image-20220303150225480"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502821.png" alt="image-20220303150257686"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031503577.png" alt="image-20220303150317443"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/Pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/Pytorch/" class="post-title-link" itemprop="url">Pytorch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:44" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:44+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:41" itemprop="dateModified" datetime="2022-03-23T11:23:41+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s</p>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,dtype=torch.double)</span><br><span class="line">x.size()</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>,device=device)</span><br><span class="line">y = torch.rand(<span class="number">2</span>,<span class="number">2</span>,device=device)</span><br><span class="line">z = x+y <span class="comment">#+-*/</span></span><br><span class="line">z = torch.add(x,y)<span class="comment">#add sub mul</span></span><br><span class="line">y.add_(x)<span class="comment"># sub_ div_ 原地操作</span></span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">x[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line"></span><br><span class="line">y=x.view(-<span class="number">1</span>,<span class="number">2</span>) <span class="comment">#插眼</span></span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">a.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">a.add_(<span class="number">13</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"></span><br><span class="line">a = np.ones(<span class="number">6</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)<span class="comment">#***</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = x+<span class="number">2</span></span><br><span class="line">z = y*y*<span class="number">2</span></span><br><span class="line"><span class="comment">#z = z.mean()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.001</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">z.backward(v)<span class="comment"># 插眼：如果不是标量则必须给vecor ***</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dont calculate 插眼</span></span><br><span class="line"><span class="comment">#x.requires_grad_(False)</span></span><br><span class="line"><span class="comment">#y = x.detach()</span></span><br><span class="line"><span class="comment">#with torch.no_grad():</span></span><br><span class="line"><span class="comment">#    y = x + 2</span></span><br><span class="line"><span class="comment">#    print(y)</span></span><br><span class="line"></span><br><span class="line">weights = torch.ones(<span class="number">4</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model_output = (weights*<span class="number">3</span>).<span class="built_in">sum</span>()</span><br><span class="line">    model_output.backward()</span><br><span class="line">    <span class="built_in">print</span>(weights.grad)</span><br><span class="line"></span><br><span class="line">    weights.grad.zero_() <span class="comment">#将积累的计算清零 插眼，需要深入理解 ***</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#optimizer</span></span><br><span class="line"><span class="comment">#optimizer = torch.optim.SGD([weights], lr=0.01)</span></span><br><span class="line"><span class="comment">#optimizer.step()</span></span><br><span class="line"><span class="comment">#optimizer.zero_grad()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">w = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_hat = w * x</span><br><span class="line">loss = (y_hat-y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>

<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png" alt="image-20220316151942503"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=np.float32)</span><br><span class="line">w = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    dw = gradient(x,y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    w-=learning_rate * dw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png" alt="image-20220316145349626"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= learning_rate * w.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    w.grad.zero_()        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Training-pipeline"><a href="#Training-pipeline" class="headerlink" title="Training pipeline"></a>Training pipeline</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png" alt="image-20220316153456524"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="comment">#y_pred = model(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png" alt="image-20220316153507880"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line"><span class="comment">#w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    <span class="comment">#y_pred = forward(x)</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">x_numpy,y_numpy = datasets.make_regression(n_samples=<span class="number">100</span>,n_features=<span class="number">1</span>,noise=<span class="number">20</span>,random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = torch.from_numpy(x_numpy.astype(np.float32))</span><br><span class="line">y = torch.from_numpy(y_numpy.astype(np.float32))</span><br><span class="line">y = y.view(y.shape[<span class="number">0</span>],<span class="number">1</span>)<span class="comment"># 插眼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = nn.Linear(input_size,output_size)</span><br><span class="line">pr = model(x).detach().numpy()</span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># forward pss and loss</span></span><br><span class="line">    y_predicted = model(x)</span><br><span class="line">    loss = criterion(y_predicted,y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">predicted = model(x).detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(x_numpy,y_numpy,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x_numpy,predicted,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">bc = datasets.load_breast_cancer()</span><br><span class="line">x,y = bc.data,bc.target</span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#sclae</span></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">x_train = sc.fit_transform(x_train)</span><br><span class="line">x_test = sc.transform(x_test)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train.astype(np.float32))</span><br><span class="line">x_test = torch.from_numpy(x_test.astype(np.float32))</span><br><span class="line">y_train = torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">y_test = torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line">y_train = y_train.view(y_train.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line">y_test = y_test.view(y_test.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"><span class="comment"># f = wx+b, sigmod at the end</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_predicted = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_predicted</span><br><span class="line">model = LogisticRegression(n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.03</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="comment">#forward pass and loss</span></span><br><span class="line">    y_predicted = model(x_train)</span><br><span class="line">    loss = criterion(y_predicted,y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y_predicted = model(x_test)</span><br><span class="line">    y_predicted_cls = y_predicted.<span class="built_in">round</span>()</span><br><span class="line">    acc = y_predicted_cls.eq(y_test).<span class="built_in">sum</span>()/<span class="built_in">float</span>(y_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,</span><br><span class="line">                        skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = torch.from_numpy(xy[:, <span class="number">1</span>:])</span><br><span class="line">        self.y = torch.from_numpy(xy[:, [<span class="number">0</span>]])</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = WineDataSet()</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datatiter = iter(dataloader)</span></span><br><span class="line"><span class="comment"># data = datatiter.next()</span></span><br><span class="line"><span class="comment"># features, labels = data</span></span><br><span class="line"><span class="comment"># print(features,labels)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line">n_iterations = math.ceil(total_samples / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(total_samples, n_iterations)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># forward backward, update</span></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_iterations&#125;</span>,inputs <span class="subst">&#123;inputs.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-transformers"><a href="#Dataset-transformers" class="headerlink" title="Dataset transformers"></a>Dataset transformers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = xy[:, <span class="number">1</span>:]</span><br><span class="line">        self.y = xy[:, [<span class="number">0</span>]]</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        sample = self.x[index],self.y[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToTensor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,targets = sample</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(inputs),torch.from_numpy(targets)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulTransform</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,factor</span>):</span><br><span class="line">        self.factor = factor</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,target = sample</span><br><span class="line">        inputs *= self.factor</span><br><span class="line">        <span class="keyword">return</span> inputs,target</span><br><span class="line"></span><br><span class="line">dataset = WineDataSet(transform=<span class="literal">None</span>)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br><span class="line"></span><br><span class="line">composed = torchvision.transforms.Compose([ToTensor(),MulTransform(<span class="number">2</span>)])</span><br><span class="line">dataset = WineDataSet(transform=composed)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br></pre></td></tr></table></figure>

<h1 id="SoftMax-and-Crossentropy"><a href="#SoftMax-and-Crossentropy" class="headerlink" title="SoftMax and Crossentropy"></a>SoftMax and Crossentropy</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png" alt="image-20220317185503305"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x)/np.<span class="built_in">sum</span>(np.exp(x),axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = softmax(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;softmax numpy:&#x27;</span>,outputs)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = torch.softmax(x,dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">actual,predicted</span>):</span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(actual * np.log(predicted))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">Y_pred_good = np.array([<span class="number">0.7</span>,<span class="number">0.2</span>,<span class="number">0.1</span>])</span><br><span class="line">Y_pred_bad = np.array([<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>])</span><br><span class="line">l1 = cross_entropy(Y,Y_pred_good)</span><br><span class="line">l2 = cross_entropy(Y,Y_pred_bad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss1 numpy:<span class="subst">&#123;l1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss2 numpy:<span class="subst">&#123;l2:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#3 samples</span></span><br><span class="line"></span><br><span class="line">Y = torch.tensor([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">y_pred_good = torch.tensor([[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line">y_pred_bad = torch.tensor([[<span class="number">2.1</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">l1 = loss(y_pred_good,Y)</span><br><span class="line">l2 = loss(y_pred_bad,Y)</span><br><span class="line"><span class="built_in">print</span>(l1.item())</span><br><span class="line"><span class="built_in">print</span>(l2.item())</span><br><span class="line"></span><br><span class="line">_,pred1 = torch.<span class="built_in">max</span>(y_pred_good,<span class="number">1</span>)</span><br><span class="line">_,pred2 = torch.<span class="built_in">max</span>(y_pred_bad,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred1)</span><br><span class="line"><span class="built_in">print</span>(pred2)</span><br></pre></td></tr></table></figure>

<h1 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png" alt="image-20220318104226578"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png" alt="image-20220318104246948"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiclass problem</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line"></span><br><span class="line">        y_pred = torch.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = NeuralNet2(input_size=<span class="number">28</span>*<span class="number">28</span>,hidden_size=<span class="number">5</span>,num_classes=<span class="number">1</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># option1 create nn modules</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        <span class="comment">#nn.Sigmoid</span></span><br><span class="line">        <span class="comment">#nn.Softmax</span></span><br><span class="line">        <span class="comment">#nn.TanH</span></span><br><span class="line">        <span class="comment">#nn.LeakyReLU</span></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment"># option 2 use activation functions directly in forward pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        <span class="comment">#F.leaky_relu()</span></span><br><span class="line">        self.linear = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = torch.relu(self.linear1(x))</span><br><span class="line">        out = torch.simoid(self.linear2(out))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h1 id="Feed-Forward-Neural-Net"><a href="#Feed-Forward-Neural-Net" class="headerlink" title="Feed-Forward Neural Net"></a>Feed-Forward Neural Net</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># device config</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#hyper parameters</span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br><span class="line"><span class="comment"># DataLoader,Transformation</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">samples,labels = examples.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(samples.shape,labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(samples[i][<span class="number">0</span>],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = NeuralNet(input_size,hidden_size,num_classes)</span><br><span class="line">model=model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">## loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training loo</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#100,1,28,28</span></span><br><span class="line">        <span class="comment">#100,784</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#forward</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#backwards</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.n_ntotal_steps, loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#value,index</span></span><br><span class="line">        _,predictions = torch.<span class="built_in">max</span>(outputs,<span class="number">1</span>)</span><br><span class="line">        n_samples+= labels.shape[<span class="number">0</span>]</span><br><span class="line">        n_correct = (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = <span class="number">100.0</span>* n_correct/n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png" alt="image-20220318145648589"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset has PILImage images of range [0, 1]. </span></span><br><span class="line"><span class="comment"># We transform them to Tensors of normalized range [-1, 1]</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class</span></span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># -&gt; n, 3, 32, 32</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))  <span class="comment"># -&gt; n, 6, 14, 14</span></span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))  <span class="comment"># -&gt; n, 16, 5, 5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)            <span class="comment"># -&gt; n, 400</span></span><br><span class="line">        x = F.relu(self.fc1(x))               <span class="comment"># -&gt; n, 120</span></span><br><span class="line">        x = F.relu(self.fc2(x))               <span class="comment"># -&gt; n, 84</span></span><br><span class="line">        x = self.fc3(x)                       <span class="comment"># -&gt; n, 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet().to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># origin shape: [4, 3, 32, 32] = 4, 3, 1024</span></span><br><span class="line">        <span class="comment"># input_layer: 3 input channels, 6 output channels, 5 kernel size</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line">PATH = <span class="string">&#x27;./cnn.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    n_class_correct = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    n_class_samples = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            pred = predicted[i]</span><br><span class="line">            <span class="keyword">if</span> (label == pred):</span><br><span class="line">                n_class_correct[label] += <span class="number">1</span></span><br><span class="line">            n_class_samples[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        acc = <span class="number">100.0</span> * n_class_correct[i] / n_class_samples[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png" alt="image-20220318145729962"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">mean = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">std = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;data/hymenoptera_data&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=<span class="number">4</span>,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">25</span></span>):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        optimizer.zero_grad()</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Finetuning the convnet ####</span></span><br><span class="line"><span class="comment"># Load a pretrained model and reset final fully connected layer.</span></span><br><span class="line"></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 2.</span></span><br><span class="line"><span class="comment"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span></span><br><span class="line">model.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StepLR Decays the learning rate of each parameter group by gamma every step_size epochs</span></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Learning rate scheduling should be applied after optimizer’s update</span></span><br><span class="line"><span class="comment"># e.g., you should write your code this way:</span></span><br><span class="line"><span class="comment"># for epoch in range(100):</span></span><br><span class="line"><span class="comment">#     train(...)</span></span><br><span class="line"><span class="comment">#     validate(...)</span></span><br><span class="line"><span class="comment">#     scheduler.step()</span></span><br><span class="line"></span><br><span class="line">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### ConvNet as fixed feature extractor ####</span></span><br><span class="line"><span class="comment"># Here, we need to freeze all the network except the final layer.</span></span><br><span class="line"><span class="comment"># We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()</span></span><br><span class="line">model_conv = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that only parameters of final layer are being optimized as</span></span><br><span class="line"><span class="comment"># opposed to before.</span></span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># default `log_dir` is &quot;runs&quot; - we&#x27;ll be more specific here</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/mnist1&#x27;</span>)</span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment"># 28x28</span></span><br><span class="line">hidden_size = <span class="number">500</span> </span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST dataset </span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),  </span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, </span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, </span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">example_data, example_targets = examples.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(example_data)</span><br><span class="line">writer.add_image(<span class="string">&#x27;mnist_images&#x27;</span>, img_grid)</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully connected neural network with one hidden layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.l1 = nn.Linear(input_size, hidden_size) </span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="comment"># no activation and no softmax at the end</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = NeuralNet(input_size, hidden_size, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">writer.add_graph(model, example_data.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">running_correct = <span class="number">0</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        <span class="comment"># origin shape: [100, 1, 28, 28]</span></span><br><span class="line">        <span class="comment"># resized: [100, 784]</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        running_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>, running_loss / <span class="number">100</span>, epoch * n_total_steps + i)</span><br><span class="line">            running_accuracy = running_correct / <span class="number">100</span> / predicted.size(<span class="number">0</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, running_accuracy, epoch * n_total_steps + i)</span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            <span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="comment"># In test phase, we don&#x27;t need to compute gradients (for memory efficiency)</span></span><br><span class="line">class_labels = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        values, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        class_probs_batch = [F.softmax(output, dim=<span class="number">0</span>) <span class="keyword">for</span> output <span class="keyword">in</span> outputs]</span><br><span class="line"></span><br><span class="line">        class_preds.append(class_probs_batch)</span><br><span class="line">        class_labels.append(predicted)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000, 10, and 10000, 1</span></span><br><span class="line">    <span class="comment"># stack concatenates tensors along a new dimension</span></span><br><span class="line">    <span class="comment"># cat concatenates tensors in the given dimension</span></span><br><span class="line">    class_preds = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_preds])</span><br><span class="line">    class_labels = torch.cat(class_labels)</span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network on the 10000 test images: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">    classes = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">        labels_i = class_labels == i</span><br><span class="line">        preds_i = class_preds[:, i]</span><br><span class="line">        writer.add_pr_curve(<span class="built_in">str</span>(i), labels_i, preds_i, global_step=<span class="number">0</span>)</span><br><span class="line">        writer.close()</span><br><span class="line">    <span class="comment">###################################################</span></span><br></pre></td></tr></table></figure>

<h1 id="Save-amp-Load"><a href="#Save-amp-Load" class="headerlink" title="Save &amp; Load"></a>Save &amp; Load</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 3 DIFFERENT METHODS TO REMEMBER:</span></span><br><span class="line"><span class="string"> - torch.save(arg, PATH) # can be model, tensor, or dictionary</span></span><br><span class="line"><span class="string"> - torch.load(PATH)</span></span><br><span class="line"><span class="string"> - torch.load_state_dict(arg)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 2 DIFFERENT WAYS OF SAVING</span></span><br><span class="line"><span class="string"># 1) lazy way: save whole model</span></span><br><span class="line"><span class="string">torch.save(model, PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model class must be defined somewhere</span></span><br><span class="line"><span class="string">model = torch.load(PATH)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) recommended way: save only the state_dict</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model must be created again with parameters</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line"><span class="comment"># train your model...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################save all ######################################</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save and load entire model</span></span><br><span class="line"></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model, FILE)</span><br><span class="line"></span><br><span class="line">loaded_model = torch.load(FILE)</span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> loaded_model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############save only state dict #########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save only state dict</span></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model.state_dict(), FILE)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.state_dict())</span><br><span class="line">loaded_model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">loaded_model.load_state_dict(torch.load(FILE)) <span class="comment"># it takes the loaded dictionary, not the path file itself</span></span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loaded_model.state_dict())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########load checkpoint#####################</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="string">&quot;epoch&quot;</span>: <span class="number">90</span>,</span><br><span class="line"><span class="string">&quot;model_state&quot;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&quot;optim_state&quot;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line">FILE = <span class="string">&quot;checkpoint.pth&quot;</span></span><br><span class="line">torch.save(checkpoint, FILE)</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(FILE)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state&#x27;</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optim_state&#x27;</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line"><span class="comment"># model.train()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remember that you must call model.eval() to set dropout and batch normalization layers </span></span><br><span class="line"><span class="comment"># to evaluation mode before running inference. Failing to do this will yield </span></span><br><span class="line"><span class="comment"># inconsistent inference results. If you wish to resuming training, </span></span><br><span class="line"><span class="comment"># call model.train() to ensure these layers are in training mode.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; SAVING ON GPU/CPU </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 1) Save on GPU, Load on CPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=device))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) Save on GPU, Load on GPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note: Be sure to use the .to(torch.device(&#x27;cuda&#x27;)) function </span></span><br><span class="line"><span class="string"># on all model inputs, too!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 3) Save on CPU, Load on GPU</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># This loads the model to a given GPU device. </span></span><br><span class="line"><span class="string"># Next, be sure to call model.to(torch.device(&#x27;cuda&#x27;)) to convert the model’s parameter tensors to CUDA tensors</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





























      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">冀ICP备2021011397号-1 </a>
  </div>

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Juggler</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.12.1/dist/algoliasearch-lite.umd.js" integrity="sha256-gOvJ6W+j+t/cgnnl9iUU3cb6F1WFQGDdtTXhfPjU4bc=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4.39.0/dist/instantsearch.production.min.js" integrity="sha256-+ZlQZK9m82XOYGFZCIRrPOFh2kDdAGB6e7TjWGvoaSY=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js","integrity":"sha256-7wT34TI0pEBeEFoi4z+vhuSddGh6vUTMWdqJ2SDe2jg="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.2.0/dist/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://juggler.fun/page/3/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"LoveinSun","repo":"blog-comment","client_id":"40e1002206dc11748978","client_secret":"027043262cdf608cfa6b1c20173bc245b1cff702","admin_user":"LoveinSun","distraction_free_mode":true,"proxy":"https://proxy.juggler.fun:9013/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"9d8d3da09189165dcde8f1d3e109ad78"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
