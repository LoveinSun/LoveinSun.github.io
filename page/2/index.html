<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"juggler.fun","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:type" content="website">
<meta property="og:title" content="JugglerDancing">
<meta property="og:url" content="https://juggler.fun/page/2/index.html">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="吾之生命如流星，誓要从全世界路过。">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Juggler">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://juggler.fun/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>JugglerDancing</title>
  





  <script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js" integrity="sha256-6Y7CJDaltoeNgk+ZftgCD9jLgmGv4xKUo8nQ0HgAwVo=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" integrity="sha256-uqQQGnDcmRKvhKwc5Vm4XT1GQ2oV6t1U0NR2N9tV+BQ=" crossorigin="anonymous" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
<div id="aplayer"></div>
<script type="text/javascript" src="/dist/music.js"></script>
	<div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">JugglerDancing</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Juggler is dancing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Juggler</p>
  <div class="site-description" itemprop="description">吾之生命如流星，誓要从全世界路过。</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/nacos/fastapi-nacos/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/nacos/fastapi-nacos/" class="post-title-link" itemprop="url">fastapi nacos</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-03-23 10:25:44 / Modified: 11:26:29" itemprop="dateCreated datePublished" datetime="2022-03-23T10:25:44+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/nacos/" itemprop="url" rel="index"><span itemprop="name">nacos</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nacos_py</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> munch <span class="keyword">import</span> munchify</span><br><span class="line"><span class="keyword">from</span> starlette.requests <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> starlette.responses <span class="keyword">import</span> Response</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"> </span><br><span class="line">sys.tracebacklimit = <span class="number">3</span>  <span class="comment"># 限制打印错误行数</span></span><br><span class="line"><span class="comment"># 首先配置application.properties中nacos.core.auth.enabled=true</span></span><br><span class="line"><span class="comment"># 配置nacos 用户-角色-权限</span></span><br><span class="line"> </span><br><span class="line">app = FastAPI()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># async def catch_exceptions_middleware(request: Request, call_next):</span></span><br><span class="line"><span class="comment">#     try:</span></span><br><span class="line"><span class="comment">#         return await call_next(request)</span></span><br><span class="line"><span class="comment">#     except Exception as e:</span></span><br><span class="line"><span class="comment">#         # print(e)</span></span><br><span class="line"><span class="comment">#         # print(traceback.format_list())</span></span><br><span class="line"><span class="comment">#         return Response(&quot;Internal server error&quot;, status_code=500)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># app.middleware(&#x27;http&#x27;)(catch_exceptions_middleware)</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.exception_handler(<span class="params">Exception</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">custom_http_exception_handler</span>(<span class="params">request, exc</span>):</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="string">&quot;Internal server exception&quot;</span>, status_code=<span class="number">500</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.exception_handler(<span class="params">ZeroDivisionError</span>)  </span><span class="comment"># 统一处理某些错误</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">custom_http_exception_handler</span>(<span class="params">request, exc</span>):</span><br><span class="line">    <span class="keyword">return</span> Response(<span class="string">&quot;Internal server error&quot;</span>, status_code=<span class="number">500</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">nacos</span>:</span><br><span class="line">    SERVER_ADDRESSES = <span class="string">&quot;127.0.0.1:8845&quot;</span></span><br><span class="line">    NAMESPACE = <span class="string">&quot;public&quot;</span></span><br><span class="line">    client = nacos_py.NacosClient(SERVER_ADDRESSES, namespace=NAMESPACE, username=<span class="string">&quot;pang&quot;</span>, password=<span class="string">&quot;pang&quot;</span>)</span><br><span class="line">    data_id = <span class="string">&quot;testDataId&quot;</span></span><br><span class="line">    group = <span class="string">&quot;testGroup&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_watcher</span>(<span class="params">self, methods</span>):</span><br><span class="line">        self.client.add_config_watchers(self.data_id, self.group, methods)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">self, data_id=<span class="literal">None</span>, group=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> data_id <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data_id = self.data_id</span><br><span class="line">        <span class="keyword">if</span> group <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            group = self.group</span><br><span class="line">        confi = self.client.get_config(data_id, group)</span><br><span class="line">        confi = yaml.safe_load(confi)</span><br><span class="line">        core_config = munchify(confi)</span><br><span class="line">        <span class="built_in">print</span>(core_config)</span><br><span class="line">        <span class="keyword">return</span> confi</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">args</span>):</span><br><span class="line">    <span class="keyword">global</span> config</span><br><span class="line">    config = a.get_config()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">a = nacos()</span><br><span class="line">config = a.get_config()</span><br><span class="line">a.add_watcher(&#123;call&#125;)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/print&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">root</span>():</span><br><span class="line">    var = <span class="number">1</span> / <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: config&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/prin&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">root</span>():</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: config&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/C/Azure-Service-Bus-%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E5%99%A8%E4%BB%A5%E5%8F%8A%E6%8C%89%E5%BA%8F%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/C/Azure-Service-Bus-%E5%AE%9E%E7%8E%B0%E5%AE%9A%E6%97%B6%E5%99%A8%E4%BB%A5%E5%8F%8A%E6%8C%89%E5%BA%8F%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/" class="post-title-link" itemprop="url">Azure Service Bus 实现定时器以及按序执行任务</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 18:50:13" itemprop="dateCreated datePublished" datetime="2022-03-22T18:50:13+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:20:09" itemprop="dateModified" datetime="2022-03-23T11:20:09+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C/" itemprop="url" rel="index"><span itemprop="name">C#</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"><span class="keyword">using</span> System.Threading.Tasks;</span><br><span class="line"><span class="keyword">using</span> Azure.Messaging.ServiceBus;</span><br><span class="line"><span class="keyword">using</span> System.Collections;</span><br><span class="line"><span class="keyword">using</span> Newtonsoft.Json.Linq;</span><br><span class="line"><span class="keyword">using</span> System.Collections.Generic;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">namespace</span> <span class="title">ServiceBusConsole</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">internal</span> <span class="keyword">class</span> <span class="title">Program</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// connection string to your Service Bus namespace</span></span><br><span class="line">        <span class="keyword">static</span> <span class="built_in">string</span> connectionString = <span class="string">&quot;Endpoint=sb://&quot;</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// name of your Service Bus topic</span></span><br><span class="line">        <span class="keyword">static</span> <span class="built_in">string</span> topicName = <span class="string">&quot;actieue&quot;</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">static</span> Queue&lt;<span class="built_in">string</span>&gt; a;</span><br><span class="line">        <span class="comment">// number of messages to be sent to the topic</span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">const</span> <span class="built_in">int</span> taskNumber = <span class="number">8</span>;</span><br><span class="line"> </span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">Main</span>(<span class="params"><span class="built_in">string</span>[] args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            Random random = <span class="keyword">new</span> Random();</span><br><span class="line">            a = <span class="keyword">new</span> Queue&lt;<span class="built_in">string</span>&gt;();</span><br><span class="line">            <span class="keyword">for</span>(<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; taskNumber; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                JObject jo = <span class="keyword">new</span> JObject();</span><br><span class="line">                jo[<span class="string">&quot;taskId&quot;</span>] = i;</span><br><span class="line">                jo[<span class="string">&quot;excutionTime&quot;</span>] = random.Next(<span class="number">10</span>);</span><br><span class="line">                a.Enqueue(jo.ToString());</span><br><span class="line">            &#125;</span><br><span class="line">            ArrayList b = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            b.Add(a.Dequeue());</span><br><span class="line">            sendMessage(b).Wait();</span><br><span class="line">            <span class="keyword">get</span>().Wait();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">sendMessage</span>(<span class="params">ArrayList msgs</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// the client that owns the connection and can be used to create senders and receivers</span></span><br><span class="line">            ServiceBusClient client;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// the sender used to publish messages to the topic</span></span><br><span class="line">            ServiceBusSender sender;</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// The Service Bus client types are safe to cache and use as a singleton for the lifetime</span></span><br><span class="line">            <span class="comment">// of the application, which is best practice when messages are being published or read</span></span><br><span class="line">            <span class="comment">// regularly.</span></span><br><span class="line">            <span class="comment">//</span></span><br><span class="line">            <span class="comment">// Create the clients that we&#x27;ll use for sending and processing messages.</span></span><br><span class="line">            client = <span class="keyword">new</span> ServiceBusClient(connectionString);</span><br><span class="line">            sender = client.CreateSender(topicName);</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// create a batch </span></span><br><span class="line">            ServiceBusMessageBatch messageBatch = <span class="keyword">await</span> sender.CreateMessageBatchAsync();</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">foreach</span> (Object o <span class="keyword">in</span> msgs)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="built_in">string</span> msg = (<span class="built_in">string</span>)o;</span><br><span class="line">                <span class="comment">// try adding a message to the batch</span></span><br><span class="line">                ServiceBusMessage m = <span class="keyword">new</span> ServiceBusMessage(msg);</span><br><span class="line">                JObject j = JObject.Parse(msg);</span><br><span class="line">                <span class="built_in">double</span> d = <span class="built_in">double</span>.Parse(j[<span class="string">&quot;excutionTime&quot;</span>].ToString());</span><br><span class="line">                m.ScheduledEnqueueTime = DateTimeOffset.Now.AddSeconds(d);</span><br><span class="line">                <span class="keyword">if</span> (!messageBatch.TryAddMessage(m))</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="comment">// if it is too large for the batch</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">$&quot;The message msg is too large to fit in the batch.&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Use the producer client to send the batch of messages to the Service Bus topic</span></span><br><span class="line">                <span class="keyword">await</span> sender.SendMessagesAsync(messageBatch);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">finally</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Calling DisposeAsync on client types is required to ensure that network</span></span><br><span class="line">                <span class="comment">// resources and other unmanaged objects are properly cleaned up.</span></span><br><span class="line">                messageBatch.Dispose();</span><br><span class="line">                <span class="keyword">await</span> sender.DisposeAsync();</span><br><span class="line">                <span class="keyword">await</span> client.DisposeAsync();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">get</span>()</span></span><br><span class="line">        &#123;</span><br><span class="line">            ServiceBusClient client;</span><br><span class="line">            ServiceBusProcessor processor;</span><br><span class="line">            client = <span class="keyword">new</span> ServiceBusClient(connectionString);</span><br><span class="line">            processor = client.CreateProcessor(topicName, <span class="keyword">new</span> ServiceBusProcessorOptions());</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// add handler to process messages</span></span><br><span class="line">                processor.ProcessMessageAsync += MessageHandler;</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// add handler to process any errors</span></span><br><span class="line">                processor.ProcessErrorAsync += ErrorHandler;</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// start processing </span></span><br><span class="line">                <span class="keyword">await</span> processor.StartProcessingAsync();</span><br><span class="line"> </span><br><span class="line">                Console.WriteLine(<span class="string">&quot;Start Task 0 is runing&quot;</span>);</span><br><span class="line">                Console.WriteLine(<span class="string">$&quot;It is <span class="subst">&#123;DateTimeOffset.Now&#125;</span> now&quot;</span>);</span><br><span class="line">                Console.ReadKey();</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// stop processing </span></span><br><span class="line">                Console.WriteLine(<span class="string">&quot;\nStopping the receiver...&quot;</span>);</span><br><span class="line">                <span class="keyword">await</span> processor.StopProcessingAsync();</span><br><span class="line">                Console.WriteLine(<span class="string">&quot;Stopped receiving messages&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">finally</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// Calling DisposeAsync on client types is required to ensure that network</span></span><br><span class="line">                <span class="comment">// resources and other unmanaged objects are properly cleaned up.</span></span><br><span class="line">                <span class="keyword">await</span> processor.DisposeAsync();</span><br><span class="line">                <span class="keyword">await</span> client.DisposeAsync();</span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">async</span> Task <span class="title">MessageHandler</span>(<span class="params">ProcessMessageEventArgs args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            ArrayList c = <span class="keyword">new</span> ArrayList();</span><br><span class="line">            <span class="built_in">string</span> body = args.Message.Body.ToString();</span><br><span class="line">            <span class="keyword">try</span></span><br><span class="line">            &#123;</span><br><span class="line">                c.Add(a.Dequeue());</span><br><span class="line">                sendMessage(c).Wait();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">catch</span> (Exception ex)</span><br><span class="line">            &#123;</span><br><span class="line"> </span><br><span class="line">            &#125;</span><br><span class="line"> </span><br><span class="line">            Console.WriteLine(<span class="string">$&quot;At <span class="subst">&#123;DateTimeOffset.Now&#125;</span>,This task is finished:\nReceived: <span class="subst">&#123;body&#125;</span> &quot;</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="comment">// complete the message. messages is deleted from the subscription. </span></span><br><span class="line">            <span class="keyword">await</span> args.CompleteMessageAsync(args.Message);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// handle any errors when receiving messages</span></span><br><span class="line">        <span class="function"><span class="keyword">static</span> Task <span class="title">ErrorHandler</span>(<span class="params">ProcessErrorEventArgs args</span>)</span></span><br><span class="line">        &#123;</span><br><span class="line">            Console.WriteLine(args.Exception.ToString());</span><br><span class="line">            <span class="keyword">return</span> Task.CompletedTask;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/%E6%9D%82%E8%AE%B0/%E7%A5%9D%E5%AE%89%E5%A5%BD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/%E6%9D%82%E8%AE%B0/%E7%A5%9D%E5%AE%89%E5%A5%BD/" class="post-title-link" itemprop="url">祝安好</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 11:17:52" itemprop="dateCreated datePublished" datetime="2022-03-22T11:17:52+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:24:10" itemprop="dateModified" datetime="2022-03-23T11:24:10+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9D%82%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">杂记</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>我想在早 中 晚对你说 <br>早安 午安 晚安<br>可我早已无处寻你</p>
<p>就好像四季<br>春天我见不到你 我只能带着初醒的梦 和每一朵花对话。<br>夏天我见不到你 绿皮红瓤的季节 我只能剪一头短发 把蝉鸣收藏。<br>秋天我见不到你 黄昏细雨里 我只能回忆起你熟悉的味道 让你感知我最澄澈的眷恋。<br>冬天我见不到你 冬夜渐深 细碎过往已让回忆温柔很多 于是在漫天大雪里 绵延不绝的是我对你的祝福。</p>
<p>我最喜欢的是夏夜的磅礴大雨<br>从前我享受飘摇其中的感觉<br>现在我想在其中撑起一把伞</p>
<p>可我如何前去寻你 <br>绝望疯长恣肆无所忌惮 <br>寂寞而眷恋着某个人 </p>
<p>如果此生再不能相见 <br>祝你早安 午安<br>和晚安</p>
<p>改自：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/34648905">https://www.zhihu.com/question/34648905</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/joy/%E9%A5%A5%E8%8D%92%E6%9C%8D%E5%8A%A1%E5%99%A8-docker-compose/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/joy/%E9%A5%A5%E8%8D%92%E6%9C%8D%E5%8A%A1%E5%99%A8-docker-compose/" class="post-title-link" itemprop="url">饥荒服务器_docker-compose</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:57:23" itemprop="dateCreated datePublished" datetime="2022-03-22T10:57:23+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:25:43" itemprop="dateModified" datetime="2022-03-23T11:25:43+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/joy/" itemprop="url" rel="index"><span itemprop="name">joy</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​<br>使用了大佬的代码</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Jamesits/docker-dst-server.git">https://github.com/Jamesits/docker-dst-server.git</a></p>
<p>但是在我的使用过程中一些mod总会报错，所以尝试将base-image改为ubuntu并解决相应错误后解决，由于我服务器的特殊配置，所以不得不将用户改为root：</p>
<p><a target="_blank" rel="noopener" href="https://gitee.com/dancingjoker/docker-dst-server">https://gitee.com/dancingjoker/docker-dst-server</a></p>
<p>我是使用的docker-compose up –build -d 启动，在docker-compose volumes中配置存档位置，其他方式可以视情况使用</p>
<p>另附定期备份命令：</p>
<p>在crontab -e中编写：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">13 4 * * * sudo bash /dir/dst/backup.sh</span><br></pre></td></tr></table></figure>
<p>定时可以参考网站：crontab.guru</p>
<p>backup.sh:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#/bin/bash</span></span><br><span class="line">tar -zcPvf /dir/dst/backup/b$(<span class="built_in">date</span> %Y%m%d%h%m%s).tar.gz /dir/dst/DoNotStarveTogether/Cluster_1</span><br></pre></td></tr></table></figure>
<p>​</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/NLP/NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/NLP/NLP/" class="post-title-link" itemprop="url">NLP</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:52" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:52+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:10" itemprop="dateModified" datetime="2022-03-23T11:23:10+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>[toc]</p>
<h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><table>
<thead>
<tr>
<th>-</th>
<th>-</th>
</tr>
</thead>
<tbody><tr>
<td>[ToL]</td>
<td>To learn</td>
</tr>
<tr>
<td>[ToLM]</td>
<td>To learn more</td>
</tr>
<tr>
<td>[ToLO]</td>
<td>To learn optionally</td>
</tr>
<tr>
<td>(0501)</td>
<td>05 min 01s</td>
</tr>
<tr>
<td>(h0501)</td>
<td>1 hour 05 min 01s</td>
</tr>
<tr>
<td>(hh0501)</td>
<td>2 hour 05 min 01s</td>
</tr>
</tbody></table>
<h1 id="Lecture-1-Introduction-and-Word-Vectors"><a href="#Lecture-1-Introduction-and-Word-Vectors" class="headerlink" title="Lecture 1 - Introduction and Word Vectors"></a>Lecture 1 - Introduction and Word Vectors</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/rmVRLeJRkl4?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214151948950.png" alt="image-20220214151948950"></p>
<h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><p>Convert one-hot encoding to distributed representitions</p>
<p>Ont hot can’t represent the relation between word vectors,it is too big</p>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>Ignore the position of word of context </p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135823259.png" alt="image-20220214135823259" style="zoom: 35%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135951707.png" alt="image-20220214135951707" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140036077.png" alt="image-20220214140036077" style="zoom:50%;" />

<h3 id="Use-two-vector-in-one-word-centor-word-context-word"><a href="#Use-two-vector-in-one-word-centor-word-context-word" class="headerlink" title="Use two vector in one word: centor word context word."></a>Use two vector in one word: centor word context word.</h3><h3 id="softmax-function"><a href="#softmax-function" class="headerlink" title="softmax function"></a>softmax function</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140209594.png" alt="image-20220214140209594" style="zoom:50%;" />

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141232602.png" alt="image-20220214141232602"></p>
<h3 id="Train-the-model-gradient-descent"><a href="#Train-the-model-gradient-descent" class="headerlink" title="Train the model: gradient descent"></a>Train the model: gradient descent</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141455212.png" alt="image-20220214141455212" style="zoom:50%;" />

<p><strong>There is a term to calculate the gradient descent. (39:50-56:40)</strong></p>
<p>result is :<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214143920015.png" alt="image-20220214143920015"></p>
<p><em><strong>ToL</strong></em></p>
<p>Review derivation and the following especially.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214142712551.png" alt="image-20220214142712551"></p>
<h2 id="Show-some-achievement-with-code-5640-h0516"><a href="#Show-some-achievement-with-code-5640-h0516" class="headerlink" title="Show some achievement with code(5640-h0516)"></a>Show some achievement with code(5640-h0516)</h2><ul>
<li>We can do vector addition, subtraction, multiplication and division, etc.</li>
</ul>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><p><strong>Why are there center word and context word(h0650)</strong></p>
<p>To avoid one vector dot product himself in some situation???? </p>
<p><strong>Even synonyms can be merged into a vector(h1215)</strong></p>
<p>Which is different from lee ,He says synonyms use different.</p>
<h1 id="Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers"><a href="#Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers" class="headerlink" title="Lecture 2 Word Vectors,Word Senses,and Neural Classifiers"></a>Lecture 2 Word Vectors,Word Senses,and Neural Classifiers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/gqaHkPEZAew?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152314870.png" alt="image-20220214152314870"></p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152611205.png" alt="image-20220214152611205" style="zoom:40%;" />

<h2 id="Bag-models-0245"><a href="#Bag-models-0245" class="headerlink" title="Bag models (0245)"></a>Bag models (0245)</h2><p>The model makes the same predictions at each position.</p>
<h2 id="Gradient-descent-0600"><a href="#Gradient-descent-0600" class="headerlink" title="Gradient descent (0600)"></a>Gradient descent (0600)</h2><p>Not usually use because of the big calculation.</p>
<p>step size: not too big nor too small</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214153736035.png" alt="image-20220214153736035" style="zoom:33%;" />

<h3 id="stochastic-gradient-descent-SGD-TOBELM-0920"><a href="#stochastic-gradient-descent-SGD-TOBELM-0920" class="headerlink" title="stochastic gradient descent SGD  TOBELM (0920)"></a>stochastic gradient descent SGD  TOBELM (0920)</h3><p>Take part of the corpus</p>
<p>billion faster.</p>
<p>Maybe even get better result.</p>
<p>But it is stochastic, either you need sparse matrix update operations to only update certain rows of full embedding matrices U and V, or you need to keep around a hash for vectors.(1344)<em><strong>ToL</strong></em></p>
<h2 id="more-details-of-word2vec-1400"><a href="#more-details-of-word2vec-1400" class="headerlink" title="more details of word2vec(1400)"></a>more details of word2vec(1400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214160400315.png" alt="image-20220214160400315"></p>
<h3 id="SG-use-center-to-predict-context"><a href="#SG-use-center-to-predict-context" class="headerlink" title="SG use center to predict context"></a>SG use center to predict context</h3><h4 id="SGNS-negative-sampling-ToBLO"><a href="#SGNS-negative-sampling-ToBLO" class="headerlink" title="SGNS negative sampling  [ToBLO]"></a>SGNS negative sampling  [ToBLO]</h4><p>use logistic function instead of softmax and take sampling of corpus</p>
<h3 id="CBOW-opposite"><a href="#CBOW-opposite" class="headerlink" title="CBOW opposite."></a>CBOW opposite.</h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214162201460.png" alt="image-20220214162201460" style="zoom:33%;" />

<h2 id="Why-use-two-vectors-1500"><a href="#Why-use-two-vectors-1500" class="headerlink" title="Why use two vectors(1500)"></a>Why use two vectors(1500)</h2><p>Sometime it will dot product with itself.</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214165957190.png" alt="image-20220214165957190" style="zoom:40%;" />

<p><strong>[ToL]</strong></p>
<p>The first one is positive word and the last is negative word (2800)</p>
<p>negative word is being sampled cause the center word will turn up on other occasions, when it does, there will have other sampling, and it will learn step by step.</p>
<h2 id="Why-not-capture-co-occurrence-counts-directly-2337"><a href="#Why-not-capture-co-occurrence-counts-directly-2337" class="headerlink" title="Why not capture co-occurrence counts directly?(2337)"></a>Why not capture co-occurrence counts directly?(2337)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214171624671.png" alt="image-20220214171624671"></p>
<h2 id="SVD-3230-ToL"><a href="#SVD-3230-ToL" class="headerlink" title="SVD(3230) [ToL]"></a>SVD(3230) [ToL]</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29846048">https://zhuanlan.zhihu.com/p/29846048</a></p>
<p>use svd to get lower dimensional representations for words</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214172338354.png" alt="image-20220214172338354" style="zoom:33%;" />(3451)</p>
<h2 id="Count-based-vs-direct-prediction"><a href="#Count-based-vs-direct-prediction" class="headerlink" title="Count based vs direct prediction"></a>Count based vs direct prediction</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173136681.png" alt="image-20220214173136681" style="zoom:50%;" />(3900)</p>
<h2 id="Encoing-meaning-components-in-vector-differences-3948"><a href="#Encoing-meaning-components-in-vector-differences-3948" class="headerlink" title="Encoing meaning components in vector differences(3948)"></a>Encoing meaning components in vector differences(3948)</h2><p>This is to make addition subtraction available for word vectors.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173907221.png" alt="image-20220214173907221"></p>
<h2 id="GloVe-4313"><a href="#GloVe-4313" class="headerlink" title="GloVe (4313)"></a>GloVe (4313)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214174416350.png" alt="image-20220214174416350" style="zoom: 33%;" />

<p>let dot product minus log of the co-occurrence</p>
<h2 id="How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756"><a href="#How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756" class="headerlink" title="How to evaluate word vectors Intrinsic vs. extrinsic(4756)"></a>How to evaluate word vectors Intrinsic vs. extrinsic(4756)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214175746085.png" alt="image-20220214175746085" style="zoom:50%;" />

<h3 id="Analogy-evaluation-and-hyperparameters-intrinsic-5515"><a href="#Analogy-evaluation-and-hyperparameters-intrinsic-5515" class="headerlink" title="Analogy evaluation and hyperparameters (intrinsic)(5515)"></a>Analogy evaluation and hyperparameters (intrinsic)(5515)</h3><h3 id="Word-vector-distances-and-their-correlation-with-human-judgements-5640"><a href="#Word-vector-distances-and-their-correlation-with-human-judgements-5640" class="headerlink" title="Word vector distances and their correlation with human judgements(5640)"></a>Word vector distances and their correlation with human judgements(5640)</h3><h2 id="Data-shows-that-300-dimensional-word-vector-is-good-5536"><a href="#Data-shows-that-300-dimensional-word-vector-is-good-5536" class="headerlink" title="Data shows that 300 dimensional word vector is good(5536)"></a>Data shows that 300 dimensional word vector is good(5536)</h2><h2 id="The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739"><a href="#The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739" class="headerlink" title="The objective function for the GloVe model and What log-bilinear means(5739)"></a>The objective function for the GloVe model and What log-bilinear means(5739)</h2><h2 id="Word-senses-and-word-sense-ambiguity-h0353"><a href="#Word-senses-and-word-sense-ambiguity-h0353" class="headerlink" title="Word senses and word sense ambiguity(h0353)"></a>Word senses and word sense ambiguity(h0353)</h2><p>One word different mean different vector. </p>
<p>then a word can be the sum of them all</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214184234513.png" alt="image-20220214184234513" style="zoom:33%;" />

<p>It will work good but not bad (h1200)</p>
<p>the vector is so sparse that you can separate out different senses  (h1402)</p>
<h1 id="Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning"><a href="#Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning" class="headerlink" title="Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning"></a>Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/X0Jw4kgaFlg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191638029.png" alt="image-20220214191638029"></p>
<h2 id="Need-to-be-learn-again-it-is-not-totally-understanded"><a href="#Need-to-be-learn-again-it-is-not-totally-understanded" class="headerlink" title="Need to be learn again, it is not totally understanded."></a>Need to be learn again, it is not totally understanded.</h2><h2 id="Named-Entity-Recognition-0530"><a href="#Named-Entity-Recognition-0530" class="headerlink" title="Named Entity Recognition(0530)"></a>Named Entity Recognition(0530)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214185926393.png" alt="image-20220214185926393"></p>
<h2 id="Simple-NER-0636"><a href="#Simple-NER-0636" class="headerlink" title="Simple NER (0636)"></a>Simple NER (0636)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190032048.png" alt="image-20220214190032048"></p>
<h3 id="How-the-sample-model-run-0836"><a href="#How-the-sample-model-run-0836" class="headerlink" title="How the sample model run (0836)"></a>How the sample model run (0836)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190306082.png" alt="image-20220214190306082"></p>
<h2 id="update-equation-1220"><a href="#update-equation-1220" class="headerlink" title="update equation(1220)"></a>update equation(1220)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191531863.png" alt="image-20220214191531863"></p>
<h2 id="jacobian-1811"><a href="#jacobian-1811" class="headerlink" title="jacobian(1811)"></a>jacobian(1811)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192319871.png" alt="image-20220214192319871"></p>
<h2 id="Chain-Rule-2015"><a href="#Chain-Rule-2015" class="headerlink" title="Chain Rule(2015)"></a>Chain Rule(2015)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192526698.png" alt="image-20220214192526698" style="zoom:50%;" />

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193151609.png" alt="image-20220214193151609"></p>
<h2 id="do-one-example-step-2650"><a href="#do-one-example-step-2650" class="headerlink" title="do one example step (2650)"></a>do one example step (2650)</h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193417520.png" alt="image-20220214193417520"></h2><p>hadamard product <a href="3200">ToL</a></p>
<h2 id="Reusing-Computation-3402"><a href="#Reusing-Computation-3402" class="headerlink" title="Reusing Computation(3402)"></a>Reusing Computation(3402)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215112833279.png" alt="image-20220215112833279" style="zoom:50%;" />

<h3 id="ds-x2F-dw"><a href="#ds-x2F-dw" class="headerlink" title="ds&#x2F;dw"></a>ds&#x2F;dw</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113433454.png" alt="image-20220215113433454" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113255573.png" alt="image-20220215113255573" style="zoom:50%;" />

<h2 id="Forward-and-backward-propagation-5000"><a href="#Forward-and-backward-propagation-5000" class="headerlink" title="Forward and backward propagation(5000)"></a>Forward and backward propagation(5000)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115109857.png" alt="image-20220215115109857" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115507912.png" alt="image-20220215115507912" style="zoom:50%;" />

<h2 id="An-example-5507"><a href="#An-example-5507" class="headerlink" title="An example(5507)"></a>An example(5507)</h2><p>a &#x3D; x+y</p>
<p>b &#x3D; max(y,z)</p>
<p>f &#x3D; ab</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215120119537.png" alt="image-20220215120119537" style="zoom:50%;" />

<h2 id="Compute-all-gradients-at-once-h0005"><a href="#Compute-all-gradients-at-once-h0005" class="headerlink" title="Compute all gradients at once (h0005)"></a>Compute all gradients at once (h0005)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145351805.png" alt="image-20220215145351805" style="zoom:50%;" />

<h2 id="Back-prop-in-general-computation-graph-h0800-ToL"><a href="#Back-prop-in-general-computation-graph-h0800-ToL" class="headerlink" title="Back-prop in general computation graph(h0800)[ToL]"></a>Back-prop in general computation graph(h0800)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145612746.png" alt="image-20220215145612746"></p>
<h2 id="Automatic-Differentiation-h1346"><a href="#Automatic-Differentiation-h1346" class="headerlink" title="Automatic Differentiation(h1346)"></a>Automatic Differentiation(h1346)</h2><p><strong>Many tools can calculate automaticly</strong>.<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215151328471.png" alt="image-20220215151328471"></p>
<h2 id="Manual-Gradient-checking-Numeric-Gradient-h1900"><a href="#Manual-Gradient-checking-Numeric-Gradient-h1900" class="headerlink" title="Manual Gradient checking : Numeric Gradient(h1900)"></a>Manual Gradient checking : Numeric Gradient(h1900)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152039987.png" alt="image-20220215152039987" style="zoom:50%;" />

<h1 id="Lecture-4-Dependency-Parsing"><a href="#Lecture-4-Dependency-Parsing" class="headerlink" title="Lecture 4 Dependency Parsing"></a>Lecture 4 Dependency Parsing</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PSGIodTN3KE?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152912089.png" alt="image-20220215152912089"></p>
<h2 id="Two-views-of-linguistic-structure"><a href="#Two-views-of-linguistic-structure" class="headerlink" title="Two views of linguistic structure"></a>Two views of linguistic structure</h2><h3 id="Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331"><a href="#Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331" class="headerlink" title="Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)"></a>Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)</h3><p><strong>Phrase structure organizes words into nested constituents</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155446438.png" alt="image-20220215155446438"></p>
<h3 id="Dependency-structure-1449"><a href="#Dependency-structure-1449" class="headerlink" title="Dependency structure(1449)"></a>Dependency structure(1449)</h3><p><strong>Dependency structure shows which words depend on (modify, attach to,or are arguments of)</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155924838.png" alt="image-20220215155924838"></p>
<h2 id="Why-do-we-need-sentence-structure-2205"><a href="#Why-do-we-need-sentence-structure-2205" class="headerlink" title="Why do  we need sentence structure?(2205)"></a>Why do  we need sentence structure?(2205)</h2><p><strong>Can not express meaning by just one word</strong>.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215160252254.png" alt="image-20220215160252254"></p>
<h2 id="Prepositional-phrase-attachment-ambiguity-2422"><a href="#Prepositional-phrase-attachment-ambiguity-2422" class="headerlink" title="Prepositional phrase attachment ambiguity.(2422)"></a>Prepositional phrase attachment ambiguity.(2422)</h2><p>There is some sentence to show it:</p>
<h3 id="San-Jose-cops-kill-man-with-knife"><a href="#San-Jose-cops-kill-man-with-knife" class="headerlink" title="San Jose cops kill man with knife"></a>San Jose cops kill man with knife</h3><p><strong>Scientists count whales from space</strong></p>
<p><strong>The board approved [its acquisition] [by Royal Trustco Ltd.] [of Toronto] [for $27 a share] [at its monthly meeting].</strong></p>
<h2 id="Coordination-scope-ambiguity-3614"><a href="#Coordination-scope-ambiguity-3614" class="headerlink" title="Coordination scope ambiguity(3614)"></a>Coordination scope ambiguity(3614)</h2><p>**Shuttle veteran and longtime NASA executive Fred Gregory appointed to board **</p>
<p><strong>Doctor: No heart, cognitive issues</strong></p>
<h2 id="Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755"><a href="#Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755" class="headerlink" title="Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)"></a>Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)</h2><p><strong>Students get [first hand job] experience</strong> <strong>Students get first [hand job] experience</strong></p>
<h2 id="Verb-Phrase-VP-attachment-ambiguity-4404"><a href="#Verb-Phrase-VP-attachment-ambiguity-4404" class="headerlink" title="Verb Phrase(VP) attachment ambiguity(4404)"></a>Verb Phrase(VP) attachment ambiguity(4404)</h2><p>Mutilated body washes up on Rio beach to be used for Olympics beach volleyball.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163226892.png" alt="image-20220215163226892"></p>
<h2 id="Dependency-Grammar-and-Dependency-structure-4355"><a href="#Dependency-Grammar-and-Dependency-structure-4355" class="headerlink" title="Dependency Grammar and Dependency structure(4355)"></a>Dependency Grammar and Dependency structure(4355)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163439157.png" alt="image-20220215163439157"></p>
<h3 id="Will-add-a-fake-ROOT-for-handy"><a href="#Will-add-a-fake-ROOT-for-handy" class="headerlink" title="Will add a fake ROOT for handy"></a>Will add a fake ROOT for handy</h3><h2 id="Dependency-Grammar-history-4742"><a href="#Dependency-Grammar-history-4742" class="headerlink" title="Dependency Grammar history(4742)"></a>Dependency Grammar history(4742)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163821573.png" alt="image-20220215163821573"> </p>
<h2 id="The-rise-of-annotated-data-Universal-Dependency-tree-5100"><a href="#The-rise-of-annotated-data-Universal-Dependency-tree-5100" class="headerlink" title="The rise of annotated data Universal Dependency tree(5100)"></a>The rise of annotated data Universal Dependency tree(5100)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215164213166.png" alt="image-20220215164213166"></p>
<h3 id="Tree-bank-5400"><a href="#Tree-bank-5400" class="headerlink" title="Tree bank(5400)"></a>Tree bank(5400)</h3><p><strong>Its too slow to write a grammar by hand but its still worth,cause it can used in another place but not only nlp</strong> .</p>
<h2 id="how-to-build-parser-with-dependency-5738"><a href="#how-to-build-parser-with-dependency-5738" class="headerlink" title="how to build parser with dependency(5738)"></a>how to build parser with dependency(5738)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165030760.png" alt="image-20220215165030760"></p>
<h2 id="Dependency-Parsing"><a href="#Dependency-Parsing" class="headerlink" title="Dependency Parsing"></a>Dependency Parsing</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165444250.png" alt="image-20220215165444250"></p>
<h3 id="Projectivity-h0416"><a href="#Projectivity-h0416" class="headerlink" title="Projectivity(h0416)"></a>Projectivity(h0416)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165801145.png" alt="image-20220215165801145"></p>
<h2 id="Methods-of-Dependency-Parsing-h0521"><a href="#Methods-of-Dependency-Parsing-h0521" class="headerlink" title="Methods of Dependency Parsing(h0521)"></a>Methods of Dependency Parsing(h0521)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170003800.png" alt="image-20220215170003800"></p>
<h2 id="Greedy-transition-based-parsing-h0621"><a href="#Greedy-transition-based-parsing-h0621" class="headerlink" title="Greedy transition-based parsing(h0621)"></a>Greedy transition-based parsing(h0621)</h2><h2 id="Basic-transition-based-dependency-parser-h0808"><a href="#Basic-transition-based-dependency-parser-h0808" class="headerlink" title="Basic transition-based dependency parser (h0808)"></a>Basic transition-based dependency parser (h0808)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170303720.png" alt="image-20220215170303720"></p>
<p><strong>[root] I ate fish</strong></p>
<p><strong>[root I ate] fish</strong></p>
<p><strong>[root ate] fish</strong></p>
<p><strong>[root ate fish]</strong></p>
<p><strong>[root ate]</strong></p>
<p><strong>[root]</strong></p>
<h2 id="MaltParser-h1351-ToL"><a href="#MaltParser-h1351-ToL" class="headerlink" title="MaltParser(h1351)[ToL]"></a>MaltParser(h1351)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215171511327.png" alt="image-20220215171511327"></p>
<h2 id="Evaluation-of-Dependency-Parsing-h1845-ToL"><a href="#Evaluation-of-Dependency-Parsing-h1845-ToL" class="headerlink" title="Evaluation of Dependency Parsing (h1845)[ToL]"></a>Evaluation of Dependency Parsing (h1845)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215172606079.png" alt="image-20220215172606079"></p>
<h1 id="Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs"><a href="#Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs" class="headerlink" title="Lecture-5 Languages models and Recurrent Neural Networks(RNNs)"></a>Lecture-5 Languages models and Recurrent Neural Networks(RNNs)</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PLryWeHPcBs?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215173841609.png" alt="image-20220215173841609"></p>
<h2 id="A-neural-dependency-parser-0624"><a href="#A-neural-dependency-parser-0624" class="headerlink" title="A neural dependency parser(0624)"></a>A neural dependency parser(0624)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215175916431.png" alt="image-20220215175916431"></p>
<h2 id="Distributed-Representations-0945"><a href="#Distributed-Representations-0945" class="headerlink" title="Distributed Representations(0945)"></a>Distributed Representations(0945)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180234046.png" alt="image-20220215180234046##"></p>
<h2 id="Deep-Learning-Classifier-are-non-linear-classifiers-1210"><a href="#Deep-Learning-Classifier-are-non-linear-classifiers-1210" class="headerlink" title="Deep Learning Classifier are non-linear classifiers(1210)"></a>Deep Learning Classifier are non-linear classifiers(1210)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180544369.png" alt="image-20220215180544369"></p>
<p>Deep Learning Classifier’s non-linear classifiers:</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180703045.png" alt="image-20220215180703045"></p>
<h2 id="Simple-feed-forward-neural-network-multi-class-classifier-1621"><a href="#Simple-feed-forward-neural-network-multi-class-classifier-1621" class="headerlink" title="Simple feed-forward neural network multi-class classifier (1621)"></a>Simple feed-forward neural network multi-class classifier (1621)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215181359982.png" alt="image-20220215181359982"></p>
<h2 id="Neural-Dependency-Parser-Model-Architecture-1730"><a href="#Neural-Dependency-Parser-Model-Architecture-1730" class="headerlink" title="Neural Dependency Parser Model Architecture(1730)"></a>Neural Dependency Parser Model Architecture(1730)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182714531.png" alt="image-20220215182714531"></p>
<h2 id="Graph-based-dependency-parsers-2044"><a href="#Graph-based-dependency-parsers-2044" class="headerlink" title="Graph-based dependency parsers (2044)"></a>Graph-based dependency parsers (2044)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182932684.png" alt="image-20220215182932684"></p>
<h2 id="Regularization-amp-amp-Overfitting-2529"><a href="#Regularization-amp-amp-Overfitting-2529" class="headerlink" title="Regularization &amp;&amp; Overfitting (2529)"></a>Regularization &amp;&amp; Overfitting (2529)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215183327050.png" alt="image-20220215183327050"></p>
<h2 id="Dropout-3100-ToL"><a href="#Dropout-3100-ToL" class="headerlink" title="Dropout (3100)[ToL]"></a>Dropout (3100)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184016985.png" alt="image-20220215184016985"></p>
<h2 id="Vectorization-3333"><a href="#Vectorization-3333" class="headerlink" title="Vectorization(3333)"></a>Vectorization(3333)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184453079.png" alt="image-20220215184453079"></p>
<h2 id="Non-linearities-4000"><a href="#Non-linearities-4000" class="headerlink" title="Non-linearities (4000)"></a>Non-linearities (4000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185618924.png" alt="image-20220215185618924"></p>
<h2 id="Parameter-Initialization-4357"><a href="#Parameter-Initialization-4357" class="headerlink" title="Parameter Initialization (4357)"></a>Parameter Initialization (4357)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185707615.png" alt="image-20220215185707615"></p>
<h2 id="Optimizers-4617"><a href="#Optimizers-4617" class="headerlink" title="Optimizers(4617)"></a>Optimizers(4617)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185920518.png" alt="image-20220215185920518"></p>
<h2 id="Learning-Rates-4810"><a href="#Learning-Rates-4810" class="headerlink" title="Learning Rates(4810)"></a>Learning Rates(4810)</h2><p>It can be slow as the learning  go on.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190108626.png" alt="image-20220215190108626"></p>
<h2 id="Language-Modeling-5036"><a href="#Language-Modeling-5036" class="headerlink" title="Language Modeling (5036)"></a>Language Modeling (5036)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190413343.png" alt="image-20220215190413343"></p>
<h2 id="n-gram-Language-Models-5356"><a href="#n-gram-Language-Models-5356" class="headerlink" title="n-gram Language Models(5356)"></a>n-gram Language Models(5356)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190718037.png" alt="image-20220215190718037" style="zoom: 50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190841180.png" alt="image-20220215190841180" style="zoom:50%;" />

<h2 id="Sparsity-Problems-5922"><a href="#Sparsity-Problems-5922" class="headerlink" title="Sparsity Problems (5922)"></a>Sparsity Problems (5922)</h2><p><em>Many situation didn’t occur so it will be zero</em></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215191735246.png" alt="image-20220215191735246"></p>
<h2 id="Storage-Problems-h0117"><a href="#Storage-Problems-h0117" class="headerlink" title="Storage Problems(h0117)"></a>Storage Problems(h0117)</h2><h2 id="How-to-build-a-neural-language-model-h0609"><a href="#How-to-build-a-neural-language-model-h0609" class="headerlink" title="How to build a neural language model(h0609)"></a>How to build a neural language model(h0609)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215192255066.png" alt="image-20220215192255066"></p>
<h2 id="A-fixed-window-neural-Language-Model-h1100"><a href="#A-fixed-window-neural-Language-Model-h1100" class="headerlink" title="A fixed-window neural Language Model(h1100)"></a>A fixed-window neural Language Model(h1100)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216103904942.png" alt="image-20220216103904942"></p>
<h2 id="Recurrent-Neural-Network-RNN-h1250"><a href="#Recurrent-Neural-Network-RNN-h1250" class="headerlink" title="Recurrent Neural Network (RNN)(h1250)"></a>Recurrent Neural Network (RNN)(h1250)</h2><p>x1 -&gt; y1</p>
<p>Wx1 x2 -&gt; y1</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216105731982.png" alt="image-20220216105731982"></p>
<h2 id="A-Simple-RNN-Language-Model-h1430"><a href="#A-Simple-RNN-Language-Model-h1430" class="headerlink" title="A Simple RNN Language Model(h1430)"></a>A Simple RNN Language Model(h1430)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110248289.png" alt="image-20220216110248289"></p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110444328.png" alt="image-20220216110444328" style="zoom: 67%;" />

<h1 id="Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks"><a href="#Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks" class="headerlink" title="Lecture 6 Simple and LSTM Recurrent Neural Networks."></a>Lecture 6 Simple and LSTM Recurrent Neural Networks.</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/0LixFSa7yts?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110620895.png" alt="image-20220216110620895"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216111222942.png" alt="image-20220216111222942"></p>
<h2 id="The-Simple-RNN-Language-Model-0310"><a href="#The-Simple-RNN-Language-Model-0310" class="headerlink" title="The Simple RNN Language Model (0310)"></a>The Simple RNN Language Model (0310)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112005817.png" alt="image-20220216112005817"></p>
<h2 id="Training-an-RNN-Language-Model-0818"><a href="#Training-an-RNN-Language-Model-0818" class="headerlink" title="Training an RNN Language Model (0818)"></a>Training an RNN Language Model (0818)</h2><p>RNN takes more time.</p>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h3><p>penalize when dont take its advise</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112357329.png" alt="image-20220216112357329"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112814935.png" alt="image-20220216112814935"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113456552.png" alt="image-20220216113456552"></p>
<p>But how do we get the answer?</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113810612.png" alt="image-20220216113810612"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216114843011.png" alt="image-20220216114843011"></p>
<h2 id="Evaluating-Language-Models-2447-ToL"><a href="#Evaluating-Language-Models-2447-ToL" class="headerlink" title="Evaluating Language Models (2447)[ToL]"></a>Evaluating Language Models (2447)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216115442761.png" alt="image-20220216115442761"></p>
<h2 id="Language-Model-is-a-system-that-predicts-the-next-word-3130"><a href="#Language-Model-is-a-system-that-predicts-the-next-word-3130" class="headerlink" title="Language Model is a  system that predicts the next word(3130)"></a>Language Model is a  system that predicts the next word(3130)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120043119.png" alt="image-20220216120043119"></p>
<h2 id="Other-use-of-RNN-3229"><a href="#Other-use-of-RNN-3229" class="headerlink" title="Other use of RNN(3229)"></a>Other use of RNN(3229)</h2><h3 id="Tag-for-word"><a href="#Tag-for-word" class="headerlink" title="Tag for word"></a>Tag for word</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120154220.png" alt="image-20220216120154220"></p>
<h3 id="Used-for-classification-3420"><a href="#Used-for-classification-3420" class="headerlink" title="Used for classification(3420)"></a>Used for classification(3420)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120331039.png" alt="image-20220216120331039"></p>
<h3 id="Used-to-Language-encoder-module-3500"><a href="#Used-to-Language-encoder-module-3500" class="headerlink" title="Used to Language encoder module (3500)"></a>Used to Language encoder module (3500)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120515954.png" alt="image-20220216120515954"></p>
<h3 id="Used-to-generate-text-3600"><a href="#Used-to-generate-text-3600" class="headerlink" title="Used to generate text (3600)"></a>Used to generate text (3600)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120602654.png" alt="image-20220216120602654"></p>
<h2 id="Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT"><a href="#Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT" class="headerlink" title="Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]"></a>Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120728010.png" alt="image-20220216120728010"></p>
<p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120836593.png" alt="image-20220216120836593"></p>
<h3 id="Why-This-is-a-problem-4400"><a href="#Why-This-is-a-problem-4400" class="headerlink" title="Why This is a  problem (4400)"></a>Why This is a  problem (4400)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121352667.png" alt="image-20220216121352667"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121537213.png" alt="image-20220216121537213"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121801767.png" alt="image-20220216121801767"></p>
<p>We can give him a limit.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121845504.png" alt="image-20220216121845504"></p>
<h2 id="Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL"><a href="#Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL" class="headerlink" title="Long Short Term Memory RNNS(LSTMS)(5000)[ToL]"></a>Long Short Term Memory RNNS(LSTMS)(5000)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216142509947.png" alt="image-20220216142509947"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143131901.png" alt="image-20220216143131901"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143953637.png" alt="image-20220216143953637"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216145201781.png" alt="image-20220216145201781"></p>
<h2 id="Bidirectional-RNN-h2000"><a href="#Bidirectional-RNN-h2000" class="headerlink" title="Bidirectional RNN (h2000)"></a>Bidirectional RNN (h2000)</h2><p>We need information from the word after</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150058982.png" alt="image-20220216150058982"></p>
<h1 id="Lecture-7-Translation-Seq2Seq-Attention"><a href="#Lecture-7-Translation-Seq2Seq-Attention" class="headerlink" title="Lecture-7 Translation, Seq2Seq, Attention"></a>Lecture-7 Translation, Seq2Seq, Attention</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/wzfWHP6SXxY?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150827060.png" alt="image-20220216150827060"></p>
<h2 id="Machine-Translation-0245"><a href="#Machine-Translation-0245" class="headerlink" title="Machine Translation(0245)"></a>Machine Translation(0245)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216152638415.png" alt="image-20220216152638415"></p>
<h3 id="What-do-you-need-1200"><a href="#What-do-you-need-1200" class="headerlink" title="What do you need (1200)"></a>What do you need (1200)</h3><p><strong>you need parallel corpus,Then you need alignment</strong></p>
<h2 id="Decoding-for-SMT-1748"><a href="#Decoding-for-SMT-1748" class="headerlink" title="Decoding for SMT(1748)"></a>Decoding for SMT(1748)</h2><p>Try many possible sequences.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216153938352.png" alt="image-20220216153938352"></p>
<h2 id="What-is-Neural-Machine-Translation-NMT-2130"><a href="#What-is-Neural-Machine-Translation-NMT-2130" class="headerlink" title="What is Neural Machine Translation(NMT)(2130)"></a>What is Neural Machine Translation(NMT)(2130)</h2><p>Neural Machine Translation(NMT) is a way to do Machine Translation with a single end-to-end neural net work.</p>
<p>The neural network architecture is called sequence-to-sequence model(aka seq2seq) and it involves RNNs</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216154743629.png" alt="image-20220216154743629"></p>
<h2 id="Seq2seq-is-more-than-MT-2600"><a href="#Seq2seq-is-more-than-MT-2600" class="headerlink" title="Seq2seq is more than MT(2600)"></a>Seq2seq is more than MT(2600)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216155851923.png" alt="image-20220216155851923"></p>
<h2 id="2732-ToL"><a href="#2732-ToL" class="headerlink" title="(2732)[ToL]"></a>(2732)[ToL]</h2><h2 id="Multi-layer-RNNs-3323"><a href="#Multi-layer-RNNs-3323" class="headerlink" title="Multi-layer RNNs(3323)"></a>Multi-layer RNNs(3323)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216160937711.png" alt="image-20220216160937711"></p>
<p>Lower-level basic meaning</p>
<p>Higher-level overall meaning</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161044182.png" alt="image-20220216161044182"></p>
<h2 id="Greedy-decoding-4000"><a href="#Greedy-decoding-4000" class="headerlink" title="Greedy decoding(4000)"></a>Greedy decoding(4000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161822091.png" alt="image-20220216161822091"></p>
<h2 id="Exhaustive-search-decoding-4200"><a href="#Exhaustive-search-decoding-4200" class="headerlink" title="Exhaustive search decoding(4200)"></a>Exhaustive search decoding(4200)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161859032.png" alt="image-20220216161859032"></p>
<h2 id="beam-search-decoding-4400"><a href="#beam-search-decoding-4400" class="headerlink" title="beam search decoding(4400)"></a>beam search decoding(4400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162108945.png" alt="image-20220216162108945"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162654834.png" alt="image-20220216162654834"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163345111.png" alt="image-20220216163345111"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163610037.png" alt="image-20220216163610037"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163703962.png" alt="image-20220216163703962"></p>
<h2 id="How-do-we-evaluate-Machine-Translation-5550"><a href="#How-do-we-evaluate-Machine-Translation-5550" class="headerlink" title="How do we evaluate Machine Translation(5550)"></a>How do we evaluate Machine Translation(5550)</h2><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163928786.png" alt="image-20220216163928786"></p>
<h2 id="NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000"><a href="#NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000" class="headerlink" title="NMT perhaps the biggest success story of NLP Deep Learning(h00000)"></a>NMT perhaps the biggest success story of NLP Deep Learning(h00000)</h2><h2 id="Attention-h1300"><a href="#Attention-h1300" class="headerlink" title="Attention(h1300)"></a>Attention(h1300)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165707869.png" alt="image-20220216165707869"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165937488.png" alt="image-20220216165937488"></p>
<h1 id="Lecture-8-Final-Projects-Practical-Tips"><a href="#Lecture-8-Final-Projects-Practical-Tips" class="headerlink" title="Lecture 8  Final Projects; Practical Tips"></a>Lecture 8  Final Projects; Practical Tips</h1><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216170053324.png" alt="image-20220216170053324"></p>
<h2 id="Sequence-to-Sequence-with-attention-0235"><a href="#Sequence-to-Sequence-with-attention-0235" class="headerlink" title="Sequence to Sequence with attention(0235)"></a>Sequence to Sequence with attention(0235)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216173442920.png" alt="image-20220216173442920"></p>
<h2 id="Attention-in-equations-0800"><a href="#Attention-in-equations-0800" class="headerlink" title="Attention: in equations(0800)"></a>Attention: in equations(0800)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174203323.png" alt="image-20220216174203323"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174430719.png" alt="image-20220216174430719"></p>
<h2 id="there-are-several-attention-variants-1500"><a href="#there-are-several-attention-variants-1500" class="headerlink" title="there are several attention variants(1500)"></a>there are several attention variants(1500)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174747222.png" alt="image-20220216174747222"></p>
<h2 id="Attention-is-a-general-Deep-Learning-technique-2240"><a href="#Attention-is-a-general-Deep-Learning-technique-2240" class="headerlink" title="Attention is a general Deep Learning technique(2240)"></a>Attention is a general Deep Learning technique(2240)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216175744427.png" alt="image-20220216175744427"></p>
<h2 id="Final-Project-3000"><a href="#Final-Project-3000" class="headerlink" title="Final Project(3000)"></a>Final Project(3000)</h2><h1 id="Lecture-9-Self-Attention-and-Transformers"><a href="#Lecture-9-Self-Attention-and-Transformers" class="headerlink" title="Lecture-9  Self- Attention and Transformers"></a>Lecture-9  Self- Attention and Transformers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/ptuGllU5SQQ?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Issues-with-recurrent-models-0434"><a href="#Issues-with-recurrent-models-0434" class="headerlink" title="Issues with recurrent models (0434)"></a>Issues with recurrent models (0434)</h2><h3 id="Linear-interaction-distance"><a href="#Linear-interaction-distance" class="headerlink" title="Linear interaction distance"></a>Linear interaction distance</h3><p>Sometimes it is too far too learn from the words.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184249889.png" alt="image-20220216184249889"></p>
<h3 id="Lack-of-parallelizability-0723"><a href="#Lack-of-parallelizability-0723" class="headerlink" title="Lack of parallelizability(0723)"></a>Lack of parallelizability(0723)</h3><p>GPU can count parallelizable but RNN lacks that.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184542395.png" alt="image-20220216184542395"></p>
<h2 id="If-not-recurrence"><a href="#If-not-recurrence" class="headerlink" title="If not recurrence"></a>If not recurrence</h2><h3 id="Word-window-models-aggregate-local-contexts-1031"><a href="#Word-window-models-aggregate-local-contexts-1031" class="headerlink" title="Word window models aggregate local contexts (1031)"></a>Word window models aggregate local contexts (1031)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113153381.png" alt="image-20220217113153381"></p>
<h3 id="Attention-1406"><a href="#Attention-1406" class="headerlink" title="Attention(1406)"></a>Attention(1406)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113459930.png" alt="image-20220217113459930"></p>
<h2 id="Self-Attention-1638"><a href="#Self-Attention-1638" class="headerlink" title="Self-Attention(1638)"></a>Self-Attention(1638)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217114733959.png" alt="image-20220217114733959"></p>
<h2 id="Self-attention-as-an-nlp-building-block-2222"><a href="#Self-attention-as-an-nlp-building-block-2222" class="headerlink" title="Self-attention as an nlp building block(2222)"></a>Self-attention as an nlp building block(2222)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217115247771.png" alt="image-20220217115247771"></p>
<h2 id="Fix-the-first-self-attention-problem"><a href="#Fix-the-first-self-attention-problem" class="headerlink" title="Fix the first self-attention problem"></a>Fix the first self-attention problem</h2><h3 id="sequence-order-2423"><a href="#sequence-order-2423" class="headerlink" title="sequence order (2423)"></a>sequence order (2423)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120240889.png" alt="image-20220217120240889"></p>
<h4 id="Position-representation-vector-through-sinusoids-2624"><a href="#Position-representation-vector-through-sinusoids-2624" class="headerlink" title="Position representation vector through sinusoids(2624)"></a>Position representation vector through sinusoids(2624)</h4><h5 id="Sinusoidal-position-representations-2730"><a href="#Sinusoidal-position-representations-2730" class="headerlink" title="Sinusoidal position representations(2730)"></a>Sinusoidal position representations(2730)</h5><h5 id="Position-representation-vector-from-scratch-2830"><a href="#Position-representation-vector-from-scratch-2830" class="headerlink" title="Position representation vector from scratch(2830)"></a>Position representation vector from scratch(2830)</h5><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120619459.png" alt="image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459"></p>
<h3 id="Adding-nonlinearities-in-self-attention-2953"><a href="#Adding-nonlinearities-in-self-attention-2953" class="headerlink" title="Adding nonlinearities in self-attention(2953)"></a>Adding nonlinearities in self-attention(2953)</h3><h2 id="Barriers-and-solutions-for-Self-Attention-as-building-block-2945"><a href="#Barriers-and-solutions-for-Self-Attention-as-building-block-2945" class="headerlink" title="Barriers and solutions for Self-Attention as building block(2945)"></a>Barriers and solutions for Self-Attention as building block(2945)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185604333.png" alt="image-20220221185604333"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185720186.png" alt="image-20220221185720186"></p>
<p>(3040)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185116405.png" alt="image-20220221185116405"></p>
<p>(3428)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185521157.png" alt="image-20220221185521157"></p>
<h2 id="The-transformer-encoder-decoder-3638"><a href="#The-transformer-encoder-decoder-3638" class="headerlink" title="The transformer encoder-decoder(3638)"></a>The transformer encoder-decoder(3638)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185909509.png" alt="image-20220221185909509"></p>
<p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190102912.png" alt="image-20220221190102912"></p>
<h3 id="key-query-value-4000"><a href="#key-query-value-4000" class="headerlink" title="key query value(4000)"></a>key query value(4000)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190217303.png" alt="image-20220221190217303"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190523039.png" alt="image-20220221190523039"></p>
<h3 id="Multi-headed-attention-4322"><a href="#Multi-headed-attention-4322" class="headerlink" title="Multi-headed attention (4322)"></a>Multi-headed attention (4322)</h3><p>(4450)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190908268.png" alt="image-20220221190908268"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190957705.png" alt="image-20220221190957705"></p>
<h2 id="Residual-connections-4723"><a href="#Residual-connections-4723" class="headerlink" title="Residual connections(4723)"></a>Residual connections(4723)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191310743.png" alt="image-20220221191310743"></p>
<h2 id="Layer-normalization-5045"><a href="#Layer-normalization-5045" class="headerlink" title="Layer normalization(5045)"></a>Layer normalization(5045)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191749317.png" alt="image-20220221191749317"></p>
<h2 id="Scaled-fot-product-5415"><a href="#Scaled-fot-product-5415" class="headerlink" title="Scaled fot product(5415)"></a>Scaled fot product(5415)</h2><h1 id="Lecture-10-Transformers-and-Pretraining"><a href="#Lecture-10-Transformers-and-Pretraining" class="headerlink" title="Lecture 10 - Transformers and Pretraining"></a>Lecture 10 - Transformers and Pretraining</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/j9AcEI98C0o?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224134741859.png" alt="image-20220224134741859"></p>
<h2 id="Word-structure-and-subword-models-0300"><a href="#Word-structure-and-subword-models-0300" class="headerlink" title="Word structure and subword models(0300)"></a>Word structure and subword models(0300)</h2><p>transform transformerify</p>
<p>taaaasty</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224135937734.png" alt="image-20220224135937734"></p>
<h2 id="The-byte-pair-encoding-0659"><a href="#The-byte-pair-encoding-0659" class="headerlink" title="The byte-pair encoding(0659)"></a>The byte-pair encoding(0659)</h2><p>Subwords model learn the structure of word. The byte-pair between it and  dont learn structure.</p>
<p>(0943)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145251761.png" alt="image-20220224145251761"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145105071.png" alt="image-20220224145105071"></p>
<h2 id="Motivating-word-meaning-and-context-1556"><a href="#Motivating-word-meaning-and-context-1556" class="headerlink" title="Motivating word meaning and context(1556)"></a>Motivating word meaning and context(1556)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145804570.png" alt="image-20220224145804570"></p>
<h2 id="Pretraining-whole-models-2000"><a href="#Pretraining-whole-models-2000" class="headerlink" title="Pretraining whole models(2000)"></a>Pretraining whole models(2000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145922233.png" alt="image-20220224145922233"></p>
<p>Wordv2vec dont consider context but we can use LSTM to achieve that.</p>
<p><strong>Mask some data and pretrain the model with them.</strong></p>
<h2 id="this-model-haven’t-met-overfitting-now-you-can-save-some-data-to-test-it-2811"><a href="#this-model-haven’t-met-overfitting-now-you-can-save-some-data-to-test-it-2811" class="headerlink" title="this model haven’t met overfitting now, you can save some data to test it.(2811)"></a>this model haven’t met overfitting now, you can save some data to test it.(2811)</h2><h2 id="transformers-for-encoding-and-decoding-3030"><a href="#transformers-for-encoding-and-decoding-3030" class="headerlink" title="transformers for encoding and decoding (3030)"></a>transformers for encoding and decoding (3030)</h2><h2 id="Pretraining-through-language-modeling-3400"><a href="#Pretraining-through-language-modeling-3400" class="headerlink" title="Pretraining through language modeling(3400)"></a>Pretraining through language modeling(3400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151624946.png" alt="image-20220224151624946"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151950866.png" alt="image-20220224151950866"></p>
<h2 id="Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740"><a href="#Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740" class="headerlink" title="Stochastic gradient descent and pretrain&#x2F;finetune(3740)"></a>Stochastic gradient descent and pretrain&#x2F;finetune(3740)</h2><h2 id="Model-pretraining-has-three-ways-4021"><a href="#Model-pretraining-has-three-ways-4021" class="headerlink" title="Model pretraining has three ways (4021)"></a>Model pretraining has three ways (4021)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152730308.png" alt="image-20220224152730308"></p>
<p><strong>Decoder can see the history, the Encoder can also the future.</strong></p>
<p>Encoder-Decoder maybe is the better.</p>
<h3 id="Decoder-4300"><a href="#Decoder-4300" class="headerlink" title="Decoder(4300)"></a>Decoder(4300)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152938046.png" alt="image-20220224152938046"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153716173.png" alt="image-20220224153716173"></p>
<h2 id="Generative-Pretrained-Transformer-GPT-4818"><a href="#Generative-Pretrained-Transformer-GPT-4818" class="headerlink" title="Generative Pretrained Transformer(GPT) (4818)"></a>Generative Pretrained Transformer(GPT) (4818)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153928012.png" alt="image-20220224153928012"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154243901.png" alt="image-20220224154243901"></p>
<h2 id="GPT2-5400"><a href="#GPT2-5400" class="headerlink" title="GPT2(5400)"></a>GPT2(5400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154759716.png" alt="image-20220224154759716"></p>
<h2 id="Pretraining-Encoding-5545"><a href="#Pretraining-Encoding-5545" class="headerlink" title="Pretraining Encoding(5545)"></a>Pretraining Encoding(5545)</h2><h3 id="Bert-5654"><a href="#Bert-5654" class="headerlink" title="(Bert)(5654)"></a>(Bert)(5654)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241654601.png" alt="image-20220224165457421"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241652887.png" alt="image-20220224165235710"></p>
<p><strong>Bert will mask some words, ask what have I mask</strong></p>
<h2 id="Bidirectional-encoder-representations-from-transformers-h0100"><a href="#Bidirectional-encoder-representations-from-transformers-h0100" class="headerlink" title="Bidirectional encoder representations from transformers(h0100)"></a>Bidirectional encoder representations from transformers(h0100)</h2><p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241703566.png" alt="image-20220224170312332"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241704798.png" alt="image-20220224170413603"></p>
<h2 id="Limitations-of-pretrained-encoders-h0900"><a href="#Limitations-of-pretrained-encoders-h0900" class="headerlink" title="Limitations of pretrained encoders(h0900)"></a>Limitations of pretrained encoders(h0900)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241712192.png" alt="image-20220224171252011"></p>
<h2 id="Extensions-of-BERT-h1000"><a href="#Extensions-of-BERT-h1000" class="headerlink" title="Extensions of BERT(h1000)"></a>Extensions of BERT(h1000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241714640.png" alt="image-20220224171454465"></p>
<h2 id="Pretraining-Encoder-Decoder-h1200"><a href="#Pretraining-Encoder-Decoder-h1200" class="headerlink" title="Pretraining Encoder-Decoder (h1200)"></a>Pretraining Encoder-Decoder (h1200)</h2><h3 id="T5-h1500"><a href="#T5-h1500" class="headerlink" title="T5(h1500)"></a>T5(h1500)</h3><p><strong>The model even dont know how many words are masked</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241723663.png" alt="image-20220224172344435"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241725878.png" alt="image-20220224172541657"></p>
<p><strong>In the pretraining the model learned a lot, but it is not always good</strong></p>
<h2 id="GPT3-h1800"><a href="#GPT3-h1800" class="headerlink" title="GPT3(h1800)"></a>GPT3(h1800)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241727692.png" alt="image-20220224172754530"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241729302.png" alt="image-20220224172922203"></p>
<h2 id="Lecture-11-Question-Answering"><a href="#Lecture-11-Question-Answering" class="headerlink" title="Lecture 11 Question Answering"></a>Lecture 11 Question Answering</h2><iframe width="1217" height="685" src="https://www.youtube.com/embed/NcqfHa0_YmU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241741555.png" alt="image-20220224174146459"></p>
<h2 id="What-is-question-answering-0414"><a href="#What-is-question-answering-0414" class="headerlink" title="What is question answering(0414)"></a>What is question answering(0414)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241752253.png" alt="image-20220224175257101"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241753477.png" alt="image-20220224175334367"></p>
<p><strong>There are lots of practical applications(0629)</strong></p>
<h2 id="Beyond-textual-QA-problems-1100"><a href="#Beyond-textual-QA-problems-1100" class="headerlink" title="Beyond textual QA problems(1100)"></a>Beyond textual QA problems(1100)</h2><h2 id="Reading-comprehension-1223"><a href="#Reading-comprehension-1223" class="headerlink" title="Reading comprehension(1223)"></a>Reading comprehension(1223)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241801824.png" alt="image-20220224180147691"></p>
<p><strong>They are useful for many practical applications</strong></p>
<p>Reading comprehension is an important tested for evaluating how well computer systems understand human language</p>
<h2 id="Standord-question-answering-dataset-1815"><a href="#Standord-question-answering-dataset-1815" class="headerlink" title="Standord question answering dataset (1815)"></a>Standord question answering dataset (1815)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241808087.png" alt="image-20220224180828915"></p>
<h2 id="Neural-models-for-reading-comprehension-2428"><a href="#Neural-models-for-reading-comprehension-2428" class="headerlink" title="Neural models for reading comprehension(2428)"></a>Neural models for reading comprehension(2428)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241814453.png" alt="image-20220224181443258"></p>
<h2 id="LSTM-based-vs-BERT-models-2713"><a href="#LSTM-based-vs-BERT-models-2713" class="headerlink" title="LSTM-based vs BERT models (2713)"></a>LSTM-based vs BERT models (2713)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241815904.png" alt="image-20220224181551779"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818432.png" alt="image-20220224181815290"></p>
<h2 id="BiDAF-3200"><a href="#BiDAF-3200" class="headerlink" title="BiDAF(3200)"></a>BiDAF(3200)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818897.png" alt="image-20220224181853733"></p>
<h3 id="Encoding-3200"><a href="#Encoding-3200" class="headerlink" title="Encoding(3200)"></a>Encoding(3200)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241821498.png" alt="image-20220224182135349"></p>
<h3 id="Attention-3400"><a href="#Attention-3400" class="headerlink" title="Attention(3400)"></a>Attention(3400)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241824459.png" alt="image-20220224182405343"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241829033.png" alt="image-20220224182904883"></p>
<h3 id="Modeling-and-output-layers-4640"><a href="#Modeling-and-output-layers-4640" class="headerlink" title="Modeling and output layers(4640)"></a>Modeling and output layers(4640)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241836707.png" alt="image-20220224183615556"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241838035.png" alt="image-20220224183819872"></p>
<h2 id="BERT-for-reading-comprehension-5227"><a href="#BERT-for-reading-comprehension-5227" class="headerlink" title="BERT for reading comprehension (5227)"></a>BERT for reading comprehension (5227)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241840230.png" alt="image-20220224184028029"></p>
<h2 id="Comparisons-between-BiDAF-and-BERT-models-2734"><a href="#Comparisons-between-BiDAF-and-BERT-models-2734" class="headerlink" title="Comparisons between BiDAF and BERT models(2734)"></a>Comparisons between BiDAF and BERT models(2734)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241851401.png" alt="image-20220224185118280"></p>
<h2 id="Can-we-design-better-pre-training-objectives-h0000"><a href="#Can-we-design-better-pre-training-objectives-h0000" class="headerlink" title="Can we design better pre-training objectives(h0000)"></a>Can we design better pre-training objectives(h0000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241855709.png" alt="image-20220224185550578"></p>
<h2 id="open-domain-question-answering-h1000"><a href="#open-domain-question-answering-h1000" class="headerlink" title="open domain question answering(h1000)"></a>open domain question answering(h1000)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251049797.png" alt="image-20220225104946631"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241912138.png" alt="image-20220224191246022"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251053842.png" alt="image-20220225105306708"></p>
<h2 id="DPR-H1400"><a href="#DPR-H1400" class="headerlink" title="DPR(H1400)"></a>DPR(H1400)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241926002.png" alt="image-20220224192658862"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251056150.png" alt="image-20220225105652971"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251057843.png" alt="image-20220225105747670"></p>
<h2 id="DensePhrase-Demo-h1800"><a href="#DensePhrase-Demo-h1800" class="headerlink" title="DensePhrase:Demo(h1800)"></a>DensePhrase:Demo(h1800)</h2><h1 id="Lecture-12-Natural-Language-Generation-ToL"><a href="#Lecture-12-Natural-Language-Generation-ToL" class="headerlink" title="Lecture 12 - Natural Language Generation[ToL]"></a>Lecture 12 - Natural Language Generation[ToL]</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/1uMo8olr5ng?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011431487.png" alt="image-20220301143159380"></p>
<h2 id="What-is-neural-language-generation-0300"><a href="#What-is-neural-language-generation-0300" class="headerlink" title="What is neural language generation?(0300)"></a>What is neural language generation?(0300)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011424191.png" alt="image-20220301142422083"></p>
<p><strong>Mache Translate</strong></p>
<p><strong>Dialogue Systems</strong> &#x2F;&#x2F;siri</p>
<p><strong>Summarization</strong></p>
<p><strong>Visual Description</strong></p>
<p><strong>Creative Generation</strong> &#x2F;&#x2F;story</p>
<h2 id="Components-of-NLG-Systems-0845"><a href="#Components-of-NLG-Systems-0845" class="headerlink" title="Components of NLG Systems(0845)"></a>Components of NLG Systems(0845)</h2><h3 id="Basic-of-natural-language-generation-0916"><a href="#Basic-of-natural-language-generation-0916" class="headerlink" title="Basic of natural language generation(0916)"></a>Basic of natural language generation(0916)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011433316.png" alt="image-20220301143317131"></p>
<h3 id="A-look-at-a-single-step-1024"><a href="#A-look-at-a-single-step-1024" class="headerlink" title="A look at a single step(1024)"></a>A look at a single step(1024)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011434716.png" alt="image-20220301143429583"></p>
<h3 id="then-select-and-train-1115"><a href="#then-select-and-train-1115" class="headerlink" title="then  select and train(1115)"></a>then  select and train(1115)</h3><p>teacher forcing need to be leaned</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011436047.png" alt="image-20220301143650876"></p>
<h2 id="Decoding-1317"><a href="#Decoding-1317" class="headerlink" title="Decoding(1317)"></a>Decoding(1317)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439775.png" alt="image-20220301143923558"></p>
<h3 id="Greedy-methods-1432"><a href="#Greedy-methods-1432" class="headerlink" title="Greedy methods(1432)"></a>Greedy methods(1432)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439087.png" alt="image-20220301143958990"></p>
<h3 id="Greedy-methods-get-repetitive-1545"><a href="#Greedy-methods-get-repetitive-1545" class="headerlink" title="Greedy methods get repetitive(1545)"></a>Greedy methods get repetitive(1545)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011441769.png" alt="image-20220301144123549"></p>
<h3 id="why-do-repetition-happen-1613"><a href="#why-do-repetition-happen-1613" class="headerlink" title="why do repetition happen(1613)"></a>why do repetition happen(1613)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011442409.png" alt="image-20220301144237210"></p>
<h3 id="How-can-we-reduce-repetition-1824-ToL"><a href="#How-can-we-reduce-repetition-1824-ToL" class="headerlink" title="How can we reduce repetition (1824)[ToL]"></a>How can we reduce repetition (1824)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011445898.png" alt="image-20220301144518763"></p>
<h3 id="People-is-not-always-choose-the-greedy-methods-1930"><a href="#People-is-not-always-choose-the-greedy-methods-1930" class="headerlink" title="People is not always choose the greedy methods(1930)"></a>People is not always choose the greedy methods(1930)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011446786.png" alt="image-20220301144630546"></p>
<h3 id="Time-to-get-random-Sampling-2047"><a href="#Time-to-get-random-Sampling-2047" class="headerlink" title="Time to get random: Sampling(2047)"></a>Time to get random: Sampling(2047)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011447561.png" alt="image-20220301144729442"></p>
<h3 id="Decoding-Top-k-sampling-2100"><a href="#Decoding-Top-k-sampling-2100" class="headerlink" title="Decoding : Top-k sampling(2100)"></a>Decoding : Top-k sampling(2100)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450298.png" alt="image-20220301145000174"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450273.png" alt="image-20220301145018125"></p>
<h3 id="Issues-with-Top-k-sampling-2339"><a href="#Issues-with-Top-k-sampling-2339" class="headerlink" title="Issues with Top-k sampling(2339)"></a>Issues with Top-k sampling(2339)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011451093.png" alt="image-20220301145153941"></p>
<h3 id="Decoding-Top-p-nucleus-sampling-2421"><a href="#Decoding-Top-p-nucleus-sampling-2421" class="headerlink" title="Decoding: Top-p(nucleus)sampling(2421)"></a>Decoding: Top-p(nucleus)sampling(2421)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011452969.png" alt="image-20220301145243854"></p>
<h3 id="Scaling-randomness-Softmax-temperature-2500-ToL"><a href="#Scaling-randomness-Softmax-temperature-2500-ToL" class="headerlink" title="Scaling randomness: Softmax temperature (2500)[ToL]"></a>Scaling randomness: Softmax temperature (2500)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011458368.png" alt="image-20220301145837161"></p>
<h3 id="improving-decoding-re-balancing-distributions-2710"><a href="#improving-decoding-re-balancing-distributions-2710" class="headerlink" title="improving decoding: re-balancing distributions(2710)"></a>improving decoding: re-balancing distributions(2710)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011500149.png" alt="image-20220301150002936"></p>
<h3 id="Backpropagation-based-distribution-re-balancing-3027"><a href="#Backpropagation-based-distribution-re-balancing-3027" class="headerlink" title="Backpropagation-based distribution re-balancing(3027)"></a>Backpropagation-based distribution re-balancing(3027)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011506509.png" alt="image-20220301150637319"></p>
<h3 id="Improving-Decoding-Re-ranking-3300-ToL"><a href="#Improving-Decoding-Re-ranking-3300-ToL" class="headerlink" title="Improving Decoding: Re-ranking(3300)[ToL]"></a>Improving Decoding: Re-ranking(3300)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011511660.png" alt="image-20220301151136510"></p>
<h3 id="Decoding-Takeaways-3540"><a href="#Decoding-Takeaways-3540" class="headerlink" title="Decoding: Takeaways(3540)"></a>Decoding: Takeaways(3540)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011512124.png" alt="image-20220301151258962"></p>
<h2 id="Training-NLG-models-4114"><a href="#Training-NLG-models-4114" class="headerlink" title="Training  NLG models(4114)"></a>Training  NLG models(4114)</h2><h3 id="Maximum-Likelihood-Training-4200"><a href="#Maximum-Likelihood-Training-4200" class="headerlink" title="Maximum Likelihood Training(4200)"></a>Maximum Likelihood Training(4200)</h3><p><strong>Are greedy decoders bad because of how they’re trained?</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011521846.png" alt="image-20220301152118621"></p>
<h3 id="Unlikelihood-Training-4427-ToL"><a href="#Unlikelihood-Training-4427-ToL" class="headerlink" title="Unlikelihood Training(4427)[ToL]"></a>Unlikelihood Training(4427)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011535301.png" alt="image-20220301153527149"></p>
<h3 id="Exposure-Bias-4513-ToL"><a href="#Exposure-Bias-4513-ToL" class="headerlink" title="Exposure Bias(4513)[ToL]"></a>Exposure Bias(4513)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011536542.png" alt="image-20220301153610391"></p>
<h3 id="Exposure-Bias-Solutions-4645"><a href="#Exposure-Bias-Solutions-4645" class="headerlink" title="Exposure Bias Solutions(4645)"></a>Exposure Bias Solutions(4645)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011537922.png" alt="image-20220301153742775"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539222.png" alt="image-20220301153907117"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539740.png" alt="image-20220301153919593"></p>
<h3 id="Reinforce-Basics-4900"><a href="#Reinforce-Basics-4900" class="headerlink" title="Reinforce Basics(4900)"></a>Reinforce Basics(4900)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011540129.png" alt="image-20220301154050890"></p>
<h3 id="Reward-Estimation-5020"><a href="#Reward-Estimation-5020" class="headerlink" title="Reward Estimation(5020)"></a>Reward Estimation(5020)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542624.png" alt="image-20220301154205522"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542000.png" alt="image-20220301154243893"></p>
<h3 id="reinforce’s-dark-side-5300"><a href="#reinforce’s-dark-side-5300" class="headerlink" title="reinforce’s dark side(5300)"></a>reinforce’s dark side(5300)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011544880.png" alt="image-20220301154452756"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011545691.png" alt="image-20220301154547630"></p>
<h3 id="Training-Takeways-5423"><a href="#Training-Takeways-5423" class="headerlink" title="Training: Takeways(5423)"></a>Training: Takeways(5423)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011547174.png" alt="image-20220301154732991"></p>
<h2 id="Evaluating-NLG-Systems-5613"><a href="#Evaluating-NLG-Systems-5613" class="headerlink" title="Evaluating NLG Systems(5613)"></a>Evaluating NLG Systems(5613)</h2><h2 id="Types-of-evaluation-methods-for-text-generation-5734"><a href="#Types-of-evaluation-methods-for-text-generation-5734" class="headerlink" title="Types of evaluation methods for text generation(5734)"></a>Types of evaluation methods for text generation(5734)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011557750.png" alt="image-20220301155705613"></p>
<h3 id="Content-Overlap-metrics-5800"><a href="#Content-Overlap-metrics-5800" class="headerlink" title="Content Overlap metrics(5800)"></a>Content Overlap metrics(5800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011559304.png" alt="image-20220301155931178"></p>
<h3 id="A-simple-failure-case-5900"><a href="#A-simple-failure-case-5900" class="headerlink" title="A simple failure case(5900)"></a>A simple failure case(5900)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011600766.png" alt="image-20220301160050567"></p>
<h3 id="Semantic-overlap-metrics-h0100"><a href="#Semantic-overlap-metrics-h0100" class="headerlink" title="Semantic overlap metrics(h0100)"></a>Semantic overlap metrics(h0100)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011603407.png" alt="image-20220301160319080"></p>
<h3 id="Model-based-metrics-h0120"><a href="#Model-based-metrics-h0120" class="headerlink" title="Model-based metrics(h0120)"></a>Model-based metrics(h0120)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011604213.png" alt="image-20220301160406112"></p>
<h4 id="word-distance-functions-h0234"><a href="#word-distance-functions-h0234" class="headerlink" title="word distance functions(h0234)"></a>word distance functions(h0234)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605672.png" alt="image-20220301160511479"></p>
<h4 id="Beyond-word-matching-h0350"><a href="#Beyond-word-matching-h0350" class="headerlink" title="Beyond word matching(h0350)"></a>Beyond word matching(h0350)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605432.png" alt="image-20220301160556251"></p>
<h3 id="Human-evaluations-h0433"><a href="#Human-evaluations-h0433" class="headerlink" title="Human evaluations(h0433)"></a>Human evaluations(h0433)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011606672.png" alt="image-20220301160658568"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011607851.png" alt="image-20220301160747509"></p>
<h4 id="Issues-h0700"><a href="#Issues-h0700" class="headerlink" title="Issues(h0700)"></a>Issues(h0700)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011609267.png" alt="image-20220301160937146"></p>
<h3 id="Takeways-h0912"><a href="#Takeways-h0912" class="headerlink" title="Takeways(h0912)"></a>Takeways(h0912)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011614202.png" alt="image-20220301161428035"></p>
<h2 id="Ethical-Considerations-h1025"><a href="#Ethical-Considerations-h1025" class="headerlink" title="Ethical Considerations(h1025)"></a>Ethical Considerations(h1025)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011615331.png" alt="image-20220301161515113"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011616579.png" alt="image-20220301161639415"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011617673.png" alt="image-20220301161723483"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011618324.png" alt="image-20220301161839135"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011619216.png" alt="image-20220301161931109"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011621427.png" alt="image-20220301162101280"></p>
<h1 id="Lecture-13-Coreference-Resolution"><a href="#Lecture-13-Coreference-Resolution" class="headerlink" title="Lecture 13 - Coreference Resolution"></a>Lecture 13 - Coreference Resolution</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/FFRnDRcbQQU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011625743.png" alt="image-20220301162522611"></p>
<h2 id="What-is-Coreference-Resolution-0604"><a href="#What-is-Coreference-Resolution-0604" class="headerlink" title="What is Coreference Resolution?(0604)"></a>What is Coreference Resolution?(0604)</h2><p><strong>Identify all mentions that refer to the same entity in the world</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011654767.png" alt="image-20220301165446496"></p>
<h2 id="Applications-1712"><a href="#Applications-1712" class="headerlink" title="Applications (1712)"></a>Applications (1712)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011656858.png" alt="image-20220301165651721"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011658422.png" alt="image-20220301165822337"></p>
<h2 id="Coreference-Resolution-in-Two-steps-1947"><a href="#Coreference-Resolution-in-Two-steps-1947" class="headerlink" title="Coreference Resolution in Two steps(1947)"></a>Coreference Resolution in Two steps(1947)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011659852.png" alt="image-20220301165948737"></p>
<h2 id="Mention-Detection-2049"><a href="#Mention-Detection-2049" class="headerlink" title="Mention Detection(2049)"></a>Mention Detection(2049)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011700078.png" alt="image-20220301170016948"></p>
<h3 id="Not-quite-so-simple-2255"><a href="#Not-quite-so-simple-2255" class="headerlink" title="Not quite so simple(2255)"></a>Not quite so simple(2255)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011702656.png" alt="image-20220301170236541"></p>
<p>It is the best donut.</p>
<p>I want to find the best donut.</p>
<h2 id="Avoiding-a-traditional-pipeline-system-2811"><a href="#Avoiding-a-traditional-pipeline-system-2811" class="headerlink" title="Avoiding a traditional pipeline system(2811)"></a>Avoiding a traditional pipeline system(2811)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011705194.png" alt="image-20220301170543068"></p>
<p><strong>End to End[ToL]</strong></p>
<h2 id="Onto-Coreference-First-some-linguistics-3035"><a href="#Onto-Coreference-First-some-linguistics-3035" class="headerlink" title="Onto Coreference! First, some linguistics (3035)"></a>Onto Coreference! First, some linguistics (3035)</h2><p><strong>Coreference and Anaphor</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011712593.png" alt="image-20220301171220450"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011713580.png" alt="image-20220301171334445"></p>
<h3 id="not-all-anaphoric-relations-are-coreferential-3349"><a href="#not-all-anaphoric-relations-are-coreferential-3349" class="headerlink" title="not all anaphoric relations are coreferential (3349)"></a>not all anaphoric relations are coreferential (3349)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011715286.png" alt="image-20220301171524154"></p>
<h2 id="Anaphora-vs-Cataphora-3610"><a href="#Anaphora-vs-Cataphora-3610" class="headerlink" title="Anaphora vs Cataphora(3610)"></a>Anaphora vs Cataphora(3610)</h2><p>One look its reference before it the other is after it.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011717048.png" alt="image-20220301171753920"></p>
<h2 id="Taking-stock-3801"><a href="#Taking-stock-3801" class="headerlink" title="Taking stock (3801)"></a>Taking stock (3801)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011719341.png" alt="image-20220301171920183"></p>
<h2 id="Four-kinds-of-coreference-Models-4018"><a href="#Four-kinds-of-coreference-Models-4018" class="headerlink" title="Four kinds of coreference Models(4018)"></a>Four kinds of coreference Models(4018)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011721240.png" alt="image-20220301172140149"></p>
<h2 id="Traditional-pronominal-anaphora-resolution-Hobbs’s-naive-algorithm-4130"><a href="#Traditional-pronominal-anaphora-resolution-Hobbs’s-naive-algorithm-4130" class="headerlink" title="Traditional pronominal anaphora resolution:Hobbs’s naive algorithm(4130)"></a>Traditional pronominal anaphora resolution:Hobbs’s naive algorithm(4130)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723580.png" alt="image-20220301172320435"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723916.png" alt="image-20220301172342791"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011724568.png" alt="image-20220301172431380"></p>
<h2 id="Knowledge-based-Pronominal-Coreference-4820"><a href="#Knowledge-based-Pronominal-Coreference-4820" class="headerlink" title="Knowledge-based Pronominal Coreference(4820)"></a>Knowledge-based Pronominal Coreference(4820)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011727409.png" alt="image-20220301172732198"></p>
<p>Hobb’s method can not really solve the questions, the model should really understand the sentence.</p>
<h2 id="Coreference-Models-Mention-Pair-5624"><a href="#Coreference-Models-Mention-Pair-5624" class="headerlink" title="Coreference Models: Mention Pair(5624)"></a>Coreference Models: Mention Pair(5624)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738690.png" alt="image-20220301173814531"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738116.png" alt="image-20220301173826974"></p>
<h3 id="Mention-Pair-Test-Time-5800"><a href="#Mention-Pair-Test-Time-5800" class="headerlink" title="Mention Pair Test Time(5800)"></a>Mention Pair Test Time(5800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011739666.png" alt="image-20220301173911539"></p>
<h3 id="Disadvantage-5953"><a href="#Disadvantage-5953" class="headerlink" title="Disadvantage(5953)"></a>Disadvantage(5953)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011741350.png" alt="image-20220301174101225"></p>
<h2 id="Coreference-Models-Mention-Ranking-h0050"><a href="#Coreference-Models-Mention-Ranking-h0050" class="headerlink" title="Coreference Models: Mention Ranking(h0050)"></a>Coreference Models: Mention Ranking(h0050)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743065.png" alt="image-20220301174326929"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743795.png" alt="image-20220301174335701"></p>
<h2 id="Convolutional-Neural-Nets-h0341"><a href="#Convolutional-Neural-Nets-h0341" class="headerlink" title="Convolutional Neural Nets(h0341)"></a>Convolutional Neural Nets(h0341)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011745334.png" alt="image-20220301174555163"></p>
<h2 id="What-is-convolution-anyway-h0452"><a href="#What-is-convolution-anyway-h0452" class="headerlink" title="What is convolution anyway?(h0452)"></a>What is convolution anyway?(h0452)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011842759.png" alt="image-20220301184216564"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011843829.png" alt="image-20220301184306662"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011844092.png" alt="image-20220301184445934"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011845881.png" alt="image-20220301184526687"></p>
<p><strong>Summarize what we have usually use pooling</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011846697.png" alt="image-20220301184655490"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011847112.png" alt="image-20220301184706063"></p>
<p>Max pooling is usually better.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011848032.png" alt="image-20220301184805861"></p>
<h2 id="End-to-End-Neural-Coref-Model-h1206"><a href="#End-to-End-Neural-Coref-Model-h1206" class="headerlink" title="End-to-End Neural Coref Model(h1206)"></a>End-to-End Neural Coref Model(h1206)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011849948.png" alt="image-20220301184935797"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850188.png" alt="image-20220301185015078"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850940.png" alt="image-20220301185022792"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011851616.png" alt="image-20220301185132395"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011852860.png" alt="image-20220301185213638"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853116.png" alt="image-20220301185316970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853483.png" alt="image-20220301185347334"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011854783.png" alt="image-20220301185443640"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011855774.png" alt="image-20220301185551550"></p>
<h2 id="Conclusion-h2017"><a href="#Conclusion-h2017" class="headerlink" title="Conclusion (h2017)"></a>Conclusion (h2017)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011857080.png" alt="image-20220301185734941"></p>
<h1 id="Lecture-14-T5-and-Large-Language-Models"><a href="#Lecture-14-T5-and-Large-Language-Models" class="headerlink" title="Lecture 14 - T5 and Large Language Models"></a>Lecture 14 - T5 and Large Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/iHWkLvoSpTg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021447359.png" alt="image-20220302144735211"></p>
<p>(0243)</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021451322.png" alt="image-20220302145100222"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021453717.png" alt="image-20220302145356635"></p>
<h2 id="T5-with-a-task-prefix-0800"><a href="#T5-with-a-task-prefix-0800" class="headerlink" title="T5 with a task prefix(0800)"></a>T5 with a task prefix(0800)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021454368.png" alt="image-20220302145406303"></p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021455282.png" alt="image-20220302145536205"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456327.png" alt="image-20220302145606261"></p>
<h3 id="STSB"><a href="#STSB" class="headerlink" title="STSB"></a>STSB</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456444.png" alt="image-20220302145658323"></p>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456947.png" alt="image-20220302145646869"></p>
<h2 id="T5-change-little-from-original-transformer-1300"><a href="#T5-change-little-from-original-transformer-1300" class="headerlink" title="T5 change little from original transformer(1300)"></a>T5 change little from original transformer(1300)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021459690.png" alt="image-20220302145917510"></p>
<h2 id="what-should-my-pre-training-data-set-be-1325"><a href="#what-should-my-pre-training-data-set-be-1325" class="headerlink" title="what should my pre-training data set be?(1325)"></a>what should my pre-training data set be?(1325)</h2><p><strong>Get from open source data source and then wipe them and get c4 1500</strong></p>
<h2 id="Then-is-how-to-train-from-a-start-1659"><a href="#Then-is-how-to-train-from-a-start-1659" class="headerlink" title="Then is how to train from a start(1659)"></a>Then is how to train from a start(1659)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021511473.png" alt="image-20220302151128378"></p>
<h2 id="pretrain-1805"><a href="#pretrain-1805" class="headerlink" title="pretrain(1805)"></a>pretrain(1805)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021515266.png" alt="image-20220302151510138"></p>
<h2 id="choose-the-model-2412"><a href="#choose-the-model-2412" class="headerlink" title="choose the model(2412)"></a>choose the model(2412)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021520528.png" alt="image-20220302152005363"></p>
<p>They use the encoder-Decoder model, It turns out it works well.</p>
<p><strong>They dont change hyper paramenters because of the cost</strong></p>
<h2 id="pre-training-objective-2629"><a href="#pre-training-objective-2629" class="headerlink" title="pre-training objective(2629)"></a>pre-training objective(2629)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021539312.png" alt="image-20220302153925164"></p>
<p><strong>Choose different train method</strong></p>
<h2 id="different-structure-of-data-source-2822"><a href="#different-structure-of-data-source-2822" class="headerlink" title="different structure of data source(2822)"></a>different structure of data source(2822)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021546645.png" alt="image-20220302154612488"></p>
<h2 id="Multi-task-learning-3443"><a href="#Multi-task-learning-3443" class="headerlink" title="Multi task learning (3443)"></a>Multi task learning (3443)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021551343.png" alt="image-20220302155158191"></p>
<h2 id="close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621"><a href="#close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621" class="headerlink" title="close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)"></a>close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021557083.png" alt="image-20220302155756918"></p>
<h2 id="What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737"><a href="#What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737" class="headerlink" title="What if it happens there are four times computes as much as before  (3737)"></a>What if it happens there are four times computes as much as before  (3737)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021600593.png" alt="image-20220302160009440"></p>
<h2 id="Overview-3840"><a href="#Overview-3840" class="headerlink" title="Overview(3840)"></a>Overview(3840)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021601735.png" alt="image-20220302160104583"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021602559.png" alt="image-20220302160234452"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021605914.png" alt="image-20220302160555766"></p>
<p> <img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021606666.png" alt="image-20220302160612550"></p>
<h2 id="What-about-all-of-the-other-languages-mT5-4735"><a href="#What-about-all-of-the-other-languages-mT5-4735" class="headerlink" title="What about all of the other languages?(mT5)(4735)"></a>What about all of the other languages?(mT5)(4735)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021611309.png" alt="image-20220302161124160"></p>
<p>Same model different corpus.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021612178.png" alt="image-20220302161211041"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021613249.png" alt="image-20220302161358092"></p>
<h2 id="XTREME-5000"><a href="#XTREME-5000" class="headerlink" title="XTREME (5000)"></a>XTREME (5000)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021614579.png" alt="image-20220302161445454"></p>
<h2 id="How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225"><a href="#How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225" class="headerlink" title="How much knowledge does a language model pick up during pre-training?(5225)"></a>How much knowledge does a language model pick up during pre-training?(5225)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619700.png" alt="image-20220302161913596"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619203.png" alt="image-20220302161932089"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619946.png" alt="image-20220302161949876"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021620563.png" alt="image-20220302162028438"></p>
<h2 id="Salient-span-masking-5631"><a href="#Salient-span-masking-5631" class="headerlink" title="Salient span masking (5631)"></a>Salient span masking (5631)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021623948.png" alt="image-20220302162316816"></p>
<p><strong>Instead of mask randomly, it mask username please date, etc.</strong></p>
<h2 id="Do-large-language-models-memorize-their-training-data-h0100"><a href="#Do-large-language-models-memorize-their-training-data-h0100" class="headerlink" title="Do large language models memorize their training data(h0100)"></a>Do large language models memorize their training data(h0100)</h2><p><strong>It seems it did</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021629154.png" alt="image-20220302162918979"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021630287.png" alt="image-20220302163050189"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021631372.png" alt="image-20220302163113267"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635048.png" alt="image-20220302163505954"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635716.png" alt="image-20220302163519627"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021637986.png" alt="image-20220302163719877"></p>
<p>They need to see examples, they need to see particular examples fewer times in order!</p>
<h2 id="Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010"><a href="#Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010" class="headerlink" title="Can we close the gap between large and small models by improving the transformer architecture(h1010)"></a>Can we close the gap between large and small models by improving the transformer architecture(h1010)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021649670.png" alt="image-20220302164909562"></p>
<p>in these test, they change some architecture such as RELu. </p>
<p><strong>there actually were very few, if any modifications that improved performance meaningfully.</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021652560.png" alt="image-20220302165203416"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021653903.png" alt="image-20220302165316814">(h1700)</p>
<h2 id="QA-h1915"><a href="#QA-h1915" class="headerlink" title="QA(h1915)"></a>QA(h1915)</h2><h1 id="Lecture-15-Add-Knowledge-to-Language-Models"><a href="#Lecture-15-Add-Knowledge-to-Language-Models" class="headerlink" title="Lecture 15 - Add Knowledge to Language Models"></a>Lecture 15 - Add Knowledge to Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/y68RJVfGoto?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021723936.png" alt="image-20220302172329814"></p>
<h2 id="Recap-LM-0232"><a href="#Recap-LM-0232" class="headerlink" title="Recap: LM(0232)"></a>Recap: LM(0232)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021726699.png" alt="image-20220302172634570"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727605.png" alt="image-20220302172712490"></p>
<h2 id="What-does-a-language-model-know-0423"><a href="#What-does-a-language-model-know-0423" class="headerlink" title="What does a language model know?(0423)"></a>What does a language model know?(0423)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727649.png" alt="image-20220302172753547"></p>
<p>Thing may right in logic but wrong in fact.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021729763.png" alt="image-20220302172916623"></p>
<h2 id="The-importance-of-know-ledge-aware-language-models-0700"><a href="#The-importance-of-know-ledge-aware-language-models-0700" class="headerlink" title="The importance of know ledge-aware language models(0700)"></a>The importance of know ledge-aware language models(0700)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733793.png" alt="image-20220302173300654"></p>
<h2 id="Query-traditional-knowledge-bases-0750"><a href="#Query-traditional-knowledge-bases-0750" class="headerlink" title="Query traditional knowledge bases(0750)"></a>Query traditional knowledge bases(0750)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733338.png" alt="image-20220302173336194"></p>
<h2 id="Query-language-models-as-knowledge-bases-0955"><a href="#Query-language-models-as-knowledge-bases-0955" class="headerlink" title="Query language models as knowledge bases(0955)"></a>Query language models as knowledge bases(0955)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021735054.png" alt="image-20220302173553905"></p>
<h2 id="Compare-and-disadvantage-1010"><a href="#Compare-and-disadvantage-1010" class="headerlink" title="Compare and disadvantage(1010)"></a>Compare and disadvantage(1010)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021738604.png" alt="image-20220302173820443"></p>
<h2 id="Techniques-to-add-knowledge-to-LMs-130"><a href="#Techniques-to-add-knowledge-to-LMs-130" class="headerlink" title="Techniques to add knowledge to LMs(130)"></a>Techniques to add knowledge to LMs(130)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021739919.png" alt="image-20220302173937785"></p>
<h2 id="Add-pretrained-embeddings-1403"><a href="#Add-pretrained-embeddings-1403" class="headerlink" title="Add pretrained embeddings(1403)"></a>Add pretrained embeddings(1403)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021743165.png" alt="image-20220302174313016"></p>
<h2 id="Aside-What-is-entity-linking-1516"><a href="#Aside-What-is-entity-linking-1516" class="headerlink" title="Aside: What is entity linking?(1516)"></a>Aside: What is entity linking?(1516)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021746116.png" alt="image-20220302174603921"></p>
<h2 id="Method-1-Add-pretrained-entity-embeddings-1815"><a href="#Method-1-Add-pretrained-entity-embeddings-1815" class="headerlink" title="Method 1: Add pretrained entity embeddings(1815)"></a>Method 1: Add pretrained entity embeddings(1815)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021747337.png" alt="image-20220302174729224"></p>
<h3 id="How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000"><a href="#How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000" class="headerlink" title="How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)"></a>How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021749944.png" alt="image-20220302174927805"></p>
<h2 id="ERNIE-Enhanced-language-representation-with-informative-entities-2143"><a href="#ERNIE-Enhanced-language-representation-with-informative-entities-2143" class="headerlink" title="ERNIE: Enhanced language representation with informative entities(2143)"></a>ERNIE: Enhanced language representation with informative entities(2143)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021752214.png" alt="image-20220302175236060"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021754765.png" alt="image-20220302175420597"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757296.png" alt="image-20220302175702140"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757888.png" alt="image-20220302175713761"></p>
<h3 id="strengths-amp-remaining-challenges-2610"><a href="#strengths-amp-remaining-challenges-2610" class="headerlink" title="strengths &amp; remaining challenges(2610)"></a>strengths &amp; remaining challenges(2610)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021758503.png" alt="image-20220302175826353"></p>
<h2 id="Jointly-learn-to-link-entities-with-KnowBERT-2958"><a href="#Jointly-learn-to-link-entities-with-KnowBERT-2958" class="headerlink" title="Jointly learn to link entities with KnowBERT(2958)"></a>Jointly learn to link entities with KnowBERT(2958)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021804637.png" alt="image-20220302180440491"></p>
<h2 id="Use-an-external-memory-3140"><a href="#Use-an-external-memory-3140" class="headerlink" title="Use an external memory(3140)"></a>Use an external memory(3140)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021807795.png" alt="image-20220302180727662"></p>
<h3 id="KGLM-3355"><a href="#KGLM-3355" class="headerlink" title="KGLM(3355)"></a>KGLM(3355)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021808462.png" alt="image-20220302180818299"></p>
<h3 id="Local-knowledge-and-full-knowledge"><a href="#Local-knowledge-and-full-knowledge" class="headerlink" title="Local knowledge and full knowledge"></a>Local knowledge and full knowledge</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021810608.png" alt="image-20220302181037473"></p>
<h3 id="When-should-the-model-use-the-external-knowledge-3600"><a href="#When-should-the-model-use-the-external-knowledge-3600" class="headerlink" title="When should the model use the external knowledge(3600)"></a>When should the model use the external knowledge(3600)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021811716.png" alt="image-20220302181146581"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021814810.png" alt="image-20220302181436660"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815905.png" alt="image-20220302181526770"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815447.png" alt="image-20220302181538323"></p>
<h2 id="Compare-to-the-others-4334"><a href="#Compare-to-the-others-4334" class="headerlink" title="Compare to the others(4334)"></a>Compare to the others(4334)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021818819.png" alt="image-20220302181801664"></p>
<h2 id="More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730"><a href="#More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730" class="headerlink" title="More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)"></a>More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021823462.png" alt="image-20220302182325290"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021825650.png" alt="image-20220302182507490"></p>
<h2 id="Modify-the-training-data-5230"><a href="#Modify-the-training-data-5230" class="headerlink" title="Modify the training data(5230)"></a>Modify the training data(5230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021828456.png" alt="image-20220302182823268"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021829477.png" alt="image-20220302182959293"></p>
<h2 id="WKLM-5458"><a href="#WKLM-5458" class="headerlink" title="WKLM(5458)"></a>WKLM(5458)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021830774.png" alt="image-20220302183028613"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021831311.png" alt="image-20220302183142193"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021832124.png" alt="image-20220302183255968"></p>
<h2 id="Learn-inductive-biases-through-masking-5811"><a href="#Learn-inductive-biases-through-masking-5811" class="headerlink" title="Learn inductive biases through masking(5811)"></a>Learn inductive biases through masking(5811)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021833826.png" alt="image-20220302183351631"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834994.png" alt="image-20220302183427849"></p>
<h2 id="Salient-span-masking-5927"><a href="#Salient-span-masking-5927" class="headerlink" title="Salient span masking(5927)"></a>Salient span masking(5927)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834166.png" alt="image-20220302183458012"></p>
<h2 id="Recap-h0053"><a href="#Recap-h0053" class="headerlink" title="Recap(h0053)"></a>Recap(h0053)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021837032.png" alt="image-20220302183700886"></p>
<h2 id="Evaluating-knowledge-in-LMS-h0211"><a href="#Evaluating-knowledge-in-LMS-h0211" class="headerlink" title="Evaluating knowledge in LMS(h0211)"></a>Evaluating knowledge in LMS(h0211)</h2><h3 id="LAMA-h0250"><a href="#LAMA-h0250" class="headerlink" title="LAMA(h0250)"></a>LAMA(h0250)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021838823.png" alt="image-20220302183849664"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021839294.png" alt="image-20220302183927125"></p>
<h3 id="The-limitations-h0650"><a href="#The-limitations-h0650" class="headerlink" title="The limitations (h0650)"></a>The limitations (h0650)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021841791.png" alt="image-20220302184139639"></p>
<h2 id="LAMA-UnHelpful-Names-LAMA-UHN"><a href="#LAMA-UnHelpful-Names-LAMA-UHN" class="headerlink" title="LAMA_UnHelpful Names(LAMA-UHN)"></a>LAMA_UnHelpful Names(LAMA-UHN)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021842799.png" alt="image-20220302184226621"></p>
<p>** They delete something that may caused by co-occurrence **</p>
<h3 id="Developing-better-prompts-to-query-knowledge-in-LMS"><a href="#Developing-better-prompts-to-query-knowledge-in-LMS" class="headerlink" title="Developing better prompts to query knowledge in LMS"></a>Developing better prompts to query knowledge in LMS</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021844225.png" alt="image-20220302184443068"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021845853.png" alt="image-20220302184528706"></p>
<h3 id="Knowledge-driven-downstream-tasks-h1253"><a href="#Knowledge-driven-downstream-tasks-h1253" class="headerlink" title="Knowledge-driven downstream tasks(h1253)"></a>Knowledge-driven downstream tasks(h1253)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847354.png" alt="image-20220302184702209"></p>
<h2 id="Relation-extraction-performance-on-TACED-h1400"><a href="#Relation-extraction-performance-on-TACED-h1400" class="headerlink" title="Relation extraction performance on TACED(h1400)"></a>Relation extraction performance on TACED(h1400)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847359.png" alt="image-20220302184753193"></p>
<h2 id="Entity-typing-performance-on-Open-Entuty"><a href="#Entity-typing-performance-on-Open-Entuty" class="headerlink" title="Entity typing performance on Open Entuty"></a>Entity typing performance on Open Entuty</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021848691.png" alt="image-20220302184828514"></p>
<h2 id="Recap-Evaluating-knowledge-in-LMs-h1600"><a href="#Recap-Evaluating-knowledge-in-LMs-h1600" class="headerlink" title="Recap: Evaluating knowledge in LMs(h1600)"></a>Recap: Evaluating knowledge in LMs(h1600)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021849200.png" alt="image-20220302184929078"></p>
<h2 id="Other-exciting-progress-amp-what’s-next-h1652"><a href="#Other-exciting-progress-amp-what’s-next-h1652" class="headerlink" title="Other exciting progress &amp; what’s next?(h1652)"></a>Other exciting progress &amp; what’s next?(h1652)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021850845.png" alt="image-20220302185006721"></p>
<h1 id="Lecture-17-Model-Analysis-and-Explanation"><a href="#Lecture-17-Model-Analysis-and-Explanation" class="headerlink" title="Lecture 17 - Model Analysis and Explanation"></a>Lecture 17 - Model Analysis and Explanation</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/f_qmSSBWV_E?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031042434.png" alt="image-20220303104239293"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031043574.png" alt="image-20220303104308448"></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><h3 id="what-are-our-models-doing-0415"><a href="#what-are-our-models-doing-0415" class="headerlink" title="what are our models doing(0415)"></a>what are our models doing(0415)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031044256.png" alt="image-20220303104435113"></p>
<h3 id="how-do-we-make-tomorrow’s-model-0515"><a href="#how-do-we-make-tomorrow’s-model-0515" class="headerlink" title="how do we make tomorrow’s model?(0515)"></a>how do we make tomorrow’s model?(0515)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031046845.png" alt="image-20220303104651667"></p>
<h3 id="What-biases-are-built-into-model-0700"><a href="#What-biases-are-built-into-model-0700" class="headerlink" title="What biases are built into model?(0700)"></a>What biases are built into model?(0700)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031050696.png" alt="image-20220303105015554"></p>
<h3 id="how-do-we-make-in-the-following-25years-0800"><a href="#how-do-we-make-in-the-following-25years-0800" class="headerlink" title="how do we make in the following 25years(0800)"></a>how do we make in the following 25years(0800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031051800.png" alt="image-20220303105141648"></p>
<h2 id="Model-analysis-at-varying-levels-of-abstraction-0904"><a href="#Model-analysis-at-varying-levels-of-abstraction-0904" class="headerlink" title="Model analysis at varying levels of abstraction(0904)"></a>Model analysis at varying levels of abstraction(0904)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031056169.png" alt="image-20220303105647998"></p>
<h2 id="Model-evaluation-as-model-analysis-1117"><a href="#Model-evaluation-as-model-analysis-1117" class="headerlink" title="Model evaluation as model analysis(1117)"></a>Model evaluation as model analysis(1117)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031059574.png" alt="image-20220303105924421"></p>
<h2 id="Model-evaluation-as-model-analysis-in-natural-language-inference-1344"><a href="#Model-evaluation-as-model-analysis-in-natural-language-inference-1344" class="headerlink" title="Model evaluation as model analysis in natural language inference(1344)"></a>Model evaluation as model analysis in natural language inference(1344)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031102348.png" alt="image-20220303110240168"></p>
<h3 id="What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558"><a href="#What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558" class="headerlink" title="What if the model is simple using heuristics to get good accuracy?(1558)"></a>What if the model is simple using heuristics to get good accuracy?(1558)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031108392.png" alt="image-20220303110832177"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031109573.png" alt="image-20220303110953359"></p>
<h2 id="Language-models-as-linguistic-test-subjects-2023"><a href="#Language-models-as-linguistic-test-subjects-2023" class="headerlink" title="Language models as linguistic test subjects(2023)"></a>Language models as linguistic test subjects(2023)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031117718.png" alt="image-20220303111752546"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031123611.png" alt="image-20220303112316410"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031126322.png" alt="image-20220303112622131"></p>
<h2 id="Careful-test-sets-as-unit-test-suites-CheckListing-3230"><a href="#Careful-test-sets-as-unit-test-suites-CheckListing-3230" class="headerlink" title="Careful  test sets as unit test suites: CheckListing(3230)"></a>Careful  test sets as unit test suites: CheckListing(3230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031150003.png" alt="image-20220303115000790"></p>
<h2 id="Fitting-the-dataset-vs-learning-the-task-3500"><a href="#Fitting-the-dataset-vs-learning-the-task-3500" class="headerlink" title="Fitting the dataset vs learning the task(3500)"></a>Fitting the dataset vs learning the task(3500)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031151961.png" alt="image-20220303115116821"></p>
<h2 id="Knowledge-evaluation-as-model-analysis-3642"><a href="#Knowledge-evaluation-as-model-analysis-3642" class="headerlink" title="Knowledge evaluation as model analysis(3642)"></a>Knowledge evaluation as model analysis(3642)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031152782.png" alt="image-20220303115222614"></p>
<h2 id="Input-influence-does-my-model-really-use-long-distance-context-3822"><a href="#Input-influence-does-my-model-really-use-long-distance-context-3822" class="headerlink" title="Input influence: does my model really use long-distance context?(3822)"></a>Input influence: does my model really use long-distance context?(3822)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031154169.png" alt="image-20220303115456959"></p>
<h2 id="Prediction-explanations-what-in-the-input-led-to-this-output-4054"><a href="#Prediction-explanations-what-in-the-input-led-to-this-output-4054" class="headerlink" title="Prediction explanations: what in the input led to this output?(4054)"></a>Prediction explanations: what in the input led to this output?(4054)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031158656.png" alt="image-20220303115848462"></p>
<h2 id="Prediction-explanations-simple-saliency-maps-4230"><a href="#Prediction-explanations-simple-saliency-maps-4230" class="headerlink" title="Prediction explanations: simple saliency maps(4230)"></a>Prediction explanations: simple saliency maps(4230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031201539.png" alt="image-20220303120124359"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031332993.png" alt="image-20220303133241797"></p>
<h2 id="Explanation-by-input-reduction-4607"><a href="#Explanation-by-input-reduction-4607" class="headerlink" title="Explanation by input reduction (4607)"></a>Explanation by input reduction (4607)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031341312.png" alt="image-20220303134148143"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031343962.png" alt="image-20220303134313746"></p>
<h2 id="Analyzing-models-by-breaking-them-5106"><a href="#Analyzing-models-by-breaking-them-5106" class="headerlink" title="Analyzing models by breaking them(5106)"></a>Analyzing models by breaking them(5106)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346413.png" alt="image-20220303134604267"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346603.png" alt="image-20220303134644433"></p>
<p>They add a nonsense sentence at the end and the prediction changed.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031347898.png" alt="image-20220303134756682"></p>
<p><strong>Change the Q also make the prediction changed</strong></p>
<h2 id="Are-models-robust-to-noise-in-their-input-5518"><a href="#Are-models-robust-to-noise-in-their-input-5518" class="headerlink" title="Are models robust to noise in their input?(5518)"></a>Are models robust to noise in their input?(5518)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031350084.png" alt="image-20220303135054871"></p>
<p>It seems not.</p>
<h2 id="Analysis-of-“interpretable”-architecture-components-5719"><a href="#Analysis-of-“interpretable”-architecture-components-5719" class="headerlink" title="Analysis of “interpretable” architecture components(5719)"></a>Analysis of “interpretable” architecture components(5719)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031356980.png" alt="image-20220303135659761"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031357241.png" alt="image-20220303135716017"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031400358.png" alt="image-20220303140006202"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031401626.png" alt="image-20220303140154452"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031403011.png" alt="image-20220303140306747"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031404517.png" alt="image-20220303140430315"></p>
<h2 id="Probing-supervised-analysis-of-neural-networks-h0408"><a href="#Probing-supervised-analysis-of-neural-networks-h0408" class="headerlink" title="Probing: supervised analysis of neural networks(h0408)"></a>Probing: supervised analysis of neural networks(h0408)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031407337.png" alt="image-20220303140720120"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031408146.png" alt="image-20220303140831970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031410797.png" alt="image-20220303141059579"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413065.png" alt="image-20220303141301877"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413295.png" alt="image-20220303141354126"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031414069.png" alt="image-20220303141443881"></p>
<p>the most efficient layer is in the middlwe.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031415636.png" alt="image-20220303141554363"></p>
<p>deeper, more abstract</p>
<h2 id="Emergent-simple-structure-in-neural-networks-h1019"><a href="#Emergent-simple-structure-in-neural-networks-h1019" class="headerlink" title="Emergent simple structure in neural networks(h1019)"></a>Emergent simple structure in neural networks(h1019)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031417261.png" alt="image-20220303141709095"></p>
<h2 id="Probing-tress-simply-recoverable-from-BERT-representations-h1136"><a href="#Probing-tress-simply-recoverable-from-BERT-representations-h1136" class="headerlink" title="Probing: tress simply recoverable from BERT representations(h1136)"></a>Probing: tress simply recoverable from BERT representations(h1136)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031419210.png" alt="image-20220303141908032"></p>
<h2 id="Final-thoughts-on-probing-and-correlation-studies-h1341"><a href="#Final-thoughts-on-probing-and-correlation-studies-h1341" class="headerlink" title="Final thoughts on probing and correlation studies(h1341)"></a>Final thoughts on probing and correlation studies(h1341)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031421004.png" alt="image-20220303142155844"></p>
<p>Not causal study</p>
<h2 id="Recasting-model-tweaks-and-ablations-as-analysis-h1406"><a href="#Recasting-model-tweaks-and-ablations-as-analysis-h1406" class="headerlink" title="Recasting model tweaks and ablations as analysis(h1406)"></a>Recasting model tweaks and ablations as analysis(h1406)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031423815.png" alt="image-20220303142341661"></p>
<h3 id="Ablation-analysis-do-we-need-all-these-attension-heads-h1445"><a href="#Ablation-analysis-do-we-need-all-these-attension-heads-h1445" class="headerlink" title="Ablation analysis: do we need all these attension heads?(h1445)"></a>Ablation analysis: do we need all these attension heads?(h1445)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031424764.png" alt="image-20220303142453543"></p>
<h2 id="What’s-the-right-layer-order-for-a-transformer-h1537"><a href="#What’s-the-right-layer-order-for-a-transformer-h1537" class="headerlink" title="What’s the right layer order for a transformer?(h1537)"></a>What’s the right layer order for a transformer?(h1537)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031425391.png" alt="image-20220303142557160"></p>
<h2 id="Parting-thoughts-h1612"><a href="#Parting-thoughts-h1612" class="headerlink" title="Parting thoughts(h1612)"></a>Parting thoughts(h1612)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031426427.png" alt="image-20220303142651251"></p>
<h1 id="Lecture-18-Future-of-NLP-Deep-Learning"><a href="#Lecture-18-Future-of-NLP-Deep-Learning" class="headerlink" title="Lecture 18 - Future of NLP + Deep Learning"></a>Lecture 18 - Future of NLP + Deep Learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/2t7Q9WVUaf8?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456172.png" alt="image-20220303145634077"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456187.png" alt="image-20220303145648087"></p>
<h2 id="General-Representation-Learning-Recipe-0312"><a href="#General-Representation-Learning-Recipe-0312" class="headerlink" title="General Representation Learning Recipe(0312)"></a>General Representation Learning Recipe(0312)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031458027.png" alt="image-20220303145813909"></p>
<p>Certain properties emerge only when we scale up the model size!</p>
<h2 id="Large-Language-Models-and-GPT-3-0358"><a href="#Large-Language-Models-and-GPT-3-0358" class="headerlink" title="Large Language Models and GPT-3(0358)"></a>Large Language Models and GPT-3(0358)</h2><h3 id="Large-Language-models-and-GPT-3-0514"><a href="#Large-Language-models-and-GPT-3-0514" class="headerlink" title="Large Language models and GPT-3(0514)"></a>Large Language models and GPT-3(0514)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031501186.png" alt="image-20220303150148074"></p>
<h3 id="What’s-new-about-GPT-3"><a href="#What’s-new-about-GPT-3" class="headerlink" title="What’s new about GPT-3"></a>What’s new about GPT-3</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502616.png" alt="image-20220303150225480"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502821.png" alt="image-20220303150257686"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031503577.png" alt="image-20220303150317443"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/Pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/python/Pytorch/" class="post-title-link" itemprop="url">Pytorch</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:44" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:44+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:41" itemprop="dateModified" datetime="2022-03-23T11:23:41+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s</p>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,dtype=torch.double)</span><br><span class="line">x.size()</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>,device=device)</span><br><span class="line">y = torch.rand(<span class="number">2</span>,<span class="number">2</span>,device=device)</span><br><span class="line">z = x+y <span class="comment">#+-*/</span></span><br><span class="line">z = torch.add(x,y)<span class="comment">#add sub mul</span></span><br><span class="line">y.add_(x)<span class="comment"># sub_ div_ 原地操作</span></span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">x[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line"></span><br><span class="line">y=x.view(-<span class="number">1</span>,<span class="number">2</span>) <span class="comment">#插眼</span></span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">a.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">a.add_(<span class="number">13</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"></span><br><span class="line">a = np.ones(<span class="number">6</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)<span class="comment">#***</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = x+<span class="number">2</span></span><br><span class="line">z = y*y*<span class="number">2</span></span><br><span class="line"><span class="comment">#z = z.mean()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.001</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">z.backward(v)<span class="comment"># 插眼：如果不是标量则必须给vecor ***</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dont calculate 插眼</span></span><br><span class="line"><span class="comment">#x.requires_grad_(False)</span></span><br><span class="line"><span class="comment">#y = x.detach()</span></span><br><span class="line"><span class="comment">#with torch.no_grad():</span></span><br><span class="line"><span class="comment">#    y = x + 2</span></span><br><span class="line"><span class="comment">#    print(y)</span></span><br><span class="line"></span><br><span class="line">weights = torch.ones(<span class="number">4</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model_output = (weights*<span class="number">3</span>).<span class="built_in">sum</span>()</span><br><span class="line">    model_output.backward()</span><br><span class="line">    <span class="built_in">print</span>(weights.grad)</span><br><span class="line"></span><br><span class="line">    weights.grad.zero_() <span class="comment">#将积累的计算清零 插眼，需要深入理解 ***</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#optimizer</span></span><br><span class="line"><span class="comment">#optimizer = torch.optim.SGD([weights], lr=0.01)</span></span><br><span class="line"><span class="comment">#optimizer.step()</span></span><br><span class="line"><span class="comment">#optimizer.zero_grad()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">w = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_hat = w * x</span><br><span class="line">loss = (y_hat-y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>

<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png" alt="image-20220316151942503"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=np.float32)</span><br><span class="line">w = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    dw = gradient(x,y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    w-=learning_rate * dw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png" alt="image-20220316145349626"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= learning_rate * w.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    w.grad.zero_()        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Training-pipeline"><a href="#Training-pipeline" class="headerlink" title="Training pipeline"></a>Training pipeline</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png" alt="image-20220316153456524"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="comment">#y_pred = model(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png" alt="image-20220316153507880"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line"><span class="comment">#w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    <span class="comment">#y_pred = forward(x)</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">x_numpy,y_numpy = datasets.make_regression(n_samples=<span class="number">100</span>,n_features=<span class="number">1</span>,noise=<span class="number">20</span>,random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = torch.from_numpy(x_numpy.astype(np.float32))</span><br><span class="line">y = torch.from_numpy(y_numpy.astype(np.float32))</span><br><span class="line">y = y.view(y.shape[<span class="number">0</span>],<span class="number">1</span>)<span class="comment"># 插眼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = nn.Linear(input_size,output_size)</span><br><span class="line">pr = model(x).detach().numpy()</span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># forward pss and loss</span></span><br><span class="line">    y_predicted = model(x)</span><br><span class="line">    loss = criterion(y_predicted,y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">predicted = model(x).detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(x_numpy,y_numpy,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x_numpy,predicted,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">bc = datasets.load_breast_cancer()</span><br><span class="line">x,y = bc.data,bc.target</span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#sclae</span></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">x_train = sc.fit_transform(x_train)</span><br><span class="line">x_test = sc.transform(x_test)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train.astype(np.float32))</span><br><span class="line">x_test = torch.from_numpy(x_test.astype(np.float32))</span><br><span class="line">y_train = torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">y_test = torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line">y_train = y_train.view(y_train.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line">y_test = y_test.view(y_test.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"><span class="comment"># f = wx+b, sigmod at the end</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_predicted = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_predicted</span><br><span class="line">model = LogisticRegression(n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.03</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="comment">#forward pass and loss</span></span><br><span class="line">    y_predicted = model(x_train)</span><br><span class="line">    loss = criterion(y_predicted,y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y_predicted = model(x_test)</span><br><span class="line">    y_predicted_cls = y_predicted.<span class="built_in">round</span>()</span><br><span class="line">    acc = y_predicted_cls.eq(y_test).<span class="built_in">sum</span>()/<span class="built_in">float</span>(y_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,</span><br><span class="line">                        skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = torch.from_numpy(xy[:, <span class="number">1</span>:])</span><br><span class="line">        self.y = torch.from_numpy(xy[:, [<span class="number">0</span>]])</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = WineDataSet()</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datatiter = iter(dataloader)</span></span><br><span class="line"><span class="comment"># data = datatiter.next()</span></span><br><span class="line"><span class="comment"># features, labels = data</span></span><br><span class="line"><span class="comment"># print(features,labels)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line">n_iterations = math.ceil(total_samples / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(total_samples, n_iterations)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># forward backward, update</span></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_iterations&#125;</span>,inputs <span class="subst">&#123;inputs.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-transformers"><a href="#Dataset-transformers" class="headerlink" title="Dataset transformers"></a>Dataset transformers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = xy[:, <span class="number">1</span>:]</span><br><span class="line">        self.y = xy[:, [<span class="number">0</span>]]</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        sample = self.x[index],self.y[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToTensor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,targets = sample</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(inputs),torch.from_numpy(targets)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulTransform</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,factor</span>):</span><br><span class="line">        self.factor = factor</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,target = sample</span><br><span class="line">        inputs *= self.factor</span><br><span class="line">        <span class="keyword">return</span> inputs,target</span><br><span class="line"></span><br><span class="line">dataset = WineDataSet(transform=<span class="literal">None</span>)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br><span class="line"></span><br><span class="line">composed = torchvision.transforms.Compose([ToTensor(),MulTransform(<span class="number">2</span>)])</span><br><span class="line">dataset = WineDataSet(transform=composed)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br></pre></td></tr></table></figure>

<h1 id="SoftMax-and-Crossentropy"><a href="#SoftMax-and-Crossentropy" class="headerlink" title="SoftMax and Crossentropy"></a>SoftMax and Crossentropy</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png" alt="image-20220317185503305"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x)/np.<span class="built_in">sum</span>(np.exp(x),axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = softmax(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;softmax numpy:&#x27;</span>,outputs)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = torch.softmax(x,dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">actual,predicted</span>):</span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(actual * np.log(predicted))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">Y_pred_good = np.array([<span class="number">0.7</span>,<span class="number">0.2</span>,<span class="number">0.1</span>])</span><br><span class="line">Y_pred_bad = np.array([<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>])</span><br><span class="line">l1 = cross_entropy(Y,Y_pred_good)</span><br><span class="line">l2 = cross_entropy(Y,Y_pred_bad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss1 numpy:<span class="subst">&#123;l1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss2 numpy:<span class="subst">&#123;l2:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#3 samples</span></span><br><span class="line"></span><br><span class="line">Y = torch.tensor([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">y_pred_good = torch.tensor([[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line">y_pred_bad = torch.tensor([[<span class="number">2.1</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">l1 = loss(y_pred_good,Y)</span><br><span class="line">l2 = loss(y_pred_bad,Y)</span><br><span class="line"><span class="built_in">print</span>(l1.item())</span><br><span class="line"><span class="built_in">print</span>(l2.item())</span><br><span class="line"></span><br><span class="line">_,pred1 = torch.<span class="built_in">max</span>(y_pred_good,<span class="number">1</span>)</span><br><span class="line">_,pred2 = torch.<span class="built_in">max</span>(y_pred_bad,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred1)</span><br><span class="line"><span class="built_in">print</span>(pred2)</span><br></pre></td></tr></table></figure>

<h1 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png" alt="image-20220318104226578"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png" alt="image-20220318104246948"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiclass problem</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line"></span><br><span class="line">        y_pred = torch.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = NeuralNet2(input_size=<span class="number">28</span>*<span class="number">28</span>,hidden_size=<span class="number">5</span>,num_classes=<span class="number">1</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># option1 create nn modules</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        <span class="comment">#nn.Sigmoid</span></span><br><span class="line">        <span class="comment">#nn.Softmax</span></span><br><span class="line">        <span class="comment">#nn.TanH</span></span><br><span class="line">        <span class="comment">#nn.LeakyReLU</span></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment"># option 2 use activation functions directly in forward pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        <span class="comment">#F.leaky_relu()</span></span><br><span class="line">        self.linear = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = torch.relu(self.linear1(x))</span><br><span class="line">        out = torch.simoid(self.linear2(out))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h1 id="Feed-Forward-Neural-Net"><a href="#Feed-Forward-Neural-Net" class="headerlink" title="Feed-Forward Neural Net"></a>Feed-Forward Neural Net</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># device config</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#hyper parameters</span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br><span class="line"><span class="comment"># DataLoader,Transformation</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">samples,labels = examples.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(samples.shape,labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(samples[i][<span class="number">0</span>],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = NeuralNet(input_size,hidden_size,num_classes)</span><br><span class="line">model=model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">## loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training loo</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#100,1,28,28</span></span><br><span class="line">        <span class="comment">#100,784</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#forward</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#backwards</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.n_ntotal_steps, loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#value,index</span></span><br><span class="line">        _,predictions = torch.<span class="built_in">max</span>(outputs,<span class="number">1</span>)</span><br><span class="line">        n_samples+= labels.shape[<span class="number">0</span>]</span><br><span class="line">        n_correct = (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = <span class="number">100.0</span>* n_correct/n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png" alt="image-20220318145648589"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset has PILImage images of range [0, 1]. </span></span><br><span class="line"><span class="comment"># We transform them to Tensors of normalized range [-1, 1]</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class</span></span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># -&gt; n, 3, 32, 32</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))  <span class="comment"># -&gt; n, 6, 14, 14</span></span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))  <span class="comment"># -&gt; n, 16, 5, 5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)            <span class="comment"># -&gt; n, 400</span></span><br><span class="line">        x = F.relu(self.fc1(x))               <span class="comment"># -&gt; n, 120</span></span><br><span class="line">        x = F.relu(self.fc2(x))               <span class="comment"># -&gt; n, 84</span></span><br><span class="line">        x = self.fc3(x)                       <span class="comment"># -&gt; n, 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet().to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># origin shape: [4, 3, 32, 32] = 4, 3, 1024</span></span><br><span class="line">        <span class="comment"># input_layer: 3 input channels, 6 output channels, 5 kernel size</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line">PATH = <span class="string">&#x27;./cnn.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    n_class_correct = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    n_class_samples = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            pred = predicted[i]</span><br><span class="line">            <span class="keyword">if</span> (label == pred):</span><br><span class="line">                n_class_correct[label] += <span class="number">1</span></span><br><span class="line">            n_class_samples[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        acc = <span class="number">100.0</span> * n_class_correct[i] / n_class_samples[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png" alt="image-20220318145729962"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">mean = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">std = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;data/hymenoptera_data&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=<span class="number">4</span>,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">25</span></span>):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        optimizer.zero_grad()</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Finetuning the convnet ####</span></span><br><span class="line"><span class="comment"># Load a pretrained model and reset final fully connected layer.</span></span><br><span class="line"></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 2.</span></span><br><span class="line"><span class="comment"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span></span><br><span class="line">model.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StepLR Decays the learning rate of each parameter group by gamma every step_size epochs</span></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Learning rate scheduling should be applied after optimizer’s update</span></span><br><span class="line"><span class="comment"># e.g., you should write your code this way:</span></span><br><span class="line"><span class="comment"># for epoch in range(100):</span></span><br><span class="line"><span class="comment">#     train(...)</span></span><br><span class="line"><span class="comment">#     validate(...)</span></span><br><span class="line"><span class="comment">#     scheduler.step()</span></span><br><span class="line"></span><br><span class="line">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### ConvNet as fixed feature extractor ####</span></span><br><span class="line"><span class="comment"># Here, we need to freeze all the network except the final layer.</span></span><br><span class="line"><span class="comment"># We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()</span></span><br><span class="line">model_conv = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that only parameters of final layer are being optimized as</span></span><br><span class="line"><span class="comment"># opposed to before.</span></span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># default `log_dir` is &quot;runs&quot; - we&#x27;ll be more specific here</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/mnist1&#x27;</span>)</span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment"># 28x28</span></span><br><span class="line">hidden_size = <span class="number">500</span> </span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST dataset </span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),  </span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, </span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, </span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">example_data, example_targets = examples.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(example_data)</span><br><span class="line">writer.add_image(<span class="string">&#x27;mnist_images&#x27;</span>, img_grid)</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully connected neural network with one hidden layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.l1 = nn.Linear(input_size, hidden_size) </span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="comment"># no activation and no softmax at the end</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = NeuralNet(input_size, hidden_size, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">writer.add_graph(model, example_data.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">running_correct = <span class="number">0</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        <span class="comment"># origin shape: [100, 1, 28, 28]</span></span><br><span class="line">        <span class="comment"># resized: [100, 784]</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        running_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>, running_loss / <span class="number">100</span>, epoch * n_total_steps + i)</span><br><span class="line">            running_accuracy = running_correct / <span class="number">100</span> / predicted.size(<span class="number">0</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, running_accuracy, epoch * n_total_steps + i)</span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            <span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="comment"># In test phase, we don&#x27;t need to compute gradients (for memory efficiency)</span></span><br><span class="line">class_labels = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        values, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        class_probs_batch = [F.softmax(output, dim=<span class="number">0</span>) <span class="keyword">for</span> output <span class="keyword">in</span> outputs]</span><br><span class="line"></span><br><span class="line">        class_preds.append(class_probs_batch)</span><br><span class="line">        class_labels.append(predicted)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000, 10, and 10000, 1</span></span><br><span class="line">    <span class="comment"># stack concatenates tensors along a new dimension</span></span><br><span class="line">    <span class="comment"># cat concatenates tensors in the given dimension</span></span><br><span class="line">    class_preds = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_preds])</span><br><span class="line">    class_labels = torch.cat(class_labels)</span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network on the 10000 test images: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">    classes = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">        labels_i = class_labels == i</span><br><span class="line">        preds_i = class_preds[:, i]</span><br><span class="line">        writer.add_pr_curve(<span class="built_in">str</span>(i), labels_i, preds_i, global_step=<span class="number">0</span>)</span><br><span class="line">        writer.close()</span><br><span class="line">    <span class="comment">###################################################</span></span><br></pre></td></tr></table></figure>

<h1 id="Save-amp-Load"><a href="#Save-amp-Load" class="headerlink" title="Save &amp; Load"></a>Save &amp; Load</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 3 DIFFERENT METHODS TO REMEMBER:</span></span><br><span class="line"><span class="string"> - torch.save(arg, PATH) # can be model, tensor, or dictionary</span></span><br><span class="line"><span class="string"> - torch.load(PATH)</span></span><br><span class="line"><span class="string"> - torch.load_state_dict(arg)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 2 DIFFERENT WAYS OF SAVING</span></span><br><span class="line"><span class="string"># 1) lazy way: save whole model</span></span><br><span class="line"><span class="string">torch.save(model, PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model class must be defined somewhere</span></span><br><span class="line"><span class="string">model = torch.load(PATH)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) recommended way: save only the state_dict</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model must be created again with parameters</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line"><span class="comment"># train your model...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################save all ######################################</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save and load entire model</span></span><br><span class="line"></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model, FILE)</span><br><span class="line"></span><br><span class="line">loaded_model = torch.load(FILE)</span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> loaded_model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############save only state dict #########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save only state dict</span></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model.state_dict(), FILE)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.state_dict())</span><br><span class="line">loaded_model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">loaded_model.load_state_dict(torch.load(FILE)) <span class="comment"># it takes the loaded dictionary, not the path file itself</span></span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loaded_model.state_dict())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########load checkpoint#####################</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="string">&quot;epoch&quot;</span>: <span class="number">90</span>,</span><br><span class="line"><span class="string">&quot;model_state&quot;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&quot;optim_state&quot;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line">FILE = <span class="string">&quot;checkpoint.pth&quot;</span></span><br><span class="line">torch.save(checkpoint, FILE)</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(FILE)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state&#x27;</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optim_state&#x27;</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line"><span class="comment"># model.train()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remember that you must call model.eval() to set dropout and batch normalization layers </span></span><br><span class="line"><span class="comment"># to evaluation mode before running inference. Failing to do this will yield </span></span><br><span class="line"><span class="comment"># inconsistent inference results. If you wish to resuming training, </span></span><br><span class="line"><span class="comment"># call model.train() to ensure these layers are in training mode.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; SAVING ON GPU/CPU </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 1) Save on GPU, Load on CPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=device))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) Save on GPU, Load on GPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note: Be sure to use the .to(torch.device(&#x27;cuda&#x27;)) function </span></span><br><span class="line"><span class="string"># on all model inputs, too!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 3) Save on CPU, Load on GPU</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># This loads the model to a given GPU device. </span></span><br><span class="line"><span class="string"># Next, be sure to call model.to(torch.device(&#x27;cuda&#x27;)) to convert the model’s parameter tensors to CUDA tensors</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





























      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/ML/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/ML/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" class="post-title-link" itemprop="url">李宏毅-機器學習</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:31" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:31+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-28 19:03:28" itemprop="dateModified" datetime="2022-03-28T19:03:28+08:00">2022-03-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>[toc]</p>
<p><a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw//~hylee/ml/2021-spring.php">https://speech.ee.ntu.edu.tw/\~hylee/ml/2021-spring.php</a></p>
<h1 id="預測本頻道觀看人數-上-機器學習基本概念簡介"><a href="#預測本頻道觀看人數-上-機器學習基本概念簡介" class="headerlink" title="預測本頻道觀看人數 (上) - 機器學習基本概念簡介"></a>預測本頻道觀看人數 (上) - 機器學習基本概念簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/Ye018rCVvOo?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2><p>机器学习就是让机器具备找一个函数的能力。</p>
<p>例子：</p>
<ul>
<li>语音识别</li>
<li>图像识别</li>
<li>α GO</li>
</ul>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031514843.png" alt="image-20220303151401751"></p>
<h2 id="不同类型的函数"><a href="#不同类型的函数" class="headerlink" title="不同类型的函数"></a>不同类型的函数</h2><ul>
<li>Regression: The function outputs a scalar.</li>
<li>Classification: Given options(classes),the function outputs the correct one,</li>
<li>Structured Learning, create something with structure(image,document)</li>
</ul>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031517026.png" alt="image-20220303151702930"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031518554.png" alt="image-20220303151817393"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031520115.png" alt="image-20220303152026894"></p>
<h2 id="How-to-find-a-function-A-Case-Study"><a href="#How-to-find-a-function-A-Case-Study" class="headerlink" title="How to find a function? A Case Study"></a>How to find a function? A Case Study</h2><p><strong>输入Youtube历史资料输出是第二天的浏览人数</strong></p>
<ul>
<li>Function with Unknown Parameters</li>
<li>Define Loss from Training Data</li>
<li>Optimization</li>
</ul>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031527089.png" alt="image-20220303152741986"> i</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031535689.png" alt="image-20220303153527593"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031536619.png" alt="image-20220303153641363"></p>
<p>这个图是error surface</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031542558.png" alt="image-20220303154220441"></p>
<p>步伐取决于斜率和learningrate</p>
<p>Hyperparameters 超参数</p>
<p><strong>Gradient descent</strong>并不是总能停在global minima 而是停在了local minima.</p>
<p>该问题可以被解决，并不是gradient descent真正的通点(插眼，我猜是计算量太大，引出随机梯度下降)</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031551963.png" alt="image-20220303155114875"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031554659.png" alt="image-20220303155404537"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031559165.png" alt="image-20220303155902077"></p>
<h3 id="写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）"><a href="#写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）" class="headerlink" title="写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）"></a>写一个新的函数，使得预测函数更加复杂更加符合实际（一周为周期）</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031606327.png" alt="image-20220303160601224"></p>
<p>似乎观看人数的循环规律止于7之28天之间</p>
<h1 id="預測本頻道觀看人數-下-深度學習基本概念簡介"><a href="#預測本頻道觀看人數-下-深度學習基本概念簡介" class="headerlink" title="預測本頻道觀看人數 (下) - 深度學習基本概念簡介"></a>預測本頻道觀看人數 (下) - 深度學習基本概念簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/bHcJCp2Fyxs?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="线性model太简单了"><a href="#线性model太简单了" class="headerlink" title="线性model太简单了"></a>线性model太简单了</h2><p>这种情况叫做Model Bias</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031619385.png" alt="image-20220303161928270"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031626802.png" alt="image-20220303162651714"></p>
<h2 id="Sigmoid-Function"><a href="#Sigmoid-Function" class="headerlink" title="Sigmoid Function"></a>Sigmoid Function</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031628608.png" alt="image-20220303162856520"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031630037.png" alt="image-20220303162959828"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031632307.png" alt="image-20220303163216198"></p>
<p>用多个feature加到一起去近似</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031634320.png" alt="image-20220303163431237"></p>
<p>引入离散数学：</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031641696.png" alt="image-20220303164128593"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031641091.png" alt="image-20220303164146976"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031643189.png" alt="image-20220303164345044"></p>
<p>最终得到<img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031644291.png" alt="image-20220303164410178"></p>
<h2 id="重新定义一些符号。。。"><a href="#重新定义一些符号。。。" class="headerlink" title="重新定义一些符号。。。"></a>重新定义一些符号。。。</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031646522.png" alt="image-20220303164649426"></p>
<h2 id="至此我们改进了前面提到的机器学习框架的第一步：Function-with-unknown"><a href="#至此我们改进了前面提到的机器学习框架的第一步：Function-with-unknown" class="headerlink" title="至此我们改进了前面提到的机器学习框架的第一步：Function with unknown"></a>至此我们改进了前面提到的机器学习框架的第一步：Function with unknown</h2><p>课外知识：Hard Sigmoid</p>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031653085.png" alt="image-20220303165346995"></p>
<p>先随机找一组θ初始值，以后可以有更好的方法，而不是随机的。之后根据梯度不断更新。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031657021.png" alt="image-20220303165751938"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031658809.png" alt="image-20220303165812728"></p>
<h2 id="Batch"><a href="#Batch" class="headerlink" title="Batch"></a>Batch</h2><p>将data随机分为多个batch，每次学习一个batch</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031700638.png" alt="image-20220303170034535"></p>
<p>每更新一次参数（学习一个batch）叫一次update，每更新完一轮data（学习了多个batch）叫一个epoch。</p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706785.png" alt="image-20220303170611709"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706753.png" alt="image-20220303170642672"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031706502.png" alt="image-20220303170650433"></p>
<h2 id="实战效果"><a href="#实战效果" class="headerlink" title="实战效果"></a>实战效果</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031708375.png" alt="image-20220303170853283"></p>
<h2 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031709367.png" alt="image-20220303170931236"></p>
<h3 id="实战效果-1"><a href="#实战效果-1" class="headerlink" title="实战效果"></a>实战效果</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031711887.png" alt="image-20220303171108801"></p>
<h2 id="此即深度学习"><a href="#此即深度学习" class="headerlink" title="此即深度学习"></a>此即深度学习</h2><p>Deep &#x3D; Many hidden layers</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031716390.png" alt="image-20220303171659257"></p>
<h2 id="为什么不将网络变胖而是把它变深，-留待讲解，插眼。"><a href="#为什么不将网络变胖而是把它变深，-留待讲解，插眼。" class="headerlink" title="为什么不将网络变胖而是把它变深， 留待讲解，插眼。"></a>为什么不将网络变胖而是把它变深， 留待讲解，插眼。</h2><h2 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h2><p>训练数据loss减少，测试数据loss增大</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031720430.png" alt="image-20220303172014330"></p>
<h1 id="機器學習任務攻略"><a href="#機器學習任務攻略" class="headerlink" title="機器學習任務攻略"></a>機器學習任務攻略</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/WeHM2xpYQpw?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Framework-of-ML"><a href="#Framework-of-ML" class="headerlink" title="Framework of ML"></a>Framework of ML</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031738785.png" alt="image-20220303173837677"></p>
<h2 id="General-Guide"><a href="#General-Guide" class="headerlink" title="General Guide"></a>General Guide</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031739014.png" alt="image-20220303173913887"></p>
<h2 id="Model-bias"><a href="#Model-bias" class="headerlink" title="Model bias"></a>Model bias</h2><p>函数弹性不够大</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031742234.png" alt="image-20220303174220131"></p>
<h2 id="Optimization-Issue"><a href="#Optimization-Issue" class="headerlink" title="Optimization Issue"></a>Optimization Issue</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031744637.png" alt="image-20220303174412541"></p>
<h2 id="如何判断是model-Bias-还是Optimization-Issue的原因？"><a href="#如何判断是model-Bias-还是Optimization-Issue的原因？" class="headerlink" title="如何判断是model Bias 还是Optimization Issue的原因？"></a>如何判断是model Bias 还是Optimization Issue的原因？</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031746633.png" alt="image-20220303174638510"></p>
<p><strong>注意training data上的效果， 多出来的层数不进行操作都可以达到20层的效果，弹性应该比他大得多， 说明优化有问题</strong></p>
<p><strong>test data上出现这种情况可能是由于过拟合，但一定要在training data上验证了才可以确定</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031752014.png" alt="image-20220303175225883"></p>
<h2 id="Overfitting-1"><a href="#Overfitting-1" class="headerlink" title="Overfitting"></a>Overfitting</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031755366.png" alt="image-20220303175509274"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031756385.png" alt="image-20220303175647299"></p>
<p>测试数据过少，模型预测函数的自由度太大（由于弹性太大）。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><ol>
<li>增加训练资料</li>
<li>Data augmentation<img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031800246.png" alt="image-20220303180005066"></li>
<li>Constrained model(根据实际情况降低model的弹性)，限制要适量，过度的话就拟合不出来了。<img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031808217.png" alt="image-20220303180822114"></li>
</ol>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031809367.png" alt="image-20220303180949271"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031816811.png" alt="image-20220303181623713"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031820371.png" alt="image-20220303182048257"></p>
<p>选mse最低的不一定就是最好的model</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031824145.png" alt="image-20220303182438942"></p>
<h2 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031830775.png" alt="image-20220303183009660"></p>
<h2 id="N-fold-Cross-Validation"><a href="#N-fold-Cross-Validation" class="headerlink" title="N-fold Cross Validation"></a>N-fold Cross Validation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031833724.png" alt="image-20220303183314584"></p>
<h2 id="Mismatch"><a href="#Mismatch" class="headerlink" title="Mismatch"></a>Mismatch</h2><p>由于没有将一些情况考虑进去，比如春节，data中不包含春节的经验，所以模型在考虑结果时当然不会考虑到春节的影响。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031837920.png" alt="image-20220303183747747"></p>
<h1 id="類神經網路訓練不起來怎麼辦-一-：-局部最小值-local-minima-與鞍點-saddle-point"><a href="#類神經網路訓練不起來怎麼辦-一-：-局部最小值-local-minima-與鞍點-saddle-point" class="headerlink" title="類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)"></a>類神經網路訓練不起來怎麼辦 (一)： 局部最小值 (local minima) 與鞍點 (saddle point)</h1><p>Optimization Fails because……</p>
<h2 id="当-gradient-接近零，学习速度也就接近0，其原因有可能为："><a href="#当-gradient-接近零，学习速度也就接近0，其原因有可能为：" class="headerlink" title="当 gradient 接近零，学习速度也就接近0，其原因有可能为："></a>当 gradient 接近零，学习速度也就接近0，其原因有可能为：</h2><ol>
<li>local minima</li>
<li>saddle point</li>
<li>critical point</li>
</ol>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031858346.png" alt="image-20220303185828184"></p>
<h2 id="如何确定到底是哪个原因？"><a href="#如何确定到底是哪个原因？" class="headerlink" title="如何确定到底是哪个原因？"></a>如何确定到底是哪个原因？</h2><h3 id="Tayler-Series-Approximation"><a href="#Tayler-Series-Approximation" class="headerlink" title="Tayler Series Approximation"></a>Tayler Series Approximation</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031902082.png" alt="image-20220303190237983"></p>
<p>可以根据二阶导数来判断：[ToL]</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031903553.png" alt="image-20220303190333409"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031906974.png" alt="image-20220303190611878"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031907993.png" alt="image-20220303190754882"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031921036.png" alt="image-20220303192157924"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031923676.png" alt="image-20220303192301531"></p>
<p><strong>实际上用到的机会少，因为随着模型规模的增大，二阶倒数太难算了</strong></p>
<h2 id="Saddle-Point-v-s-Local-Minima"><a href="#Saddle-Point-v-s-Local-Minima" class="headerlink" title="Saddle Point v.s. Local Minima"></a>Saddle Point v.s. Local Minima</h2><p>低维的local minima很有可能是高维的saddle point</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031930955.png" alt="image-20220303193046843"></p>
<p>Eigen value 为负的话还是有路可以降低loss</p>
<h1 id="類神經網路訓練不起來怎麼辦-二-：-批次-batch-與動量-momentum"><a href="#類神經網路訓練不起來怎麼辦-二-：-批次-batch-與動量-momentum" class="headerlink" title="類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)"></a>類神經網路訓練不起來怎麼辦 (二)： 批次 (batch) 與動量 (momentum)</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/zzbr1h9sF54?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041030179.png" alt="image-20220304103024053"></p>
<p>每次epoch重新分batch，每次这样的操作叫一次epoch</p>
<h2 id="Small-Batch-vs-Large-Batch"><a href="#Small-Batch-vs-Large-Batch" class="headerlink" title="Small Batch vs Large Batch"></a>Small Batch vs Large Batch</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041033664.png" alt="image-20220304103318420"></p>
<h2 id="考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多"><a href="#考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多" class="headerlink" title="考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多"></a>考虑到GPU平行运算的问题更大的batch不一定就比小的batch花的时间多</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041046728.png" alt="image-20220304104656601"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041048088.png" alt="image-20220304104858844"></p>
<h2 id="更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。"><a href="#更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。" class="headerlink" title="更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。"></a>更新参数所拥有的数据越多，更新越精准，batch越多，更新一次batch的数据越少，噪音越大，然而效果反而更好。</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041054516.png" alt="image-20220304105415406"></p>
<h2 id="即使train-data效果差不多，在test-data里小的batch-size也会得到更好的效果。"><a href="#即使train-data效果差不多，在test-data里小的batch-size也会得到更好的效果。" class="headerlink" title="即使train data效果差不多，在test data里小的batch size也会得到更好的效果。"></a>即使train data效果差不多，在test data里小的batch size也会得到更好的效果。</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041059093.png" alt="image-20220304105932975"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041101148.png" alt="image-20220304110100032"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041101633.png" alt="image-20220304110140510"></p>
<h2 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041103317.png" alt="image-20220304110343178"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041129131.png" alt="image-20220304112920970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041129992.png" alt="image-20220304112957929"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041131368.png" alt="image-20220304113126319"></p>
<p>所以有种说法说惯性受过去所有运动的影响。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041133673.png" alt="image-20220304113311573"></p>
<h1 id="類神經網路訓練不起來怎麼辦-三-：自動調整學習速率-Learning-Rate"><a href="#類神經網路訓練不起來怎麼辦-三-：自動調整學習速率-Learning-Rate" class="headerlink" title="類神經網路訓練不起來怎麼辦 (三)：自動調整學習速率 (Learning Rate)"></a>類神經網路訓練不起來怎麼辦 (三)：自動調整學習速率 (Learning Rate)</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/HYUXEeh3kwY?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="训练卡住了，loss不再下降，并不意味着到了local-minima-或者鞍点之类的"><a href="#训练卡住了，loss不再下降，并不意味着到了local-minima-或者鞍点之类的" class="headerlink" title="训练卡住了，loss不再下降，并不意味着到了local minima 或者鞍点之类的"></a>训练卡住了，loss不再下降，并不意味着到了local minima 或者鞍点之类的</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041136807.png" alt="image-20220304113647688"></p>
<p>这样的点叫Critical point</p>
<h2 id="But-training-can-be-difficult-even-without-critical-points"><a href="#But-training-can-be-difficult-even-without-critical-points" class="headerlink" title="But training can be difficult even without critical points"></a>But training can be difficult even without critical points</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041142539.png" alt="image-20220304114234366"></p>
<p>步伐(Learning rite)太大会在两边回荡，即critical point, 但是步伐太小又会使学习缓慢</p>
<h2 id="Different-Parameters-needs-different-learning-rate"><a href="#Different-Parameters-needs-different-learning-rate" class="headerlink" title="Different Parameters needs different learning rate"></a>Different Parameters needs different learning rate</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041148187.png" alt="image-20220304114813007"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041151498.png" alt="image-20220304115102390"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041151816.png" alt="image-20220304115136720"></p>
<h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041155229.png" alt="image-20220304115536101"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041357009.png" alt="image-20220304135729901"></p>
<h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041445576.png" alt="image-20220304144525383"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041450266.png" alt="image-20220304145033090"></p>
<h2 id="Learning-Rate-Scheduling"><a href="#Learning-Rate-Scheduling" class="headerlink" title="Learning Rate Scheduling"></a>Learning Rate Scheduling</h2><p>随着终点的临近让学习率下降（Learning rate decay）</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041452632.png" alt="image-20220304145205529"></p>
<h2 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h2><p>在transformer中引用了warm up的方法</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041501503.png" alt="image-20220304150125342"></p>
<h2 id="Summary-of-Optimization"><a href="#Summary-of-Optimization" class="headerlink" title="Summary of Optimization"></a>Summary of Optimization</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041505473.png" alt="image-20220304150534374"></p>
<p>两个都考虑所有历史，但是一个更注重方向，一个只注重大小。</p>
<h2 id="Next-Time"><a href="#Next-Time" class="headerlink" title="Next Time"></a>Next Time</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041509834.png" alt="image-20220304150952610"></p>
<h1 id="類神經網路訓練不起來怎麼辦-四-：損失函數-Loss-也可能有影響"><a href="#類神經網路訓練不起來怎麼辦-四-：損失函數-Loss-也可能有影響" class="headerlink" title="類神經網路訓練不起來怎麼辦 (四)：損失函數 (Loss) 也可能有影響"></a>類神經網路訓練不起來怎麼辦 (四)：損失函數 (Loss) 也可能有影響</h1><h2 id="To-learn-more"><a href="#To-learn-more" class="headerlink" title="To learn more"></a>To learn more</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041510324.png" alt="image-20220304151032225"></p>
<h2 id="Classification-as-Regression"><a href="#Classification-as-Regression" class="headerlink" title="Classification as Regression?"></a>Classification as Regression?</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041516201.png" alt="image-20220304151647092"></p>
<p>暗示12关系比较近，13比较远，所以不是很可行，所以选择one-hot编码。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041518549.png" alt="image-20220304151854421"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041520094.png" alt="image-20220304152006992"></p>
<p>SoftMax 将可以为任何值的数值映射到0～1之间</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041523578.png" alt="image-20220304152306438"></p>
<p>当只有两类时softmax和sigmoid是相同的 （插眼，没太懂）</p>
<h2 id="Loss-of-Classification"><a href="#Loss-of-Classification" class="headerlink" title="Loss of Classification"></a>Loss of Classification</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041526528.png" alt="image-20220304152656424"></p>
<p><strong>Minimizing cross-entropy is equivalent to maximizing likelihood.</strong></p>
<p>Pytorch Cross-entropy 内含Softmax</p>
<h2 id="为什么相较于MSE-Cross-entropy更常被用到"><a href="#为什么相较于MSE-Cross-entropy更常被用到" class="headerlink" title="为什么相较于MSE Cross-entropy更常被用到"></a>为什么相较于MSE Cross-entropy更常被用到</h2><p>MSE计算loss不容易从loss大的地方走下来，因为那里梯度太小了</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041535884.png" alt="image-20220304153548703"></p>
<h1 id="類神經網路訓練不起來怎麼辦-五-：-批次標準化-Batch-Normalization-簡介"><a href="#類神經網路訓練不起來怎麼辦-五-：-批次標準化-Batch-Normalization-簡介" class="headerlink" title="類神經網路訓練不起來怎麼辦 (五)： 批次標準化 (Batch Normalization) 簡介"></a>類神經網路訓練不起來怎麼辦 (五)： 批次標準化 (Batch Normalization) 簡介</h1><iframe width="936" height="702" src="https://www.youtube.com/embed/BABPWOkSbLE?list=PLJV\_el3uVTsMhtt7\_Y6sgTHGHp1Vb2P2J" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Changing-Landscape"><a href="#Changing-Landscape" class="headerlink" title="Changing Landscape"></a>Changing Landscape</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041546974.png" alt="image-20220304154632827"></p>
<p>上图很6</p>
<h2 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h2><p>Feature Normalization是上图的解决办法，以下是Feature Normalization的一种方法</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041551595.png" alt="image-20220304155117462"></p>
<p>In general, feature normalization makes gradient scent converge faster.</p>
<h2 id="Considering-Deep-Learning"><a href="#Considering-Deep-Learning" class="headerlink" title="Considering Deep Learning"></a>Considering Deep Learning</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041558809.png" alt="image-20220304155830694"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041600231.png" alt="image-20220304160019106"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041603772.png" alt="image-20220304160308639"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041607876.png" alt="image-20220304160723726"></p>
<h2 id="Batch-Normalization-插眼，没看太懂"><a href="#Batch-Normalization-插眼，没看太懂" class="headerlink" title="Batch Normalization[插眼，没看太懂]"></a>Batch Normalization[插眼，没看太懂]</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041610821.png" alt="image-20220304161028697"></p>
<h3 id="BN-in-Test"><a href="#BN-in-Test" class="headerlink" title="BN in Test"></a>BN in Test</h3><p>在训练时先将测试时没有的参数算出来</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041612417.png" alt="image-20220304161252307"></p>
<h2 id="Internal-Covariate-Shift"><a href="#Internal-Covariate-Shift" class="headerlink" title="Internal Covariate Shift?"></a>Internal Covariate Shift?</h2><p><strong>How Does Batch Normalization help Optimization</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041618922.png" alt="image-20220304161800822"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041621787.png" alt="image-20220304162115627"></p>
<h1 id="卷積神經網路-Convolutional-Neural-Networks-CNN"><a href="#卷積神經網路-Convolutional-Neural-Networks-CNN" class="headerlink" title="卷積神經網路 (Convolutional Neural Networks, CNN)"></a>卷積神經網路 (Convolutional Neural Networks, CNN)</h1><h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041626754.png" alt="image-20220304162622583"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041627457.png" alt="image-20220304162756344"></p>
<h2 id="Observation-1-x2F-x2F-引出receptive-field"><a href="#Observation-1-x2F-x2F-引出receptive-field" class="headerlink" title="Observation 1 &#x2F;&#x2F;引出receptive field"></a>Observation 1 &#x2F;&#x2F;引出receptive field</h2><p>y隐藏层一个节点观测图片的一小部分</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041630573.png" alt="image-20220304163005423"></p>
<h2 id="Simplification-1"><a href="#Simplification-1" class="headerlink" title="Simplification 1"></a>Simplification 1</h2><h3 id="receptive-field"><a href="#receptive-field" class="headerlink" title="receptive field"></a>receptive field</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041634243.png" alt="image-20220304163438134"></p>
<ul>
<li>Can different neurons have different sizes of receptive field?</li>
<li>Cover only some channels.</li>
<li>Not square receptive field?</li>
</ul>
<h3 id="Typical-Setting"><a href="#Typical-Setting" class="headerlink" title="Typical Setting"></a>Typical Setting</h3><p><strong>Kernel size</strong></p>
<p><strong>stride</strong></p>
<p><strong>overlap</strong></p>
<p><strong>padding</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041643682.png" alt="image-20220304164301547"></p>
<h2 id="Observation-2-x2F-x2F-引出filter"><a href="#Observation-2-x2F-x2F-引出filter" class="headerlink" title="Observation 2 &#x2F;&#x2F;引出filter"></a>Observation 2 &#x2F;&#x2F;引出filter</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041644756.png" alt="image-20220304164435601"></p>
<h2 id="Simplification-2"><a href="#Simplification-2" class="headerlink" title="Simplification 2"></a>Simplification 2</h2><p>两个节点照顾的位置不一样，但是参数是一样的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041647931.png" alt="image-20220304164731795"></p>
<h3 id="Typical-Setting-1"><a href="#Typical-Setting-1" class="headerlink" title="Typical Setting"></a>Typical Setting</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041649596.png" alt="image-20220304164923467"></p>
<h2 id="Benefit-of-Convolutional-Layer"><a href="#Benefit-of-Convolutional-Layer" class="headerlink" title="Benefit of Convolutional Layer"></a>Benefit of Convolutional Layer</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041651892.png" alt="image-20220304165101777"></p>
<p>弹性逐渐减小</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041651701.png" alt="image-20220304165134571"></p>
<h2 id="Convolutional-layer-x2F-x2F-另一种说法"><a href="#Convolutional-layer-x2F-x2F-另一种说法" class="headerlink" title="Convolutional layer &#x2F;&#x2F;另一种说法"></a>Convolutional layer &#x2F;&#x2F;另一种说法</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041656607.png" alt="image-20220304165611474"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041656649.png" alt="image-20220304165653532"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041657119.png" alt="image-20220304165700992"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041658075.png" alt="image-20220304165828912"></p>
<p>虽然只有3*3，但是后面的层的节点考虑到的会更大</p>
<h2 id="Comparison-of-Two-Stories"><a href="#Comparison-of-Two-Stories" class="headerlink" title="Comparison of Two Stories"></a>Comparison of Two Stories</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041701162.png" alt="image-20220304170144042"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041702290.png" alt="image-20220304170236195"></p>
<h2 id="Observation-3-x2F-x2F-引出pooling"><a href="#Observation-3-x2F-x2F-引出pooling" class="headerlink" title="Observation 3 &#x2F;&#x2F;引出pooling"></a>Observation 3 &#x2F;&#x2F;引出pooling</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041704770.png" alt="image-20220304170412626"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041705375.png" alt="image-20220304170500275"></p>
<p>Pooling 把图片变小</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041705189.png" alt="image-20220304170540035"></p>
<p>最主要的理由是减少运算量</p>
<h2 id="The-Whole-CNN"><a href="#The-Whole-CNN" class="headerlink" title="The Whole CNN"></a>The Whole CNN</h2><h3 id="Flatten-把所有数值拉直变成向量"><a href="#Flatten-把所有数值拉直变成向量" class="headerlink" title="Flatten 把所有数值拉直变成向量"></a>Flatten 把所有数值拉直变成向量</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041707777.png" alt="image-20220304170715646"></p>
<h2 id="Application-Playing-Go"><a href="#Application-Playing-Go" class="headerlink" title="Application: Playing Go"></a>Application: Playing Go</h2><p>下围棋是一个分类的问题</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041709589.png" alt="image-20220304170916451"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041710880.png" alt="image-20220304171007739"></p>
<p>α Go每个棋盘上的位置都有48个属性</p>
<h2 id="Why-CNN-for-GO-playing"><a href="#Why-CNN-for-GO-playing" class="headerlink" title="Why CNN for GO playing"></a>Why CNN for GO playing</h2><p>上面讲的observation跟围棋有相似性。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041712147.png" alt="image-20220304171251950"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041713448.png" alt="image-20220304171339209"></p>
<p>但要注意下围棋不适合用pooling</p>
<h2 id="More-Applications"><a href="#More-Applications" class="headerlink" title="More Applications"></a>More Applications</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041714210.png" alt="image-20220304171414066"></p>
<h2 id="To-learn-more-1"><a href="#To-learn-more-1" class="headerlink" title="To learn more"></a>To learn more</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203041714142.png" alt="image-20220304171451982"></p>
<h1 id="自注意力機制-Self-attention-上"><a href="#自注意力機制-Self-attention-上" class="headerlink" title="自注意力機制 (Self-attention) (上)"></a>自注意力機制 (Self-attention) (上)</h1><p>regression输出是一个数值 输入是一个向量</p>
<p>classification 输出是一个类别 输入是一个向量</p>
<p>如果更复杂？</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071043556.png" alt="image-20220307104316456"></p>
<h2 id="Vector-as-Input"><a href="#Vector-as-Input" class="headerlink" title="Vector as Input"></a>Vector as Input</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071045288.png" alt="image-20220307104507177"></p>
<p>语音，社交网络，分子结构等可以转化为多个向量作为输入</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071047811.png" alt="image-20220307104723704"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071047867.png" alt="image-20220307104742682"></p>
<h2 id="What-is-the-output"><a href="#What-is-the-output" class="headerlink" title="What is the output?"></a>What is the output?</h2><h3 id="输入数量与输出数量一致"><a href="#输入数量与输出数量一致" class="headerlink" title="输入数量与输出数量一致"></a>输入数量与输出数量一致</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071051455.png" alt="image-20220307105157313"></p>
<h3 id="输入输出数量不一致"><a href="#输入输出数量不一致" class="headerlink" title="输入输出数量不一致"></a>输入输出数量不一致</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071054236.png" alt="image-20220307105424097"></p>
<h2 id="Sequence-Labeling"><a href="#Sequence-Labeling" class="headerlink" title="Sequence Labeling"></a>Sequence Labeling</h2><p>输入与输出一样多</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071058945.png" alt="image-20220307105846809"></p>
<p><strong>I saw a saw</strong></p>
<p>不能用fully-connected network，因为同一个词汇出现两次对于fully-connected network 来说是一样的,所以要用窗口，</p>
<p>但是由于输入长度不一定，窗口也就不一定，由此引出self -attention</p>
<h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071111335.png" alt="image-20220307111131085"></p>
<h2 id="Part-of-attention-network"><a href="#Part-of-attention-network" class="headerlink" title="Part of attention network"></a>Part of attention network</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071117302.png" alt="image-20220307111704195"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071125941.png" alt="image-20220307112506872"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071125982.png" alt="image-20220307112523817"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071127259.png" alt="image-20220307112724128"></p>
<p>谁的关联性更大，其向量就会更占支配地位，b1就会更像谁</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071131405.png" alt="image-20220307113107052"></p>
<h1 id="自注意力機制-Self-attention-下"><a href="#自注意力機制-Self-attention-下" class="headerlink" title="自注意力機制 (Self-attention) (下)"></a>自注意力機制 (Self-attention) (下)</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071137892.png" alt="image-20220307113754724"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071146043.png" alt="image-20220307114609872"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071149976.png" alt="image-20220307114954832"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071354645.png" alt="image-20220307135416518"></p>
<h2 id="Multi-head-self-attention"><a href="#Multi-head-self-attention" class="headerlink" title="Multi-head self-attention"></a>Multi-head self-attention</h2><p>得到q<sup>i</sup>,k<sup>i</sup>,v<sup>i</sup>后再乘两个矩阵得到两个结果。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071400284.png" alt="image-20220307140025135"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071401579.png" alt="image-20220307140123414"></p>
<h2 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h2><p>之前的公式没有结合位置信息</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071408609.png" alt="image-20220307140832441"></p>
<p>这里每个位置的向量是订好的</p>
<p>后来有了新的动态生成的办法</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071410740.png" alt="image-20220307141038425"></p>
<h2 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071411275.png" alt="image-20220307141125110"></p>
<h3 id="Speech"><a href="#Speech" class="headerlink" title="Speech"></a>Speech</h3><p>用于语音识别时要有所更改，因为语音识别所生成的向量太大了，如果结合所有输入的话计算量可能接受不了。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071414502.png" alt="image-20220307141400333"></p>
<h3 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071415634.png" alt="image-20220307141521417"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071415451.png" alt="image-20220307141535227"></p>
<h3 id="Self-attention-for-Graph"><a href="#Self-attention-for-Graph" class="headerlink" title="Self-attention for Graph"></a>Self-attention for Graph</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071433516.png" alt="image-20220307143348377"></p>
<h4 id="To-Learn-more-about-GNN"><a href="#To-Learn-more-about-GNN" class="headerlink" title="To Learn more about GNN"></a>To Learn more about GNN</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071434204.png" alt="image-20220307143445063"></p>
<h2 id="Self-attention-v-s-CNN"><a href="#Self-attention-v-s-CNN" class="headerlink" title="Self-attention v.s. CNN"></a>Self-attention v.s. CNN</h2><p>CNN 可以看作Self-attention的子集，</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071418941.png" alt="image-20220307141830783"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071418164.png" alt="image-20220307141815004"></p>
<p>资料少时用CNN，多时用self-attention，因为self-attention弹性更大（插眼，为啥？），需要的资料更多。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071421128.png" alt="image-20220307142129968"></p>
<h2 id="Self-attention-vs-RNN"><a href="#Self-attention-vs-RNN" class="headerlink" title="Self-attention vs RNN"></a>Self-attention vs RNN</h2><p>RNN：</p>
<ul>
<li>很难考虑远处的信息</li>
<li>不是平行的</li>
</ul>
<p>self-attention:</p>
<ul>
<li>相反</li>
</ul>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071430856.png" alt="image-20220307143053684"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071431403.png" alt="image-20220307143107347"></p>
<h3 id="To-learn-more-about-RNN"><a href="#To-learn-more-about-RNN" class="headerlink" title="To learn more about RNN"></a>To learn more about RNN</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071431895.png" alt="image-20220307143122783"></p>
<h2 id="To-Learn-More"><a href="#To-Learn-More" class="headerlink" title="To Learn More"></a>To Learn More</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071435335.png" alt="image-20220307143509187"></p>
<h1 id="Transformer-上-Encoder"><a href="#Transformer-上-Encoder" class="headerlink" title="Transformer(上) Encoder"></a>Transformer(上) Encoder</h1><h2 id="Sequence-to-sequence’s-application"><a href="#Sequence-to-sequence’s-application" class="headerlink" title="Sequence-to-sequence’s application"></a>Sequence-to-sequence’s application</h2><p>transformer 是一个Sequence-to-sequence(Swq2seq) model</p>
<p>输出长度是由模型决定的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071509244.png" alt="image-20220307150909089"></p>
<p>由闽南语音直接转为汉字</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071510052.png" alt="image-20220307151048819"></p>
<p>在翻译倒装句时错误率会更高</p>
<h3 id="Seq2seq-for-Chatbot"><a href="#Seq2seq-for-Chatbot" class="headerlink" title="Seq2seq for Chatbot"></a>Seq2seq for Chatbot</h3><p>Question Answering 可以理解为Seq2seq model 的问题</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071519000.png" alt="image-20220307151925810"></p>
<h3 id="Seq2seq-for-Syntactic-parsing"><a href="#Seq2seq-for-Syntactic-parsing" class="headerlink" title="Seq2seq for Syntactic parsing"></a>Seq2seq for Syntactic parsing</h3><p>输入句子输出文法分析树</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071523121.png" alt="image-20220307152313995"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071523984.png" alt="image-20220307152348890"></p>
<p>将文法视作一种语言用翻译的模型得到结果</p>
<h3 id="seq2seq-for-multi-label-classification"><a href="#seq2seq-for-multi-label-classification" class="headerlink" title="seq2seq for multi-label classification"></a>seq2seq for multi-label classification</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071527897.png" alt="image-20220307152715773"></p>
<h3 id="Seq2Seq-for-Object-Detection"><a href="#Seq2Seq-for-Object-Detection" class="headerlink" title="Seq2Seq for Object Detection"></a>Seq2Seq for Object Detection</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071527752.png" alt="image-20220307152749508"></p>
<h2 id="Seq2seq"><a href="#Seq2seq" class="headerlink" title="Seq2seq"></a>Seq2seq</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071529867.png" alt="image-20220307152903671"></p>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071530886.png" alt="image-20220307153008711"></p>
<p>先讲个其他的，再回来进行比对</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071531592.png" alt="image-20220307153109367"></p>
<p>Block原来更加复杂：</p>
<p>batch normalization:对不同example 不同feature同一dimension 计算mean 和 standard deviation，在这里没有用到，用到的是layer normalization,他是对不同统一example 同一feature的不同dimension计算mean 和standard deviation.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071540252.png" alt="image-20220307154059043"></p>
<p>最后回到encoder的结构，其实是一样的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071542817.png" alt="image-20220307154250587"></p>
<h2 id="To-learn-more-2"><a href="#To-learn-more-2" class="headerlink" title="To learn more"></a>To learn more</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071543029.png" alt="image-20220307154339897"></p>
<h1 id="Transformer-下-Decoder"><a href="#Transformer-下-Decoder" class="headerlink" title="Transformer (下) Decoder"></a>Transformer (下) Decoder</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071545979.png" alt="image-20220307154510783"></p>
<h2 id="Autoregressive-Speech-Recognition-as-example-AT"><a href="#Autoregressive-Speech-Recognition-as-example-AT" class="headerlink" title="Autoregressive(Speech Recognition as example)(AT)"></a>Autoregressive(Speech Recognition as example)(AT)</h2><p>一步错步步错</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071602817.png" alt="image-20220307160214593"></p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071602020.png" alt="image-20220307160257798"></p>
<p>除了篮框这部分其他的和encoder很像，除了multi-attention 加了mask</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071604306.png" alt="image-20220307160410167"></p>
<h3 id="Masked-multi-head-attention"><a href="#Masked-multi-head-attention" class="headerlink" title="Masked multi-head attention"></a>Masked multi-head attention</h3><p>在计算b2时没办法把考虑a3，a4，因为还没生成出来，模型是从左至右计算的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071607166.png" alt="image-20220307160750850"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071608463.png" alt="image-20220307160804347"></p>
<h3 id="Stop-Token-We-don’t-know-the-correct-output-length"><a href="#Stop-Token-We-don’t-know-the-correct-output-length" class="headerlink" title="Stop Token: We don’t know the correct output length"></a>Stop Token: We don’t know the correct output length</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071614100.png" alt="image-20220307161457882"></p>
<h2 id="Non-autoregressive-NAT"><a href="#Non-autoregressive-NAT" class="headerlink" title="Non-autoregressive(NAT)"></a>Non-autoregressive(NAT)</h2><p>优势在于平行输出，所以时间会变快。而且可以控制输出长度。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071621756.png" alt="image-20220307162150521"></p>
<h3 id="To-learn-more-about-nat"><a href="#To-learn-more-about-nat" class="headerlink" title="To learn more about nat"></a>To learn more about nat</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071622824.png" alt="image-20220307162208729"></p>
<h2 id="Encode-Decoder"><a href="#Encode-Decoder" class="headerlink" title="Encode-Decoder"></a>Encode-Decoder</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071623270.png" alt="image-20220307162308131"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071627857.png" alt="image-20220307162714666"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071629321.png" alt="image-20220307162926098"></p>
<h3 id="Cross-Attention"><a href="#Cross-Attention" class="headerlink" title="Cross Attention"></a>Cross Attention</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071634484.png" alt="image-20220307163404206"></p>
<h3 id="train"><a href="#train" class="headerlink" title="train"></a>train</h3><p>使用已经有结果的数据</p>
<p>给正确答案，希望输出越接近越好</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071643365.png" alt="image-20220307164309157"></p>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071729215.png" alt="image-20220307172946935"></p>
<h2 id="tips-about-train-seq2seq"><a href="#tips-about-train-seq2seq" class="headerlink" title="tips about train seq2seq"></a>tips about train seq2seq</h2><h3 id="Copy-Mechanism"><a href="#Copy-Mechanism" class="headerlink" title="Copy Mechanism"></a>Copy Mechanism</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071732280.png" alt="image-20220307173231148"></p>
<h4 id="To-learn-more-3"><a href="#To-learn-more-3" class="headerlink" title="To learn more"></a>To learn more</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071734723.png" alt="image-20220307173455607"></p>
<h3 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071733236.png" alt="image-20220307173304080"></p>
<h3 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h3><p>强迫attention有一定固定的行为，比如语音识别必须由左向右</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071743328.png" alt="image-20220307174338215"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071745616.png" alt="image-20220307174550435"></p>
<h2 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h2><p>尝试多种可能性</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203071754641.png" alt="image-20220307175417463"></p>
<p>有争议，很多人说很烂</p>
<p>因为有可能说重复的话，但是加入一点杂音反而会好很多，说明分数最高的路不一定就是最好的答案。</p>
<p>有明确答案的任务效果更好，需要发散思路的问题可能更需要加入杂音。</p>
<p>另外，tts需要加入杂音才能更好的产生结果</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101537685.png" alt="image-20220310153700434"></p>
<h2 id="Optimizing-Evaluation-Metrics"><a href="#Optimizing-Evaluation-Metrics" class="headerlink" title="Optimizing Evaluation Metrics?"></a>Optimizing Evaluation Metrics?</h2><p>训练用Cross entry评价用BLEU score.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101540023.png" alt="image-20220310154040833"></p>
<h2 id="训练和测试不一致（Exposure-bias）"><a href="#训练和测试不一致（Exposure-bias）" class="headerlink" title="训练和测试不一致（Exposure bias）"></a>训练和测试不一致（Exposure bias）</h2><p>训练永远看到的是正确的东西,测试会有错的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101546322.png" alt="image-20220310154657069"></p>
<h3 id="Scheduled-Sampling"><a href="#Scheduled-Sampling" class="headerlink" title="Scheduled Sampling"></a>Scheduled Sampling</h3><p>训练时给点错误的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101547120.png" alt="image-20220310154734903"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-一-–-基本概念介紹"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-一-–-基本概念介紹" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (一) – 基本概念介紹"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (一) – 基本概念介紹</h1><h2 id="Network-as-Generator"><a href="#Network-as-Generator" class="headerlink" title="Network as Generator"></a>Network as Generator</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101610056.png" alt="image-20220310161015930"></p>
<p>两个结合输出一个新的分布。</p>
<h2 id="为什么要输出一个分布？"><a href="#为什么要输出一个分布？" class="headerlink" title="为什么要输出一个分布？"></a>为什么要输出一个分布？</h2><p>由于问题的发散产生了分支（过于发散），这时往往会需要输出一个分支</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101614894.png" alt="image-20220310161428703"></p>
<p>训练中可能会出现同时向左向右转的现象</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101616626.png" alt="image-20220310161619452"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101619793.png" alt="image-20220310161925614"></p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><h3 id="Anime-Face-Generation"><a href="#Anime-Face-Generation" class="headerlink" title="Anime Face Generation"></a>Anime Face Generation</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101623774.png" alt="image-20220310162322633"></p>
<h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101625320.png" alt="image-20220310162507160"></p>
<h3 id="Basic-Idea-of-GAN"><a href="#Basic-Idea-of-GAN" class="headerlink" title="Basic Idea of GAN"></a>Basic Idea of GAN</h3><p>两相竞争</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101630765.png" alt="image-20220310163007559"></p>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>discriminator不断的将生成的和实际的图片分类出来，generator为了不被分辨出来儿不断进步</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101633177.png" alt="image-20220310163311970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101637180.png" alt="image-20220310163731041"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101639482.png" alt="image-20220310163904307"></p>
<h2 id="Progressive-GAN"><a href="#Progressive-GAN" class="headerlink" title="Progressive GAN"></a>Progressive GAN</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203101644579.png" alt="image-20220310164410293"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-二-–-理論介紹與WGAN"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-二-–-理論介紹與WGAN" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (二) – 理論介紹與WGAN"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (二) – 理論介紹與WGAN</h1><h2 id="Our-Objective"><a href="#Our-Objective" class="headerlink" title="Our Objective"></a>Our Objective</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111401553.png" alt="image-20220311140158414"></p>
<p><strong>But it is too hard to compute the divergence</strong></p>
<h2 id="How-to-solve-the-problem-of-divergency-sample-and-discriminator"><a href="#How-to-solve-the-problem-of-divergency-sample-and-discriminator" class="headerlink" title="How to solve the problem of divergency(sample and discriminator)"></a>How to solve the problem of divergency(sample and discriminator)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111407430.png" alt="image-20220311140722260"></p>
<h3 id="Discriminator-1"><a href="#Discriminator-1" class="headerlink" title="Discriminator"></a>Discriminator</h3><p>D<sup>*</sup> 与divergence 相关</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111414252.png" alt="image-20220311141404996"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111417233.png" alt="image-20220311141710097"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111419204.png" alt="image-20220311141916086"></p>
<h2 id="can-we-use-other-divergence"><a href="#can-we-use-other-divergence" class="headerlink" title="can we use other divergence?"></a>can we use other divergence?</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111420998.png" alt="image-20220311142056838"></p>
<h2 id="Tips-of-gan"><a href="#Tips-of-gan" class="headerlink" title="Tips of gan"></a>Tips of gan</h2><h3 id="JS-divergence-is-not-suitable"><a href="#JS-divergence-is-not-suitable" class="headerlink" title="JS divergence is not suitable"></a>JS divergence is not suitable</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111427871.png" alt="image-20220311142740738"></p>
<p>如果取样太少的话，命名generator已经取得了进步但是无法在discriminator 体现不出来</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111428345.png" alt="image-20220311142826197"></p>
<p>只要没有相交js divergence就为log2，但是有可能已经进步了，只不过没有达到那个程度。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111434806.png" alt="image-20220311143400651"></p>
<h2 id="Wasserstein-distance"><a href="#Wasserstein-distance" class="headerlink" title="Wasserstein distance"></a>Wasserstein distance</h2><p>让一个分布与另一个分布重合所用的精力</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111439317.png" alt="image-20220311143947176"></p>
<p>但是当分布复杂时，想让它们重合有不同的moving plan,所以需要穷举。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111442061.png" alt="image-20220311144159911"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111445703.png" alt="image-20220311144501598"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111447842.png" alt="image-20220311144703645"></p>
<h2 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111454545.png" alt="image-20220311145434422"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111459051.png" alt="image-20220311145930884"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-三-–-生成器效能評估與條件式生成"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-三-–-生成器效能評估與條件式生成" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (三) – 生成器效能評估與條件式生成"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (三) – 生成器效能評估與條件式生成</h1><h2 id="GAN-is-still-challenging"><a href="#GAN-is-still-challenging" class="headerlink" title="GAN is still challenging"></a>GAN is still challenging</h2><p>如果一方停下了，没办法再前进的话，另一方也会停下。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111503152.png" alt="image-20220311150342006"></p>
<h2 id="GAN-for-Sequence-Generation"><a href="#GAN-for-Sequence-Generation" class="headerlink" title="GAN for Sequence Generation"></a>GAN for Sequence Generation</h2><p>如果有多个输出且去max的话，那么其他输出的参数因参数的变化而增长是无法体现出来的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111511598.png" alt="image-20220311151119409"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111512967.png" alt="image-20220311151243838"></p>
<h3 id="For-more"><a href="#For-more" class="headerlink" title="For more"></a>For more</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111514047.png" alt="image-20220311151415941"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111514548.png" alt="image-20220311151423436"></p>
<h2 id="为什么用GAN"><a href="#为什么用GAN" class="headerlink" title="为什么用GAN"></a>为什么用GAN</h2><p>因为GAN目前效果比VAE FLOW好。。。即使是它比较难train也比其他的方法也不会难太多</p>
<h2 id="Possible-Solution"><a href="#Possible-Solution" class="headerlink" title="Possible Solution"></a>Possible Solution</h2><p>Train一个输入向量，输出图片的模型</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111518742.png" alt="image-20220311151853551"></p>
<h2 id="Quality-of-Image"><a href="#Quality-of-Image" class="headerlink" title="Quality of Image"></a>Quality of Image</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111520886.png" alt="image-20220311152042659"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111522292.png" alt="image-20220311152253198"></p>
<h2 id="Diversity-Mode-Collapse"><a href="#Diversity-Mode-Collapse" class="headerlink" title="Diversity - Mode Collapse"></a>Diversity - Mode Collapse</h2><p>Discriminator万一有弱点被generator抓到的话。。。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111524890.png" alt="image-20220311152459572"></p>
<h2 id="Diversity-Mode-Dropping"><a href="#Diversity-Mode-Dropping" class="headerlink" title="Diversity - Mode Dropping"></a>Diversity - Mode Dropping</h2><p>看似分布和质量都合理，但是其实真实数据比这更大</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111527252.png" alt="image-20220311152716994"></p>
<p>用分类器分类的结果如果过去集中则可能是这个问题</p>
<p>如果够平均则可能没有这个问题。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111529302.png" alt="image-20220311152928194"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111529694.png" alt="image-20220311152935580"></p>
<h2 id="Frechet-inception-Distance-FID-插眼"><a href="#Frechet-inception-Distance-FID-插眼" class="headerlink" title="Frechet inception Distance(FID)(插眼)"></a>Frechet inception Distance(FID)(插眼)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111538202.png" alt="image-20220311153848062"></p>
<h2 id="We-don’t-want-memory-GAN"><a href="#We-don’t-want-memory-GAN" class="headerlink" title="We don’t want memory GAN"></a>We don’t want memory GAN</h2><p>产生的跟训练资料的一模一样是不行的</p>
<h2 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h2><h3 id="Text-to-image"><a href="#Text-to-image" class="headerlink" title="Text to image"></a>Text to image</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111546613.png" alt="image-20220311154649317"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111549517.png" alt="image-20220311154918368"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111551107.png" alt="image-20220311155116997"></p>
<h2 id="Application-1"><a href="#Application-1" class="headerlink" title="Application"></a>Application</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111555415.png" alt="image-20220311155544191"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111556838.png" alt="image-20220311155633673"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111558823.png" alt="image-20220311155821568"></p>
<h1 id="生成式對抗網路-Generative-Adversarial-Network-GAN-四-–-Cycle-GAN"><a href="#生成式對抗網路-Generative-Adversarial-Network-GAN-四-–-Cycle-GAN" class="headerlink" title="生成式對抗網路 (Generative Adversarial Network, GAN) (四) – Cycle GAN"></a>生成式對抗網路 (Generative Adversarial Network, GAN) (四) – Cycle GAN</h1><h2 id="Learning-from-Unpaired-Data（无监督）"><a href="#Learning-from-Unpaired-Data（无监督）" class="headerlink" title="Learning from Unpaired Data（无监督）"></a>Learning from Unpaired Data（无监督）</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111609272.png" alt="image-20220311160950161"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111612339.png" alt="image-20220311161251161"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111613065.png" alt="image-20220311161332878"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111615863.png" alt="image-20220311161525671"></p>
<p>没有成对的资料来训练</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111617412.png" alt="image-20220311161726234"></p>
<p>由于有了还原，产生的图片就不能和输入差太多（保证有一些关系（即使很奇怪（暂时还没啥好解法）））</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111619453.png" alt="image-20220311161900285"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111624332.png" alt="image-20220311162411169"></p>
<h2 id="more"><a href="#more" class="headerlink" title="more"></a>more</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111624254.png" alt="image-20220311162435070"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111625776.png" alt="image-20220311162524575"></p>
<h2 id="SELFIE2ANIME"><a href="#SELFIE2ANIME" class="headerlink" title="SELFIE2ANIME"></a>SELFIE2ANIME</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111626226.png" alt="image-20220311162646942"></p>
<h2 id="Text-Style-Transfer"><a href="#Text-Style-Transfer" class="headerlink" title="Text Style Transfer"></a>Text Style Transfer</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111629172.png" alt="image-20220311162931032"></p>
<p>Other</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111631772.png" alt="image-20220311163122634"></p>
<h1 id="自督導式學習-Self-supervised-Learning-一-–-芝麻街與進擊的巨人"><a href="#自督導式學習-Self-supervised-Learning-一-–-芝麻街與進擊的巨人" class="headerlink" title="自督導式學習 (Self-supervised Learning) (一) – 芝麻街與進擊的巨人"></a>自督導式學習 (Self-supervised Learning) (一) – 芝麻街與進擊的巨人</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111636506.png" alt="image-20220311163636334"></p>
<h1 id="自督導式學習-Self-supervised-Learning-二-–-BERT簡介"><a href="#自督導式學習-Self-supervised-Learning-二-–-BERT簡介" class="headerlink" title="自督導式學習 (Self-supervised Learning) (二) – BERT簡介"></a>自督導式學習 (Self-supervised Learning) (二) – BERT簡介</h1><h2 id="Self-supervised-Learning"><a href="#Self-supervised-Learning" class="headerlink" title="Self-supervised Learning"></a>Self-supervised Learning</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111653796.png" alt="image-20220311165359636"></p>
<h2 id="Masking-Input"><a href="#Masking-Input" class="headerlink" title="Masking Input"></a>Masking Input</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111700481.png" alt="image-20220311170046338"></p>
<h2 id="Next-Sentence-Prediction"><a href="#Next-Sentence-Prediction" class="headerlink" title="Next Sentence Prediction"></a>Next Sentence Prediction</h2><p>分辨两个句子是不是该接在一起</p>
<p>被认为不是很有用，model没有学到很多东西</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111706915.png" alt="image-20220311170618799"></p>
<h2 id="Downstream-Tasks-将前面的训练结果用在其他训练上"><a href="#Downstream-Tasks-将前面的训练结果用在其他训练上" class="headerlink" title="Downstream Tasks 将前面的训练结果用在其他训练上"></a>Downstream Tasks 将前面的训练结果用在其他训练上</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111709607.png" alt="image-20220311170912465"></p>
<h2 id="GLUE"><a href="#GLUE" class="headerlink" title="GLUE"></a>GLUE</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111710742.png" alt="image-20220311171023561"></p>
<h2 id="How-to-use-BERT"><a href="#How-to-use-BERT" class="headerlink" title="How to use BERT"></a>How to use BERT</h2><h3 id="Case-1-input-asq-output-class"><a href="#Case-1-input-asq-output-class" class="headerlink" title="Case 1 input asq output class"></a>Case 1 input asq output class</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111717475.png" alt="image-20220311171722364"></p>
<h3 id="Case-2-input-seq-output-same-as-seq"><a href="#Case-2-input-seq-output-same-as-seq" class="headerlink" title="Case 2 input seq output same as seq"></a>Case 2 input seq output same as seq</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111722660.png" alt="image-20220311172214528"></p>
<h3 id="Case-3-input-two-seq-output-class"><a href="#Case-3-input-two-seq-output-class" class="headerlink" title="Case 3 input two seq output class"></a>Case 3 input two seq output class</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111725901.png" alt="image-20220311172540773"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111725457.png" alt="image-20220311172558350"></p>
<h3 id="Case-4-input-document-and-query-output-answer"><a href="#Case-4-input-document-and-query-output-answer" class="headerlink" title="Case 4 input document and query output  answer"></a>Case 4 input document and query output  answer</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111728498.png" alt="image-20220311172832343"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111732272.png" alt="image-20220311173255130"></p>
<h2 id="Training-BERT-is-challenging"><a href="#Training-BERT-is-challenging" class="headerlink" title="Training BERT is challenging"></a>Training BERT is challenging</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111738014.png" alt="image-20220311173804867"></p>
<h2 id="BERT-Embryology-胚胎学"><a href="#BERT-Embryology-胚胎学" class="headerlink" title="BERT Embryology(胚胎学)"></a>BERT Embryology(胚胎学)</h2><p>了解BERT学习到知识的细节</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111739932.png" alt="image-20220311173936718"></p>
<h2 id="Pre-training-a-seq2seq-model"><a href="#Pre-training-a-seq2seq-model" class="headerlink" title="Pre-training a seq2seq model"></a>Pre-training a seq2seq model</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111740402.png" alt="image-20220311174051298"></p>
<p>输入encoder弄坏的数据，decoder输出没坏的数据</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203111741904.png" alt="image-20220311174144788"></p>
<h1 id="自督導式學習-Self-supervised-Learning-三-–-BERT的奇聞軼事"><a href="#自督導式學習-Self-supervised-Learning-三-–-BERT的奇聞軼事" class="headerlink" title="自督導式學習 (Self-supervised Learning) (三) – BERT的奇聞軼事"></a>自督導式學習 (Self-supervised Learning) (三) – BERT的奇聞軼事</h1><h2 id="Why-does-BERT-work"><a href="#Why-does-BERT-work" class="headerlink" title="Why does BERT work"></a>Why does BERT work</h2><p>同一个字有不同的意义</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141054271.png" alt="image-20220314105449128"></p>
<p>一个词汇的意思取决于它的上下文</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141103522.png" alt="image-20220314110345369"></p>
<h2 id="Applying-BERT-to-protein-DNA-music-classification"><a href="#Applying-BERT-to-protein-DNA-music-classification" class="headerlink" title="Applying BERT to protein,DNA,music classification"></a>Applying BERT to protein,DNA,music classification</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141115093.png" alt="image-20220314111554974"> </p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141116489.png" alt="image-20220314111616272"></p>
<h2 id="Multi-lingual-BERT"><a href="#Multi-lingual-BERT" class="headerlink" title="Multi-lingual BERT"></a>Multi-lingual BERT</h2><p>训练在英文反而在中文的test上取得了进步</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141119777.png" alt="image-20220314111954632"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141120398.png" alt="image-20220314112004247"></p>
<h3 id="Cross-lingual-Alignment-一种解释"><a href="#Cross-lingual-Alignment-一种解释" class="headerlink" title="Cross-lingual Alignment(一种解释)"></a>Cross-lingual Alignment(一种解释)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141122448.png" alt="image-20220314112242298"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141127924.png" alt="image-20220314112701789"></p>
<p>似乎不同语言向量的差异就是语言的信息？</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141128385.png" alt="image-20220314112843223"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141130116.png" alt="image-20220314113023958"></p>
<h1 id="自督導式學習-Self-supervised-Learning-四-–-GPT的野望"><a href="#自督導式學習-Self-supervised-Learning-四-–-GPT的野望" class="headerlink" title="自督導式學習 (Self-supervised Learning) (四) – GPT的野望"></a>自督導式學習 (Self-supervised Learning) (四) – GPT的野望</h1><p>如下，只不过是数据量特别大</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141135977.png" alt="image-20220314113548845"></p>
<h2 id="How-to-use-GPT"><a href="#How-to-use-GPT" class="headerlink" title="How to use GPT"></a>How to use GPT</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141142869.png" alt="image-20220314114228746"></p>
<h2 id="Few-shot-learning-no-gradient-descent-“In-context”-Learning"><a href="#Few-shot-learning-no-gradient-descent-“In-context”-Learning" class="headerlink" title="Few-shot learning (no gradient descent) “In-context” Learning"></a>Few-shot learning (no gradient descent) “In-context” Learning</h2><p>只用很少的资料去训练。效果见仁见智</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141144552.png" alt="image-20220314114438407"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141145793.png" alt="image-20220314114526420"></p>
<h2 id="Beyond-Text"><a href="#Beyond-Text" class="headerlink" title="Beyond  Text"></a>Beyond  Text</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141147297.png" alt="image-20220314114700178"></p>
<h3 id="Image-1"><a href="#Image-1" class="headerlink" title="Image"></a>Image</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141148087.png" alt="image-20220314114801920"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141148727.png" alt="image-20220314114841612"></p>
<h3 id="Speech-1"><a href="#Speech-1" class="headerlink" title="Speech"></a>Speech</h3><p>语音方面暂时没有公认的像GLUE的资料库</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141149764.png" alt="image-20220314114939626"></p>
<p>他自己做了一个</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141150897.png" alt="image-20220314115057788"></p>
<h2 id="Application-of-self-supervised"><a href="#Application-of-self-supervised" class="headerlink" title="Application of self supervised"></a>Application of self supervised</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141153415.png" alt="image-20220314115333201"></p>
<h1 id="自編碼器-Auto-encoder-上-–-基本概念"><a href="#自編碼器-Auto-encoder-上-–-基本概念" class="headerlink" title="自編碼器 (Auto-encoder) (上) – 基本概念"></a>自編碼器 (Auto-encoder) (上) – 基本概念</h1><h2 id="Outline"><a href="#Outline" class="headerlink" title="Outline"></a>Outline</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141342822.png" alt="image-20220314134255650"></p>
<h2 id="review-of-self-supervised-learning-frame-work"><a href="#review-of-self-supervised-learning-frame-work" class="headerlink" title="review of self-supervised learning frame work"></a>review of self-supervised learning frame work</h2><p>学习没有标注资料的任务，在有bert gpt之前，就有了auto-encoder。</p>
<h2 id="auto-encoder-in-image"><a href="#auto-encoder-in-image" class="headerlink" title="auto-encoder in image"></a>auto-encoder in image</h2><h3 id="Dimension-reduction"><a href="#Dimension-reduction" class="headerlink" title="Dimension reduction"></a>Dimension reduction</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141347670.png" alt="image-20220314134751495"></p>
<h3 id="for-more"><a href="#for-more" class="headerlink" title="for more"></a>for more</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141348069.png" alt="image-20220314134822953"></p>
<h2 id="Why-auto-encoder"><a href="#Why-auto-encoder" class="headerlink" title="Why auto-encoder?"></a>Why auto-encoder?</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141355167.png" alt="image-20220314135524915"></p>
<p>并不是3*3的向量都是图片，其形式是有限的，所以可以用更小的维度表示3*3的图片。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141354951.png" alt="image-20220314135442811"></p>
<h2 id="Auto-encoder-is-not-a-new-idea"><a href="#Auto-encoder-is-not-a-new-idea" class="headerlink" title="Auto-encoder is not a new idea"></a>Auto-encoder is not a new idea</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141356898.png" alt="image-20220314135619740"></p>
<h2 id="De-noising-Auto-encoder"><a href="#De-noising-Auto-encoder" class="headerlink" title="De-noising Auto-encoder"></a>De-noising Auto-encoder</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141400008.png" alt="image-20220314140040870"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141403569.png" alt="image-20220314140324449"></p>
<h1 id="自編碼器-Auto-encoder-下-–-領結變聲器與更多應用"><a href="#自編碼器-Auto-encoder-下-–-領結變聲器與更多應用" class="headerlink" title="自編碼器 (Auto-encoder) (下) – 領結變聲器與更多應用"></a>自編碼器 (Auto-encoder) (下) – 領結變聲器與更多應用</h1><h2 id="Feature-Disentangle"><a href="#Feature-Disentangle" class="headerlink" title="Feature Disentangle"></a>Feature Disentangle</h2><p>分解中间向量，理解其信息</p>
<h3 id="Representation-includes-information-of-different-aspects"><a href="#Representation-includes-information-of-different-aspects" class="headerlink" title="Representation includes information of different aspects"></a>Representation includes information of different aspects</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141405093.png" alt="image-20220314140525936"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141406091.png" alt="image-20220314140612916"></p>
<h2 id="Application-voice-conversion"><a href="#Application-voice-conversion" class="headerlink" title="Application: voice conversion"></a>Application: voice conversion</h2><p>不需要资料库中两个人说一样的话。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141410469.png" alt="image-20220314141012317"></p>
<h2 id="discrete-representation"><a href="#discrete-representation" class="headerlink" title="discrete representation"></a>discrete representation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141414058.png" alt="image-20220314141405868"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141417025.png" alt="image-20220314141736842"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141418141.png" alt="image-20220314141833087"></p>
<p>固定输出的可能性，不是无限的而是离散的</p>
<h2 id="Text-as-representation"><a href="#Text-as-representation" class="headerlink" title="Text as representation"></a>Text as representation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141421620.png" alt="image-20220314142133471"></p>
<p>强迫encoder train出人话一样的中间向量。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141423309.png" alt="image-20220314142307092"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141424328.png" alt="image-20220314142410154"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141424637.png" alt="image-20220314142442444"></p>
<h2 id="Tree-as-Embedding"><a href="#Tree-as-Embedding" class="headerlink" title="Tree as Embedding"></a>Tree as Embedding</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141425516.png" alt="image-20220314142514373"></p>
<h2 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141426358.png" alt="image-20220314142624201"></p>
<h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141427873.png" alt="image-20220314142742720"></p>
<h2 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141429280.png" alt="image-20220314142932175"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141430974.png" alt="image-20220314143015788"></p>
<p>用来探测异常交易，异常请求，异常病情等</p>
<p>和分类器还是有区别的，因为训练资料大多数只有一类</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141433311.png" alt="image-20220314143326176"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141434235.png" alt="image-20220314143418074"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141434870.png" alt="image-20220314143443674"></p>
<h2 id="For-More"><a href="#For-More" class="headerlink" title="For More"></a>For More</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141435726.png" alt="image-20220314143556606"></p>
<h1 id="來自人類的惡意攻擊-Adversarial-Attack-上-–-基本概念"><a href="#來自人類的惡意攻擊-Adversarial-Attack-上-–-基本概念" class="headerlink" title="來自人類的惡意攻擊 (Adversarial Attack) (上) – 基本概念"></a>來自人類的惡意攻擊 (Adversarial Attack) (上) – 基本概念</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>需要在有人试图欺骗他的情况下正常工作</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141438923.png" alt="image-20220314143801762"></p>
<h2 id="How-to-arrack"><a href="#How-to-arrack" class="headerlink" title="How to arrack"></a>How to arrack</h2><h3 id="Example-of-attack"><a href="#Example-of-attack" class="headerlink" title="Example of attack"></a>Example of attack</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141441623.png" alt="image-20220314144113467"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141443616.png" alt="image-20220314144315367"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141443785.png" alt="image-20220314144325514"></p>
<p>正常的错误应该是这样的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141445644.png" alt="image-20220314144533270"></p>
<h3 id="含恶意的噪音"><a href="#含恶意的噪音" class="headerlink" title="含恶意的噪音"></a>含恶意的噪音</h3><p>尽量让正确的目标概率变小，让目标概率变大，同时尽量让差距小于人类能感知的差异的最小值</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141510206.png" alt="image-20220314151015068"></p>
<h3 id="Non-perceivable"><a href="#Non-perceivable" class="headerlink" title="Non-perceivable"></a>Non-perceivable</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141514554.png" alt="image-20220314151407433"></p>
<h2 id="Attack-Approach"><a href="#Attack-Approach" class="headerlink" title="Attack Approach"></a>Attack Approach</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141525745.png" alt="image-20220314152519619"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141529038.png" alt="image-20220314152905906"></p>
<h1 id="來自人類的惡意攻擊-Adversarial-Attack-下-–-類神經網路能否躲過人類深不見底的惡意？"><a href="#來自人類的惡意攻擊-Adversarial-Attack-下-–-類神經網路能否躲過人類深不見底的惡意？" class="headerlink" title="來自人類的惡意攻擊 (Adversarial Attack) (下) – 類神經網路能否躲過人類深不見底的惡意？"></a>來自人類的惡意攻擊 (Adversarial Attack) (下) – 類神經網路能否躲過人類深不見底的惡意？</h1><h2 id="White-Box-vs-Black-Box"><a href="#White-Box-vs-Black-Box" class="headerlink" title="White Box vs Black Box"></a>White Box vs Black Box</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141532903.png" alt="image-20220314153222740"></p>
<h2 id="Black-Box"><a href="#Black-Box" class="headerlink" title="Black Box"></a>Black Box</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141534392.png" alt="image-20220314153412201"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141540185.png" alt="image-20220314154050031"></p>
<p>不同的数据产生的结果截然不同</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141545777.png" alt="image-20220314154500629"></p>
<h2 id="One-pixel-attack"><a href="#One-pixel-attack" class="headerlink" title="One pixel attack"></a>One pixel attack</h2><p>只改变一点导致结果改变</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141548038.png" alt="image-20220314154808782"></p>
<h2 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141548715.png" alt="image-20220314154841529"></p>
<h2 id="Beyond-Images"><a href="#Beyond-Images" class="headerlink" title="Beyond Images"></a>Beyond Images</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141552567.png" alt="image-20220314155241385"></p>
<h2 id="Attack-in-the-Physical-World"><a href="#Attack-in-the-Physical-World" class="headerlink" title="Attack in the Physical World"></a>Attack in the Physical World</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141556837.png" alt="image-20220314155630581"></p>
<h2 id="Backdoor-in-Model"><a href="#Backdoor-in-Model" class="headerlink" title="Backdoor in Model"></a>Backdoor in Model</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141604162.png" alt="image-20220314160459014"></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>模糊化，让攻击信号被改变</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141609473.png" alt="image-20220314160922185"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141609675.png" alt="image-20220314160910483"></p>
<p>但是如果被知道了使用了这种方法，攻击时也可以加上这个，所以可以加上随机性</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141612937.png" alt="image-20220314161213775"></p>
<h2 id="Proactive-Defense"><a href="#Proactive-Defense" class="headerlink" title="Proactive Defense"></a>Proactive Defense</h2><p>自己攻击自己然后把攻击数据学习进去</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141618546.png" alt="image-20220314161820428"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141621045.png" alt="image-20220314162136755"></p>
<h1 id="機器學習模型的可解釋性-Explainable-ML-上-–-為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？"><a href="#機器學習模型的可解釋性-Explainable-ML-上-–-為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？" class="headerlink" title="機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？"></a>機器學習模型的可解釋性 (Explainable ML) (上) – 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢？</h1><h2 id="Why-we-need-Explainable-ML"><a href="#Why-we-need-Explainable-ML" class="headerlink" title="Why we need Explainable ML?"></a>Why we need Explainable ML?</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141628250.png" alt="image-20220314162821135"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141628765.png" alt="image-20220314162835563"></p>
<h2 id="Interpretable-vs-powerful"><a href="#Interpretable-vs-powerful" class="headerlink" title="Interpretable vs powerful"></a>Interpretable vs powerful</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141630592.png" alt="image-20220314163028426"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141631242.png" alt="image-20220314163111887"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141633544.png" alt="image-20220314163334420"></p>
<h2 id="Goal-of-Explainable-ML"><a href="#Goal-of-Explainable-ML" class="headerlink" title="Goal of Explainable ML"></a>Goal of Explainable ML</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141639423.png" alt="image-20220314163927285"></p>
<p>人们只是需要一个理由去接受 - .- </p>
<h2 id="Explainable-ML"><a href="#Explainable-ML" class="headerlink" title="Explainable ML"></a>Explainable ML</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141641803.png" alt="image-20220314164155673"></p>
<h3 id="Local-Exception"><a href="#Local-Exception" class="headerlink" title="Local Exception"></a>Local Exception</h3><p>改造或删除某部分导致结论错误，那么它就是原因</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141644885.png" alt="image-20220314164414637"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141646771.png" alt="image-20220314164642441"></p>
<p>更改向量的值，计算偏导数，得出是哪个参数更重要</p>
<p>Saliency Map</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141649365.png" alt="image-20220314164936108"></p>
<h3 id="A-test"><a href="#A-test" class="headerlink" title="A test"></a>A test</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141652938.png" alt="image-20220314165245766"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141652541.png" alt="image-20220314165232008"></p>
<p>结果是由于数据错误，，，背景问题</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141654709.png" alt="image-20220314165405405"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141654791.png" alt="image-20220314165415412"></p>
<p>因为介绍文字而判断图片</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141655165.png" alt="image-20220314165519831"></p>
<h3 id="SmoothGrad"><a href="#SmoothGrad" class="headerlink" title="SmoothGrad"></a>SmoothGrad</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141656110.png" alt="image-20220314165641944"></p>
<h3 id="Gradient-Saturation"><a href="#Gradient-Saturation" class="headerlink" title="Gradient Saturation"></a>Gradient Saturation</h3><p>如果在平滑处取导数的话会得出鼻子长度与判读大象无关的结论</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141658849.png" alt="image-20220314165857732"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141659780.png" alt="image-20220314165946718"></p>
<h2 id="How-a-net-work-process-the-input-data"><a href="#How-a-net-work-process-the-input-data" class="headerlink" title="How a net work process the input data"></a>How a net work process the input data</h2><h3 id="为了观察过程压缩中间向量的维度"><a href="#为了观察过程压缩中间向量的维度" class="headerlink" title="为了观察过程压缩中间向量的维度"></a>为了观察过程压缩中间向量的维度</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141701305.png" alt="image-20220314170144183"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141705435.png" alt="image-20220314170511238"></p>
<h3 id="很多问题尚待研究。。"><a href="#很多问题尚待研究。。" class="headerlink" title="很多问题尚待研究。。"></a>很多问题尚待研究。。</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141706839.png" alt="image-20220314170659716"></p>
<h3 id="用探针处理中间向量"><a href="#用探针处理中间向量" class="headerlink" title="用探针处理中间向量"></a>用探针处理中间向量</h3><p>但注意Classifier的正确情况</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141708280.png" alt="image-20220314170851046"></p>
<h3 id="example"><a href="#example" class="headerlink" title="example"></a>example</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141712792.png" alt="image-20220314171208635"></p>
<p>在不同层加探针看语音到底在那里失去了性别信息，或者杂音。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141715485.png" alt="image-20220314171551251"></p>
<h1 id="機器學習模型的可解釋性-Explainable-ML-下-–機器心中的貓長什麼樣子？"><a href="#機器學習模型的可解釋性-Explainable-ML-下-–機器心中的貓長什麼樣子？" class="headerlink" title="機器學習模型的可解釋性 (Explainable ML) (下) –機器心中的貓長什麼樣子？"></a>機器學習模型的可解釋性 (Explainable ML) (下) –機器心中的貓長什麼樣子？</h1><h2 id="What-does-a-filter-detect-（插眼，他在说什么）"><a href="#What-does-a-filter-detect-（插眼，他在说什么）" class="headerlink" title="What does a filter detect?（插眼，他在说什么）"></a>What does a filter detect?（插眼，他在说什么）</h2><p>通过filter观察模型在观察什么</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141754322.png" alt="image-20220314175448144"></p>
<p>图示是某个filter</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141756789.png" alt="image-20220314175637568"></p>
<p>下图是被攻击了，命名看不出来是什么，机器却觉得是0123456789。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141758118.png" alt="image-20220314175821937"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141814729.png" alt="image-20220314181454529"></p>
<p>要得到如下的结果要大量的知识和处理。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141815852.png" alt="image-20220314181543310"></p>
<p>或者通过generator达到目的（插眼，他在说什么）</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141818899.png" alt="image-20220314181845733"></p>
<p>并不是在乎机器真正的注意点，而是将注意点转成人能理解的形式</p>
<h2 id="Outlook"><a href="#Outlook" class="headerlink" title="Outlook"></a>Outlook</h2><p>用简单的linear模型模拟复杂的deep learning模型，再用简单的模型理解复杂的模型</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203141823945.png" alt="image-20220314182334820"></p>
<h1 id="概述領域自適應-Domain-Adaptation"><a href="#概述領域自適應-Domain-Adaptation" class="headerlink" title="概述領域自適應 (Domain Adaptation)"></a>概述領域自適應 (Domain Adaptation)</h1><h2 id="Domain-shift"><a href="#Domain-shift" class="headerlink" title="Domain shift"></a>Domain shift</h2><p>有一些改变就会犯错</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151038867.png" alt="image-20220315103810740"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151043678.png" alt="image-20220315104344563"></p>
<p>需要考虑两种情况</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151046869.png" alt="image-20220315104603745"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151048770.png" alt="image-20220315104805665"></p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151049494.png" alt="image-20220315104903362"></p>
<h2 id="Domain-Adversarial-Training"><a href="#Domain-Adversarial-Training" class="headerlink" title="Domain Adversarial Training"></a>Domain Adversarial Training</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151051102.png" alt="image-20220315105143945"></p>
<p>Domain Classifier用来分辨是黑白的还是彩色的，训练到它分别不出来且loss不再下降</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151111252.png" alt="image-20220315111113121"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151112339.png" alt="image-20220315111225175"></p>
<h2 id="Limitation-插眼"><a href="#Limitation-插眼" class="headerlink" title="Limitation(插眼)"></a>Limitation(插眼)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151116059.png" alt="image-20220315111608905"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151117838.png" alt="image-20220315111724707"></p>
<h2 id="Outlook-1"><a href="#Outlook-1" class="headerlink" title="Outlook"></a>Outlook</h2><p>有两者数据不完全重合的情况</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151118787.png" alt="image-20220315111818652"></p>
<h2 id="More-condition-in-domain-Adaptation"><a href="#More-condition-in-domain-Adaptation" class="headerlink" title="More condition in domain Adaptation"></a>More condition in domain Adaptation</h2><h3 id="little-unlabel"><a href="#little-unlabel" class="headerlink" title="little unlabel"></a>little unlabel</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151120389.png" alt="image-20220315112056270"></p>
<h3 id="Know-nothing"><a href="#Know-nothing" class="headerlink" title="Know nothing"></a>Know nothing</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151121979.png" alt="image-20220315112136861"></p>
<h4 id="Domain-Generation"><a href="#Domain-Generation" class="headerlink" title="Domain Generation"></a>Domain Generation</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203151122277.png" alt="image-20220315112247065"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-一-–-增強式學習跟機器學習一樣都是三個步驟"><a href="#概述增強式學習-Reinforcement-Learning-RL-一-–-增強式學習跟機器學習一樣都是三個步驟" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (一) – 增強式學習跟機器學習一樣都是三個步驟"></a>概述增強式學習 (Reinforcement Learning, RL) (一) – 增強式學習跟機器學習一樣都是三個步驟</h1><h2 id="Supervised-learning-gt-RL"><a href="#Supervised-learning-gt-RL" class="headerlink" title="Supervised learning -&gt; RL"></a>Supervised learning -&gt; RL</h2><p>收集正确答案很困难的时候</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241704421.png" alt="image-20220324170448289"></p>
<h2 id="Outline-1"><a href="#Outline-1" class="headerlink" title="Outline"></a>Outline</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241704171.png" alt="image-20220324170459063"></p>
<h1 id="Mache-learning-≈-looking-for-a-function"><a href="#Mache-learning-≈-looking-for-a-function" class="headerlink" title="Mache learning ≈ looking for a function"></a>Mache learning ≈ looking for a function</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241708673.png" alt="image-20220324170828552"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241710102.png" alt="image-20220324171016982"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241712929.png" alt="image-20220324171238799"></p>
<p>在围棋中只有游戏结束时才能获得reward</p>
<h2 id="Mache-Learning-is-so-simple"><a href="#Mache-Learning-is-so-simple" class="headerlink" title="Mache Learning is so simple"></a>Mache Learning is so simple</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241716360.png" alt="image-20220324171600228"></p>
<h3 id="Step-1-Function-with-Unknown"><a href="#Step-1-Function-with-Unknown" class="headerlink" title="Step 1: Function with Unknown"></a>Step 1: Function with Unknown</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241719016.png" alt="image-20220324171952880"></p>
<h3 id="Step-2-Define-“Loss”"><a href="#Step-2-Define-“Loss”" class="headerlink" title="Step 2: Define “Loss”"></a>Step 2: Define “Loss”</h3><p>reward 是一次的 return是总和</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241724187.png" alt="image-20220324172437043"></p>
<h3 id="Step-3-Optimization"><a href="#Step-3-Optimization" class="headerlink" title="Step 3: Optimization"></a>Step 3: Optimization</h3><p>环境和reward有随机性,相比gan，env和reward它们不是神经网络，这两者的随机性是rn很重要的特性</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241731122.png" alt="image-20220324173149984"></p>
<h2 id="How-to-control-your-actor"><a href="#How-to-control-your-actor" class="headerlink" title="How to control your actor"></a>How to control your actor</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241747874.png" alt="image-20220324174707771"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241748455.png" alt="image-20220324174814337"></p>
<p>这其中还可以区分程度</p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-二-–-Policy-Gradient-與修課心情"><a href="#概述增強式學習-Reinforcement-Learning-RL-二-–-Policy-Gradient-與修課心情" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (二) – Policy Gradient 與修課心情"></a>概述增強式學習 (Reinforcement Learning, RL) (二) – Policy Gradient 與修課心情</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241832203.png" alt="image-20220324183243087"></p>
<h2 id="version0"><a href="#version0" class="headerlink" title="version0"></a>version0</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241832432.png" alt="image-20220324183257305"></p>
<p>但是这样是短视的，行动会影响后面的很多reward，还有要先失去一些分数才能获得更多的分数的情况。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241836897.png" alt="image-20220324183659769"></p>
<h2 id="version-1-Cumulated-reward"><a href="#version-1-Cumulated-reward" class="headerlink" title="version 1 Cumulated reward"></a>version 1 Cumulated reward</h2><p>缺点在于如果很长的话，第一个有可能不至于影响到最后一个</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241838997.png" alt="image-20220324183844901"></p>
<h2 id="version-2"><a href="#version-2" class="headerlink" title="version 2"></a>version 2</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241842182.png" alt="image-20220324184203073"></p>
<h2 id="version-3"><a href="#version-3" class="headerlink" title="version 3"></a>version 3</h2><p>做一下标准化，因为好和坏是相对的，有可能在这一把得10分很高了，下一把10分很低。当全是正的时，差一些的就是坏的。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241848169.png" alt="image-20220324184809057"></p>
<h2 id="Policy-Gradient"><a href="#Policy-Gradient" class="headerlink" title="Policy Gradient"></a>Policy Gradient</h2><h3 id="on-policy"><a href="#on-policy" class="headerlink" title="on-policy"></a>on-policy</h3><p>收集资料在for循环里</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241851523.png" alt="image-20220324185137430"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241852874.png" alt="image-20220324185218772"></p>
<p>原因：</p>
<p>围棋中，同样的行为对不同预判能力的玩家来说是不一样好的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241857743.png" alt="image-20220324185724629"></p>
<h3 id="off-policy"><a href="#off-policy" class="headerlink" title="off policy"></a>off policy</h3><p>用一些办法使其可以收集;上几步的资料</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241900132.png" alt="image-20220324190004012"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241901280.png" alt="image-20220324190151089"></p>
<h2 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h2><p>有些action没被执行过就不知道到底好不好，所以想让它尽可能的大一点。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203241903671.png" alt="image-20220324190349538"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-四-回饋非常罕見的時候怎麼辦？機器的望梅止渴"><a href="#概述增強式學習-Reinforcement-Learning-RL-四-回饋非常罕見的時候怎麼辦？機器的望梅止渴" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (四) - 回饋非常罕見的時候怎麼辦？機器的望梅止渴"></a>概述增強式學習 (Reinforcement Learning, RL) (四) - 回饋非常罕見的時候怎麼辦？機器的望梅止渴</h1><h2 id="Sparse-Reward"><a href="#Sparse-Reward" class="headerlink" title="Sparse Reward"></a>Sparse Reward</h2><p>如果reward好多都是零只有一两个极大或其他类似情况应该怎么办？比如让机器栓螺丝</p>
<p>所以需要定义一些额外的reward 这就叫reward shaping</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251435534.png" alt="image-20220325143505402"></p>
<h2 id="Examples-of-Reward-Shaping"><a href="#Examples-of-Reward-Shaping" class="headerlink" title="Examples of Reward Shaping"></a>Examples of Reward Shaping</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251444112.png" alt="image-20220325144419946"></p>
<h1 id="概述增強式學習-Reinforcement-Learning-RL-五-如何從示範中學習？逆向增強式學習-Inverse-RL"><a href="#概述增強式學習-Reinforcement-Learning-RL-五-如何從示範中學習？逆向增強式學習-Inverse-RL" class="headerlink" title="概述增強式學習 (Reinforcement Learning, RL) (五) - 如何從示範中學習？逆向增強式學習 (Inverse RL)"></a>概述增強式學習 (Reinforcement Learning, RL) (五) - 如何從示範中學習？逆向增強式學習 (Inverse RL)</h1><p>有的时候就没有reward，</p>
<h1 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251456210.png" alt="image-20220325145629061"></p>
<h2 id="Limitation-Learning"><a href="#Limitation-Learning" class="headerlink" title="Limitation Learning"></a>Limitation Learning</h2><p>引入人类行为资料</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251501455.png" alt="image-20220325150105295"></p>
<h2 id="Isn’t-it-Supervised-Learning-？"><a href="#Isn’t-it-Supervised-Learning-？" class="headerlink" title="Isn’t it Supervised Learning ？"></a>Isn’t it Supervised Learning ？</h2><p>并不是，因为有些事是人类不会做的，但是是机器需要考虑的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251508011.png" alt="image-20220325150839883"></p>
<h2 id="More-problem"><a href="#More-problem" class="headerlink" title="More problem"></a>More problem</h2><p>可能会学一些坏习惯。。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251511665.png" alt="image-20220325151142335"></p>
<h2 id="Inverse-Reinforcement-Learning"><a href="#Inverse-Reinforcement-Learning" class="headerlink" title="Inverse Reinforcement Learning"></a>Inverse Reinforcement Learning</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251517890.png" alt="image-20220325151713780"></p>
<h2 id="Framework-of-IRL"><a href="#Framework-of-IRL" class="headerlink" title="Framework of IRL"></a>Framework of IRL</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251527503.png" alt="image-20220325152712378"></p>
<h1 id="機器終身學習-Life-Long-Learning-LL-一-為什麼今日的人工智慧無法成為天網？災難性遺忘-Catastrophic-Forgetting"><a href="#機器終身學習-Life-Long-Learning-LL-一-為什麼今日的人工智慧無法成為天網？災難性遺忘-Catastrophic-Forgetting" class="headerlink" title="機器終身學習 (Life Long Learning, LL) (一) - 為什麼今日的人工智慧無法成為天網？災難性遺忘(Catastrophic Forgetting)"></a>機器終身學習 (Life Long Learning, LL) (一) - 為什麼今日的人工智慧無法成為天網？災難性遺忘(Catastrophic Forgetting)</h1><h3 id="LLL"><a href="#LLL" class="headerlink" title="LLL"></a>LLL</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251531491.png" alt="image-20220325153108319"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203251536194.png" alt="image-20220325153641075"></p>
<h2 id="模型会遗忘"><a href="#模型会遗忘" class="headerlink" title="模型会遗忘"></a>模型会遗忘</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281347107.png" alt="image-20220328134715016"></p>
<p>但其实是可以同时学到任务一任务二的。。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281347005.png" alt="image-20220328134740922"></p>
<h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281352687.png" alt="image-20220328135201610"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281356046.png" alt="image-20220328135624974"></p>
<h2 id="同时训练好多任务缺陷明显，而且一点都不像终身学习"><a href="#同时训练好多任务缺陷明显，而且一点都不像终身学习" class="headerlink" title="同时训练好多任务缺陷明显，而且一点都不像终身学习"></a>同时训练好多任务缺陷明显，而且一点都不像终身学习</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281400020.png" alt="image-20220328140029927"></p>
<h2 id="为每一个任务储存模型缺点依然明显"><a href="#为每一个任务储存模型缺点依然明显" class="headerlink" title="为每一个任务储存模型缺点依然明显"></a>为每一个任务储存模型缺点依然明显</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281403147.png" alt="image-20220328140310068"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281406944.png" alt="image-20220328140640856"></p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281408113.png" alt="image-20220328140852027"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281415267.png" alt="image-20220328141536175"></p>
<h1 id="機器終身學習-Life-Long-Learning-LL-二-災難性遺忘-Catastrophic-Forgetting-的克服之道"><a href="#機器終身學習-Life-Long-Learning-LL-二-災難性遺忘-Catastrophic-Forgetting-的克服之道" class="headerlink" title="機器終身學習 (Life Long Learning, LL) (二) - 災難性遺忘(Catastrophic Forgetting)的克服之道"></a>機器終身學習 (Life Long Learning, LL) (二) - 災難性遺忘(Catastrophic Forgetting)的克服之道</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281417826.png" alt="image-20220328141752746"></p>
<p>第一种方法是比较常见的方法</p>
<h2 id="为什么这种情况会发生？"><a href="#为什么这种情况会发生？" class="headerlink" title="为什么这种情况会发生？"></a>为什么这种情况会发生？</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281422113.png" alt="image-20220328142228026"></p>
<h2 id="Selective-Synaptic-Plasticity"><a href="#Selective-Synaptic-Plasticity" class="headerlink" title="Selective Synaptic Plasticity"></a>Selective Synaptic Plasticity</h2><p>更改损失函数确保尽量少对<strong>重要参数</strong>进行修改：</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281429623.png" alt="image-20220328142900542"></p>
<p>对于参数重要度的参数很重要，小了失去了效果，大了不容易学到新的,它是根据情况算出来的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281431771.png" alt="image-20220328143125690"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281437603.png" alt="image-20220328143717529"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281440882.png" alt="image-20220328144001796"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281447839.png" alt="image-20220328144757763"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281448073.png" alt="image-20220328144828004"></p>
<h2 id="Gradient-Episodic-Memory-GEM"><a href="#Gradient-Episodic-Memory-GEM" class="headerlink" title="Gradient Episodic Memory(GEM)"></a>Gradient Episodic Memory(GEM)</h2><p>但是这个方法需要存少量的以前的资料</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281452218.png" alt="image-20220328145254126"></p>
<h2 id="Addition-Neural-Resource-Allocation"><a href="#Addition-Neural-Resource-Allocation" class="headerlink" title="Addition Neural Resource Allocation"></a>Addition Neural Resource Allocation</h2><h3 id="Progressive-Neural-Networks"><a href="#Progressive-Neural-Networks" class="headerlink" title="Progressive Neural Networks"></a>Progressive Neural Networks</h3><p>没新加一个任务就新加一套参数</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281457758.png" alt="image-20220328145732673"></p>
<h3 id="PackNet"><a href="#PackNet" class="headerlink" title="PackNet"></a>PackNet</h3><p>提前预备出任务需要的参数位置，给后来的任务使用</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281500141.png" alt="image-20220328150025009"></p>
<h3 id="Generating-Data"><a href="#Generating-Data" class="headerlink" title="Generating Data"></a>Generating Data</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281502765.png" alt="image-20220328150202679"></p>
<h2 id="More-scenarios"><a href="#More-scenarios" class="headerlink" title="More scenarios"></a>More scenarios</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281503628.png" alt="image-20220328150332554"></p>
<h2 id="Curriculum-Learning"><a href="#Curriculum-Learning" class="headerlink" title="Curriculum Learning"></a>Curriculum Learning</h2><p>学习的顺序也很重要</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281506747.png" alt="image-20220328150636666"></p>
<h1 id="神經網路壓縮-Network-Compression-一-類神經網路剪枝-Pruning-與大樂透假說-Lottery-Ticket-Hypothesis"><a href="#神經網路壓縮-Network-Compression-一-類神經網路剪枝-Pruning-與大樂透假說-Lottery-Ticket-Hypothesis" class="headerlink" title="神經網路壓縮 (Network Compression) (一) - 類神經網路剪枝 (Pruning) 與大樂透假說 (Lottery Ticket Hypothesis)"></a>神經網路壓縮 (Network Compression) (一) - 類神經網路剪枝 (Pruning) 與大樂透假說 (Lottery Ticket Hypothesis)</h1><h2 id="Need-smaller-model"><a href="#Need-smaller-model" class="headerlink" title="Need smaller model"></a>Need smaller model</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281507130.png" alt="image-20220328150756022"></p>
<p>由于时间差或者隐私问题需要在小型设备上运行。</p>
<h2 id="Outline-2"><a href="#Outline-2" class="headerlink" title="Outline"></a>Outline</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281509784.png" alt="image-20220328150941718"></p>
<h2 id="Network-can-be-pruned-network-pruning"><a href="#Network-can-be-pruned-network-pruning" class="headerlink" title="Network can be pruned(network pruning)"></a>Network can be pruned(network pruning)</h2><p>有些参数是没用或者用处不大的，可以扔了</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281512018.png" alt="image-20220328151209934"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281515911.png" alt="image-20220328151539828"></p>
<p>参数太怪异不利于定义和运算，实践发现虽然weight pruning虽然压缩了weight但是由于运算不规则导致运算没有加速</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281518707.png" alt="image-20220328151807624"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281520198.png" alt="image-20220328152016113"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281521829.png" alt="image-20220328152146743"></p>
<h2 id="为什么不直接训练一个小的network"><a href="#为什么不直接训练一个小的network" class="headerlink" title="为什么不直接训练一个小的network"></a>为什么不直接训练一个小的network</h2><p>小的network很难得到大的network的效果</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281525091.png" alt="image-20220328152531993"></p>
<p>有一个猜想是大的network就像买了更多的彩票，概率更大</p>
<p>如果小network用大network的参数开始训练就可以，所以可能是那些参数就是可以成功训练的参数</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281528959.png" alt="image-20220328152853855"></p>
<p>正 负号对于训练参数很重要</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281533112.png" alt="image-20220328153355025"></p>
<p>但是这种想法就不一定是对的，这人说小模型其实也是可以直接训练出来的，只要epoch多一点</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281535374.png" alt="image-20220328153502282"></p>
<h1 id="神經網路壓縮-Network-Compression-二-從各種不同的面向來壓縮神經網路"><a href="#神經網路壓縮-Network-Compression-二-從各種不同的面向來壓縮神經網路" class="headerlink" title="神經網路壓縮 (Network Compression) (二) - 從各種不同的面向來壓縮神經網路"></a>神經網路壓縮 (Network Compression) (二) - 從各種不同的面向來壓縮神經網路</h1><h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><p>学生以老师的输出为标准答案，为什么不直接训小的？因为小的不好训（插眼）</p>
<p>因为老师可以告诉学生其实小的1还是有点像7和9的</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281543007.png" alt="image-20220328154349925"></p>
<p>老师可以是n重的network</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281544302.png" alt="image-20220328154454222"></p>
<p>需要对老师的softmax进行一定的调整，以防可能小的情况被无视</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281552196.png" alt="image-20220328155208113"></p>
<h2 id="Parameter-Quantization"><a href="#Parameter-Quantization" class="headerlink" title="Parameter Quantization"></a>Parameter Quantization</h2><p>储存一个参数可能用64bits那改小点会不会好点？</p>
<p>或者可以将参数分类，每类一个值，简化存储</p>
<p>或者用哈夫曼编码？</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281558687.png" alt="image-20220328155851581"></p>
<h2 id="Binary-Weights"><a href="#Binary-Weights" class="headerlink" title="Binary Weights"></a>Binary Weights</h2><p>用一个bit存储参数</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281559770.png" alt="image-20220328155945690"></p>
<p>效果似乎还可以：</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281600609.png" alt="image-20220328160023499"></p>
<h2 id="Depthwise-separable-convolution-Architecture-Design"><a href="#Depthwise-separable-convolution-Architecture-Design" class="headerlink" title="Depthwise separable convolution __Architecture Design"></a>Depthwise separable convolution __Architecture Design</h2><h3 id="Review-Standard-CNN"><a href="#Review-Standard-CNN" class="headerlink" title="Review: Standard CNN"></a>Review: Standard CNN</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281606053.png" alt="image-20220328160639972"></p>
<h3 id="Depthwise-separable-Convolution"><a href="#Depthwise-separable-Convolution" class="headerlink" title="Depthwise separable Convolution"></a>Depthwise separable Convolution</h3><p>有几个channel就有几个filter</p>
<p>Channel之间没有互动，所以有了pointwise的，它限定filter大小为1</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281615768.png" alt="image-20220328161511681"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281616476.png" alt="image-20220328161657389"></p>
<p>（插眼）</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281620185.png" alt="image-20220328162041103"></p>
<h2 id="Low-rank-approximation"><a href="#Low-rank-approximation" class="headerlink" title="Low rank approximation"></a>Low rank approximation</h2><p>用矩阵乘法减少参数规模</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281624026.png" alt="image-20220328162440961"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281627610.png" alt="image-20220328162754516"></p>
<h3 id="To-learning-more"><a href="#To-learning-more" class="headerlink" title="To learning more"></a>To learning more</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281628956.png" alt="image-20220328162812895"></p>
<h2 id="Dynamic-Computation"><a href="#Dynamic-Computation" class="headerlink" title="Dynamic Computation"></a>Dynamic Computation</h2><p>根据需要自由的调整运算量，（同一模型应用到不同的硬件上，同一硬件的不同状态上）</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281630007.png" alt="image-20220328163037924"></p>
<h3 id="Dynamic-Depth"><a href="#Dynamic-Depth" class="headerlink" title="Dynamic Depth"></a>Dynamic Depth</h3><p>根据情况停止于不同的深度</p>
<p>只要在训练时考虑各层输出就可以了，但是效果一般还有更好的。</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281633533.png" alt="image-20220328163344459"></p>
<h3 id="Dynamic-Width"><a href="#Dynamic-Width" class="headerlink" title="Dynamic Width"></a>Dynamic Width</h3><p>根据需要选择宽度</p>
<p>但是其实也有问题，可以根据需要看引用的论文</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281634666.png" alt="image-20220328163450581"></p>
<h3 id="Computation-based-on-Sample-Difficulty"><a href="#Computation-based-on-Sample-Difficulty" class="headerlink" title="Computation based on Sample Difficulty"></a>Computation based on Sample Difficulty</h3><p>根据实际问题的困难程度来选择要应用的模型深度 </p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281637553.png" alt="image-20220328163708467"></p>
<h2 id="Concluding-Remarks"><a href="#Concluding-Remarks" class="headerlink" title="Concluding Remarks"></a>Concluding Remarks</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281638583.png" alt="image-20220328163851522"></p>
<h1 id="元學習-Meta-Learning-一-元學習跟機器學習一樣也是三個步驟"><a href="#元學習-Meta-Learning-一-元學習跟機器學習一樣也是三個步驟" class="headerlink" title="元學習 Meta Learning (一) - 元學習跟機器學習一樣也是三個步驟"></a>元學習 Meta Learning (一) - 元學習跟機器學習一樣也是三個步驟</h1><p>学习如何学习</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281654075.png" alt="image-20220328165427008"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281700477.png" alt="image-20220328170015356"></p>
<h2 id="review-of-machine-learning"><a href="#review-of-machine-learning" class="headerlink" title="review of machine learning"></a>review of machine learning</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281701080.png" alt="image-20220328170158993"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281702412.png" alt="image-20220328170251327"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281703842.png" alt="image-20220328170321764"></p>
<h2 id="introduction-of-meta-learning"><a href="#introduction-of-meta-learning" class="headerlink" title="introduction of meta learning"></a>introduction of meta learning</h2><h2 id="What-is-Meta-Learning"><a href="#What-is-Meta-Learning" class="headerlink" title="What is Meta Learning?"></a>What is Meta Learning?</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281705185.png" alt="image-20220328170555103"></p>
<p>用机器学习学习的方法</p>
<h2 id="Meta-Learning-Step-1"><a href="#Meta-Learning-Step-1" class="headerlink" title="Meta Learning Step 1"></a>Meta Learning Step 1</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281708732.png" alt="image-20220328170825653"></p>
<h2 id="Meta-learning-step-2-插眼，跟丢了"><a href="#Meta-learning-step-2-插眼，跟丢了" class="headerlink" title="Meta learning step 2(插眼，跟丢了)"></a>Meta learning step 2(插眼，跟丢了)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281710157.png" alt="image-20220328171027065"></p>
<p>分别在训练集和测试集训练</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281713059.png" alt="image-20220328171303974"></p>
<p>在很多任务上进行训练</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281715838.png" alt="image-20220328171550749"></p>
<p>meta learning用测试资计算loss</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281718025.png" alt="image-20220328171801876"></p>
<h2 id="Meta-learning-step-3"><a href="#Meta-learning-step-3" class="headerlink" title="Meta learning step 3"></a>Meta learning step 3</h2><p>如果gradient descent没办法算？</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281720514.png" alt="image-20220328172006437"> </p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281721024.png" alt="image-20220328172147926"></p>
<p>few shot learning不是meta learning</p>
<h2 id="ML-vs-Meta"><a href="#ML-vs-Meta" class="headerlink" title="ML vs Meta"></a>ML vs Meta</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281725934.png" alt="image-20220328172508853"></p>
<h3 id="Training-Data"><a href="#Training-Data" class="headerlink" title="Training Data"></a>Training Data</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281726785.png" alt="image-20220328172603692"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281727297.png" alt="image-20220328172712197"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281729076.png" alt="image-20220328172950986"></p>
<h3 id="Loss-1"><a href="#Loss-1" class="headerlink" title="Loss"></a>Loss</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281730873.png" alt="image-20220328173054796"></p>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281732443.png" alt="image-20220328173249349"></p>
<h3 id="共通之处"><a href="#共通之处" class="headerlink" title="共通之处"></a>共通之处</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281733890.png" alt="image-20220328173349819"></p>
<p>Meta meta meta meat …. leaning 学习如何去学习如何学习如何学习</p>
<h1 id="元學習-Meta-Learning-二-萬物皆可-Meta"><a href="#元學習-Meta-Learning-二-萬物皆可-Meta" class="headerlink" title="元學習 Meta Learning (二) - 萬物皆可 Meta"></a>元學習 Meta Learning (二) - 萬物皆可 Meta</h1><h2 id="Review-Gradient-Descent"><a href="#Review-Gradient-Descent" class="headerlink" title="Review: Gradient Descent"></a>Review: Gradient Descent</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281742066.png" alt="image-20220328174242980"></p>
<h2 id="Learning-to-initialize"><a href="#Learning-to-initialize" class="headerlink" title="Learning to initialize"></a>Learning to initialize</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281743464.png" alt="image-20220328174308374"></p>
<h3 id="How-to-train-you-Dragon-MAML"><a href="#How-to-train-you-Dragon-MAML" class="headerlink" title="How to train you Dragon MAML"></a>How to train you <del>Dragon</del> MAML</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281747862.png" alt="image-20220328174702768"></p>
<h2 id="Maml-vs-pretraining"><a href="#Maml-vs-pretraining" class="headerlink" title="Maml vs pretraining"></a>Maml vs pretraining</h2><p> domain adaptation 是个啥？（插眼）</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281750111.png" alt="image-20220328175020986"></p>
<h3 id="More"><a href="#More" class="headerlink" title="More"></a>More</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281749342.png" alt="image-20220328174902269"></p>
<h2 id="Maml-is-good-because。。。"><a href="#Maml-is-good-because。。。" class="headerlink" title="Maml is good because。。。"></a>Maml is good because。。。</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281751958.png" alt="image-20220328175152866"></p>
<h3 id="More-1"><a href="#More-1" class="headerlink" title="More"></a>More</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281753879.png" alt="image-20220328175310815"></p>
<h2 id="Learn-to-get-a-better-Optimizer"><a href="#Learn-to-get-a-better-Optimizer" class="headerlink" title="Learn to get a better Optimizer"></a>Learn to get a better Optimizer</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281754018.png" alt="image-20220328175407919"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281754836.png" alt="image-20220328175422752"></p>
<h2 id="Network-Architecture-Search-NAS"><a href="#Network-Architecture-Search-NAS" class="headerlink" title="Network Architecture Search (NAS)"></a>Network Architecture Search (NAS)</h2><p>学习模型的架构</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281757667.png" alt="image-20220328175745582"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281758513.png" alt="image-20220328175819434"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281800827.png" alt="image-20220328180023736"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281800052.png" alt="image-20220328180041964"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281801336.png" alt="image-20220328180117256"></p>
<h2 id="Learn-about-Data-Augmentation"><a href="#Learn-about-Data-Augmentation" class="headerlink" title="Learn about Data Augmentation"></a>Learn about Data Augmentation</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281802367.png" alt="image-20220328180204271"> </p>
<h2 id="Sample-Reweighting"><a href="#Sample-Reweighting" class="headerlink" title="Sample Reweighting"></a>Sample Reweighting</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281803971.png" alt="image-20220328180324890"></p>
<h2 id="Beyond-Gradient-Descent"><a href="#Beyond-Gradient-Descent" class="headerlink" title="Beyond Gradient Descent"></a>Beyond Gradient Descent</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281804643.png" alt="image-20220328180419562"></p>
<h2 id="Until-now-…"><a href="#Until-now-…" class="headerlink" title="Until now …"></a>Until now …</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281806017.png" alt="image-20220328180602923"></p>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><h3 id="Few-shot-image-classification"><a href="#Few-shot-image-classification" class="headerlink" title="Few-shot image classification"></a>Few-shot image classification</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281807794.png" alt="image-20220328180754705"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281808353.png" alt="image-20220328180820253"></p>
<p>可以根据这个数据集制造出自己需要的数据集</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281811140.png" alt="image-20220328181140060"></p>
<h3 id="more-than-omniglot"><a href="#more-than-omniglot" class="headerlink" title="more than omniglot"></a>more than omniglot</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281812016.png" alt="image-20220328181213915"></p>
<h1 id="課程結語-最後的業配並改編《為學一首示子姪》作結"><a href="#課程結語-最後的業配並改編《為學一首示子姪》作結" class="headerlink" title="課程結語 - 最後的業配並改編《為學一首示子姪》作結"></a>課程結語 - 最後的業配並改編《為學一首示子姪》作結</h1><h2 id="What-do-we-learn"><a href="#What-do-we-learn" class="headerlink" title="What do we learn"></a>What do we learn</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281844280.png" alt="image-20220328184420187"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281845594.png" alt="image-20220328184549520"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281847986.png" alt="image-20220328184759889"></p>
<p>This is a long journey,It’s just the beginning not the end.</p>
<h2 id="What-to-Learn-Next"><a href="#What-to-Learn-Next" class="headerlink" title="What to Learn Next"></a>What to Learn Next</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281851699.png" alt="image-20220328185146622"></p>
<h1 id="爲學一-首示子侄"><a href="#爲學一-首示子侄" class="headerlink" title="爲學一 首示子侄"></a>爲學一 首示子侄</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281856990.png" alt="image-20220328185652915"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203281858304.png" alt="image-20220328185835224"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/uncategorized/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/uncategorized/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 1970-01-01 08:00:00" itemprop="dateCreated datePublished" datetime="1970-01-01T08:00:00+08:00">1970-01-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-22 10:39:23" itemprop="dateModified" datetime="2022-03-22T10:39:23+08:00">2022-03-22</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">冀ICP备2021011397号-1 </a>
  </div>

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Juggler</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  





  




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"LoveinSun","repo":"blog-comment","client_id":"40e1002206dc11748978","client_secret":"027043262cdf608cfa6b1c20173bc245b1cff702","admin_user":"LoveinSun","distraction_free_mode":true,"proxy":"https://proxy.juggler.fun:9013/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"c853ec00cc9d13bc22336b7d45d1416e"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
