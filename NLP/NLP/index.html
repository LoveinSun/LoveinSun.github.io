<!DOCTYPE html>
<html  lang="en" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>NLP | JugglerDancing</title>
    <meta name="description" content="[toc] Abbreviation   - -    [ToL] To learn   [ToLM] To learn more   [ToLO] To learn optionally   (0501) 05 min 01s   (h0501) 1 hour 05 min 01s   (hh0501) 2 hour 05 min 01s   Lecture 1 - Introduction a">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP">
<meta property="og:url" content="http://juggler.fun/NLP/NLP/index.html">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="[toc] Abbreviation   - -    [ToL] To learn   [ToLM] To learn more   [ToLO] To learn optionally   (0501) 05 min 01s   (h0501) 1 hour 05 min 01s   (hh0501) 2 hour 05 min 01s   Lecture 1 - Introduction a">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214151948950.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135823259.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135951707.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140036077.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140209594.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141232602.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141455212.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214143920015.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214142712551.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152314870.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152611205.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214153736035.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214160400315.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214162201460.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214165957190.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214171624671.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214172338354.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173136681.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173907221.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214174416350.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214175746085.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214184234513.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191638029.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214185926393.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190032048.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190306082.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191531863.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192319871.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192526698.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193151609.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193417520.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215112833279.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113433454.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113255573.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115109857.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115507912.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215120119537.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145351805.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145612746.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215151328471.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152039987.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152912089.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155446438.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155924838.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215160252254.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163226892.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163439157.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163821573.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215164213166.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165030760.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165444250.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165801145.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170003800.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170303720.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215171511327.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215172606079.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215173841609.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215175916431.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180234046.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180544369.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180703045.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215181359982.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182714531.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182932684.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215183327050.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184016985.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184453079.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185618924.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185707615.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185920518.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190108626.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190413343.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190718037.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190841180.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215191735246.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215192255066.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216103904942.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216105731982.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110248289.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110444328.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110620895.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216111222942.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112005817.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112357329.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112814935.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113456552.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113810612.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216114843011.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216115442761.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120043119.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120154220.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120331039.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120515954.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120602654.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120728010.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120836593.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121352667.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121537213.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121801767.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121845504.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216142509947.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143131901.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143953637.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216145201781.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150058982.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150827060.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216152638415.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216153938352.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216154743629.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216155851923.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216160937711.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161044182.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161822091.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161859032.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162108945.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162654834.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163345111.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163610037.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163703962.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163928786.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165707869.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165937488.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216170053324.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216173442920.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174203323.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174430719.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174747222.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216175744427.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184249889.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184542395.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113153381.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113459930.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217114733959.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217115247771.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120240889.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120619459.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185604333.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185720186.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185116405.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185521157.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185909509.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190102912.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190217303.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190523039.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190908268.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190957705.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191310743.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191749317.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224134741859.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224135937734.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145251761.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145105071.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145804570.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145922233.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151624946.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151950866.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152730308.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152938046.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153716173.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153928012.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154243901.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154759716.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241654601.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241652887.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241703566.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241704798.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241712192.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241714640.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241723663.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241725878.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241727692.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241729302.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241741555.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241752253.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241753477.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241801824.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241808087.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241814453.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241815904.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818432.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818897.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241821498.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241824459.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241829033.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241836707.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241838035.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241840230.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241851401.png">
<meta property="og:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241855709.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251049797.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241912138.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251053842.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241926002.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251056150.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251057843.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011431487.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011424191.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011433316.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011434716.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011436047.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439775.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439087.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011441769.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011442409.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011445898.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011446786.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011447561.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450298.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450273.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011451093.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011452969.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011458368.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011500149.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011506509.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011511660.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011512124.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011521846.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011535301.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011536542.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011537922.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539222.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539740.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011540129.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542624.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542000.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011544880.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011545691.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011547174.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011557750.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011559304.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011600766.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011603407.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011604213.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605672.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605432.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011606672.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011607851.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011609267.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011614202.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011615331.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011616579.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011617673.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011618324.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011619216.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011621427.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011625743.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011654767.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011656858.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011658422.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011659852.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011700078.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011702656.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011705194.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011712593.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011713580.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011715286.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011717048.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011719341.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011721240.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723580.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723916.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011724568.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011727409.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738690.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738116.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011739666.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011741350.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743065.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743795.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011745334.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011842759.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011843829.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011844092.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011845881.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011846697.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011847112.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011848032.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011849948.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850188.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850940.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011851616.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011852860.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853116.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853483.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011854783.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011855774.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011857080.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021447359.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021451322.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021453717.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021454368.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021455282.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456327.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456444.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456947.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021459690.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021511473.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021515266.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021520528.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021539312.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021546645.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021551343.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021557083.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021600593.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021601735.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021602559.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021605914.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021606666.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021611309.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021612178.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021613249.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021614579.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619700.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619203.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619946.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021620563.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021623948.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021629154.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021630287.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021631372.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635048.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635716.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021637986.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021649670.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021652560.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021653903.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021723936.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021726699.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727605.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727649.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021729763.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733793.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733338.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021735054.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021738604.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021739919.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021743165.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021746116.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021747337.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021749944.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021752214.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021754765.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757296.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757888.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021758503.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021804637.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021807795.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021808462.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021810608.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021811716.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021814810.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815905.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815447.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021818819.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021823462.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021825650.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021828456.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021829477.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021830774.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021831311.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021832124.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021833826.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834994.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834166.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021837032.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021838823.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021839294.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021841791.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021842799.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021844225.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021845853.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847354.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847359.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021848691.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021849200.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021850845.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031042434.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031043574.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031044256.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031046845.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031050696.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031051800.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031056169.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031059574.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031102348.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031108392.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031109573.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031117718.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031123611.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031126322.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031150003.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031151961.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031152782.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031154169.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031158656.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031201539.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031332993.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031341312.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031343962.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346413.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346603.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031347898.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031350084.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031356980.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031357241.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031400358.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031401626.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031403011.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031404517.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031407337.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031408146.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031410797.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413065.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413295.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031414069.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031415636.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031417261.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031419210.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031421004.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031423815.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031424764.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031425391.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031426427.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456172.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456187.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031458027.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031501186.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502616.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502821.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031503577.png">
<meta property="article:published_time" content="2022-03-22T02:41:52.000Z">
<meta property="article:modified_time" content="2022-03-23T03:23:10.559Z">
<meta property="article:author" content="Juggler">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214151948950.png">

    
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
        <link href="//cdn.jsdelivr.net/npm/gitalk@1.4.0/dist/gitalk.min.css" rel="stylesheet">
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.1.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/LoveinSun" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="https://www.gravatar.com/avatar/bf7ae8749e532822e3278817f312ba25?s=128" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">Juggler</h2>
            <h3 id="title" class="hidden xl:block">Juggler is dancing</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Beijing, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="Search" class="inline-block w-full bg-gray-100 lg:bg-white">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="Search" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="Search" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">Home</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">Archives</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-categories" role="menuitem">
                <a href="/categories">
                    <i class="iconfont icon-folder" aria-hidden="true"></i>
                    <span class="menu-title">Categories</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">Tags</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-repository" role="menuitem">
                <a href="/repository">
                    <i class="iconfont icon-project" aria-hidden="true"></i>
                    <span class="menu-title">Repository</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-links" role="menuitem">
                <a href="/links">
                    <i class="iconfont icon-friend" aria-hidden="true"></i>
                    <span class="menu-title">Links</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">About</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/LoveinSun">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont social-icon icon-telegram"></i>
                <span class="menu-title hidden lg:inline">menu.telegram</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont social-icon icon-twitter"></i>
                <span class="menu-title hidden lg:inline">menu.twitter</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            
    
        <h1 class="article-title text-lg" itemprop="name">
            NLP
        </h1>
    



            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/NLP/NLP/" class="article-date">
	  <time datetime="2022-03-22T02:41:52.000Z" itemprop="datePublished">Mar 22</time>
	</a>
</span>

                
    <span class="article-category">
    <i class="iconfont icon-folder"></i>
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </span>


                
    <span class="article-tags">
    <i class="iconfont icon-tag"></i>
    <a class="article-tag-none-link" href="/tags/NLP/" rel="tag">NLP</a>
  </span>


                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/NLP/NLP/#comments" class="article-comment-link">
                        Comments
                    </a>
                </span>
                
    
        <span class="post-wordcount" itemprop="wordCount">Word Count: 2.9k(words)</span>
    
    
        <span class="post-readcount" itemprop="timeRequired">Read Count: 17(minutes)</span>
    


            </p>
        </header>
        <div class="marked-body article-body">
            <p>[toc]</p>
<h1 id="Abbreviation"><a href="#Abbreviation" class="headerlink" title="Abbreviation"></a>Abbreviation</h1><table>
<thead>
<tr>
<th>-</th>
<th>-</th>
</tr>
</thead>
<tbody><tr>
<td>[ToL]</td>
<td>To learn</td>
</tr>
<tr>
<td>[ToLM]</td>
<td>To learn more</td>
</tr>
<tr>
<td>[ToLO]</td>
<td>To learn optionally</td>
</tr>
<tr>
<td>(0501)</td>
<td>05 min 01s</td>
</tr>
<tr>
<td>(h0501)</td>
<td>1 hour 05 min 01s</td>
</tr>
<tr>
<td>(hh0501)</td>
<td>2 hour 05 min 01s</td>
</tr>
</tbody></table>
<h1 id="Lecture-1-Introduction-and-Word-Vectors"><a href="#Lecture-1-Introduction-and-Word-Vectors" class="headerlink" title="Lecture 1 - Introduction and Word Vectors"></a>Lecture 1 - Introduction and Word Vectors</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/rmVRLeJRkl4?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214151948950.png" alt="image-20220214151948950"></p>
<h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><p>Convert one-hot encoding to distributed representitions</p>
<p>Ont hot cant represent the relation between word vectors,it is too big</p>
<h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>Ignore the position of word of context </p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135823259.png" alt="image-20220214135823259" style="zoom: 35%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214135951707.png" alt="image-20220214135951707" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140036077.png" alt="image-20220214140036077" style="zoom:50%;" />

<h3 id="Use-two-vector-in-one-word-centor-word-context-word"><a href="#Use-two-vector-in-one-word-centor-word-context-word" class="headerlink" title="Use two vector in one word: centor word context word."></a>Use two vector in one word: centor word context word.</h3><h3 id="softmax-function"><a href="#softmax-function" class="headerlink" title="softmax function"></a>softmax function</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214140209594.png" alt="image-20220214140209594" style="zoom:50%;" />

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141232602.png" alt="image-20220214141232602"></p>
<h3 id="Train-the-model-gradient-descent"><a href="#Train-the-model-gradient-descent" class="headerlink" title="Train the model: gradient descent"></a>Train the model: gradient descent</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214141455212.png" alt="image-20220214141455212" style="zoom:50%;" />

<p><strong>There is a term to calculate the gradient descent. (39:50-56:40)</strong></p>
<p>result is :<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214143920015.png" alt="image-20220214143920015"></p>
<p><em><strong>ToL</strong></em></p>
<p>Review derivation and the following especially.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214142712551.png" alt="image-20220214142712551"></p>
<h2 id="Show-some-achievement-with-code-5640-h0516"><a href="#Show-some-achievement-with-code-5640-h0516" class="headerlink" title="Show some achievement with code(5640-h0516)"></a>Show some achievement with code(5640-h0516)</h2><ul>
<li>We can do vector addition, subtraction, multiplication and division, etc.</li>
</ul>
<h2 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h2><p><strong>Why are there center word and context word(h0650)</strong></p>
<p>To avoid one vector dot product himself in some situation???? </p>
<p><strong>Even synonyms can be merged into a vector(h1215)</strong></p>
<p>Which is different from lee ,He says synonyms use different.</p>
<h1 id="Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers"><a href="#Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers" class="headerlink" title="Lecture 2 Word Vectors,Word Senses,and Neural Classifiers"></a>Lecture 2 Word Vectors,Word Senses,and Neural Classifiers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/gqaHkPEZAew?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152314870.png" alt="image-20220214152314870"></p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214152611205.png" alt="image-20220214152611205" style="zoom:40%;" />

<h2 id="Bag-models-0245"><a href="#Bag-models-0245" class="headerlink" title="Bag models (0245)"></a>Bag models (0245)</h2><p>The model makes the same predictions at each position.</p>
<h2 id="Gradient-descent-0600"><a href="#Gradient-descent-0600" class="headerlink" title="Gradient descent (0600)"></a>Gradient descent (0600)</h2><p>Not usually use because of the big calculation.</p>
<p>step size: not too big nor too small</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214153736035.png" alt="image-20220214153736035" style="zoom:33%;" />

<h3 id="stochastic-gradient-descent-SGD-TOBELM-0920"><a href="#stochastic-gradient-descent-SGD-TOBELM-0920" class="headerlink" title="stochastic gradient descent SGD  TOBELM (0920)"></a>stochastic gradient descent SGD  TOBELM (0920)</h3><p>Take part of the corpus</p>
<p>billion faster.</p>
<p>Maybe even get better result.</p>
<p>But it is stochastic, either you need sparse matrix update operations to only update certain rows of full embedding matrices U and V, or you need to keep around a hash for vectors.(1344)<em><strong>ToL</strong></em></p>
<h2 id="more-details-of-word2vec-1400"><a href="#more-details-of-word2vec-1400" class="headerlink" title="more details of word2vec(1400)"></a>more details of word2vec(1400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214160400315.png" alt="image-20220214160400315"></p>
<h3 id="SG-use-center-to-predict-context"><a href="#SG-use-center-to-predict-context" class="headerlink" title="SG use center to predict context"></a>SG use center to predict context</h3><h4 id="SGNS-negative-sampling-ToBLO"><a href="#SGNS-negative-sampling-ToBLO" class="headerlink" title="SGNS negative sampling  [ToBLO]"></a>SGNS negative sampling  [ToBLO]</h4><p>use logistic function instead of softmax and take sampling of corpus</p>
<h3 id="CBOW-opposite"><a href="#CBOW-opposite" class="headerlink" title="CBOW opposite."></a>CBOW opposite.</h3><h3 id=""><a href="#" class="headerlink" title=""></a></h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214162201460.png" alt="image-20220214162201460" style="zoom:33%;" />

<h2 id="Why-use-two-vectors-1500"><a href="#Why-use-two-vectors-1500" class="headerlink" title="Why use two vectors(1500)"></a>Why use two vectors(1500)</h2><p>Sometime it will dot product with itself.</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214165957190.png" alt="image-20220214165957190" style="zoom:40%;" />

<p><strong>[ToL]</strong></p>
<p>The first one is positive word and the last is negative word (2800)</p>
<p>negative word is being sampled cause the center word will turn up on other occasions, when it does, there will have other sampling, and it will learn step by step.</p>
<h2 id="Why-not-capture-co-occurrence-counts-directly-2337"><a href="#Why-not-capture-co-occurrence-counts-directly-2337" class="headerlink" title="Why not capture co-occurrence counts directly?(2337)"></a>Why not capture co-occurrence counts directly?(2337)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214171624671.png" alt="image-20220214171624671"></p>
<h2 id="SVD-3230-ToL"><a href="#SVD-3230-ToL" class="headerlink" title="SVD(3230) [ToL]"></a>SVD(3230) [ToL]</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/29846048">https://zhuanlan.zhihu.com/p/29846048</a></p>
<p>use svd to get lower dimensional representations for words</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214172338354.png" alt="image-20220214172338354" style="zoom:33%;" />(3451)</p>
<h2 id="Count-based-vs-direct-prediction"><a href="#Count-based-vs-direct-prediction" class="headerlink" title="Count based vs direct prediction"></a>Count based vs direct prediction</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173136681.png" alt="image-20220214173136681" style="zoom:50%;" />(3900)</p>
<h2 id="Encoing-meaning-components-in-vector-differences-3948"><a href="#Encoing-meaning-components-in-vector-differences-3948" class="headerlink" title="Encoing meaning components in vector differences(3948)"></a>Encoing meaning components in vector differences(3948)</h2><p>This is to make addition subtraction available for word vectors.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214173907221.png" alt="image-20220214173907221"></p>
<h2 id="GloVe-4313"><a href="#GloVe-4313" class="headerlink" title="GloVe (4313)"></a>GloVe (4313)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214174416350.png" alt="image-20220214174416350" style="zoom: 33%;" />

<p>let dot product minus log of the co-occurrence</p>
<h2 id="How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756"><a href="#How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756" class="headerlink" title="How to evaluate word vectors Intrinsic vs. extrinsic(4756)"></a>How to evaluate word vectors Intrinsic vs. extrinsic(4756)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214175746085.png" alt="image-20220214175746085" style="zoom:50%;" />

<h3 id="Analogy-evaluation-and-hyperparameters-intrinsic-5515"><a href="#Analogy-evaluation-and-hyperparameters-intrinsic-5515" class="headerlink" title="Analogy evaluation and hyperparameters (intrinsic)(5515)"></a>Analogy evaluation and hyperparameters (intrinsic)(5515)</h3><h3 id="Word-vector-distances-and-their-correlation-with-human-judgements-5640"><a href="#Word-vector-distances-and-their-correlation-with-human-judgements-5640" class="headerlink" title="Word vector distances and their correlation with human judgements(5640)"></a>Word vector distances and their correlation with human judgements(5640)</h3><h2 id="Data-shows-that-300-dimensional-word-vector-is-good-5536"><a href="#Data-shows-that-300-dimensional-word-vector-is-good-5536" class="headerlink" title="Data shows that 300 dimensional word vector is good(5536)"></a>Data shows that 300 dimensional word vector is good(5536)</h2><h2 id="The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739"><a href="#The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739" class="headerlink" title="The objective function for the GloVe model and What log-bilinear means(5739)"></a>The objective function for the GloVe model and What log-bilinear means(5739)</h2><h2 id="Word-senses-and-word-sense-ambiguity-h0353"><a href="#Word-senses-and-word-sense-ambiguity-h0353" class="headerlink" title="Word senses and word sense ambiguity(h0353)"></a>Word senses and word sense ambiguity(h0353)</h2><p>One word different mean different vector. </p>
<p>then a word can be the sum of them all</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214184234513.png" alt="image-20220214184234513" style="zoom:33%;" />

<p>It will work good but not bad (h1200)</p>
<p>the vector is so sparse that you can separate out different senses  (h1402)</p>
<h1 id="Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning"><a href="#Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning" class="headerlink" title="Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning"></a>Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/X0Jw4kgaFlg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191638029.png" alt="image-20220214191638029"></p>
<h2 id="Need-to-be-learn-again-it-is-not-totally-understanded"><a href="#Need-to-be-learn-again-it-is-not-totally-understanded" class="headerlink" title="Need to be learn again, it is not totally understanded."></a>Need to be learn again, it is not totally understanded.</h2><h2 id="Named-Entity-Recognition-0530"><a href="#Named-Entity-Recognition-0530" class="headerlink" title="Named Entity Recognition(0530)"></a>Named Entity Recognition(0530)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214185926393.png" alt="image-20220214185926393"></p>
<h2 id="Simple-NER-0636"><a href="#Simple-NER-0636" class="headerlink" title="Simple NER (0636)"></a>Simple NER (0636)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190032048.png" alt="image-20220214190032048"></p>
<h3 id="How-the-sample-model-run-0836"><a href="#How-the-sample-model-run-0836" class="headerlink" title="How the sample model run (0836)"></a>How the sample model run (0836)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214190306082.png" alt="image-20220214190306082"></p>
<h2 id="update-equation-1220"><a href="#update-equation-1220" class="headerlink" title="update equation(1220)"></a>update equation(1220)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214191531863.png" alt="image-20220214191531863"></p>
<h2 id="jacobian-1811"><a href="#jacobian-1811" class="headerlink" title="jacobian(1811)"></a>jacobian(1811)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192319871.png" alt="image-20220214192319871"></p>
<h2 id="Chain-Rule-2015"><a href="#Chain-Rule-2015" class="headerlink" title="Chain Rule(2015)"></a>Chain Rule(2015)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214192526698.png" alt="image-20220214192526698" style="zoom:50%;" />

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193151609.png" alt="image-20220214193151609"></p>
<h2 id="do-one-example-step-2650"><a href="#do-one-example-step-2650" class="headerlink" title="do one example step (2650)"></a>do one example step (2650)</h2><h2 id="-1"><a href="#-1" class="headerlink" title=""></a><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220214193417520.png" alt="image-20220214193417520"></h2><p>hadamard product <a href="3200">ToL</a></p>
<h2 id="Reusing-Computation-3402"><a href="#Reusing-Computation-3402" class="headerlink" title="Reusing Computation(3402)"></a>Reusing Computation(3402)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215112833279.png" alt="image-20220215112833279" style="zoom:50%;" />

<h3 id="ds-x2F-dw"><a href="#ds-x2F-dw" class="headerlink" title="ds&#x2F;dw"></a>ds&#x2F;dw</h3><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113433454.png" alt="image-20220215113433454" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215113255573.png" alt="image-20220215113255573" style="zoom:50%;" />

<h2 id="Forward-and-backward-propagation-5000"><a href="#Forward-and-backward-propagation-5000" class="headerlink" title="Forward and backward propagation(5000)"></a>Forward and backward propagation(5000)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115109857.png" alt="image-20220215115109857" style="zoom:50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215115507912.png" alt="image-20220215115507912" style="zoom:50%;" />

<h2 id="An-example-5507"><a href="#An-example-5507" class="headerlink" title="An example(5507)"></a>An example(5507)</h2><p>a &#x3D; x+y</p>
<p>b &#x3D; max(y,z)</p>
<p>f &#x3D; ab</p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215120119537.png" alt="image-20220215120119537" style="zoom:50%;" />

<h2 id="Compute-all-gradients-at-once-h0005"><a href="#Compute-all-gradients-at-once-h0005" class="headerlink" title="Compute all gradients at once (h0005)"></a>Compute all gradients at once (h0005)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145351805.png" alt="image-20220215145351805" style="zoom:50%;" />

<h2 id="Back-prop-in-general-computation-graph-h0800-ToL"><a href="#Back-prop-in-general-computation-graph-h0800-ToL" class="headerlink" title="Back-prop in general computation graph(h0800)[ToL]"></a>Back-prop in general computation graph(h0800)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215145612746.png" alt="image-20220215145612746"></p>
<h2 id="Automatic-Differentiation-h1346"><a href="#Automatic-Differentiation-h1346" class="headerlink" title="Automatic Differentiation(h1346)"></a>Automatic Differentiation(h1346)</h2><p><strong>Many tools can calculate automaticly</strong>.<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215151328471.png" alt="image-20220215151328471"></p>
<h2 id="Manual-Gradient-checking-Numeric-Gradient-h1900"><a href="#Manual-Gradient-checking-Numeric-Gradient-h1900" class="headerlink" title="Manual Gradient checking : Numeric Gradient(h1900)"></a>Manual Gradient checking : Numeric Gradient(h1900)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152039987.png" alt="image-20220215152039987" style="zoom:50%;" />

<h1 id="Lecture-4-Dependency-Parsing"><a href="#Lecture-4-Dependency-Parsing" class="headerlink" title="Lecture 4 Dependency Parsing"></a>Lecture 4 Dependency Parsing</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PSGIodTN3KE?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215152912089.png" alt="image-20220215152912089"></p>
<h2 id="Two-views-of-linguistic-structure"><a href="#Two-views-of-linguistic-structure" class="headerlink" title="Two views of linguistic structure"></a>Two views of linguistic structure</h2><h3 id="Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331"><a href="#Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331" class="headerlink" title="Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)"></a>Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)</h3><p><strong>Phrase structure organizes words into nested constituents</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155446438.png" alt="image-20220215155446438"></p>
<h3 id="Dependency-structure-1449"><a href="#Dependency-structure-1449" class="headerlink" title="Dependency structure(1449)"></a>Dependency structure(1449)</h3><p><strong>Dependency structure shows which words depend on (modify, attach to,or are arguments of)</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215155924838.png" alt="image-20220215155924838"></p>
<h2 id="Why-do-we-need-sentence-structure-2205"><a href="#Why-do-we-need-sentence-structure-2205" class="headerlink" title="Why do  we need sentence structure?(2205)"></a>Why do  we need sentence structure?(2205)</h2><p><strong>Can not express meaning by just one word</strong>.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215160252254.png" alt="image-20220215160252254"></p>
<h2 id="Prepositional-phrase-attachment-ambiguity-2422"><a href="#Prepositional-phrase-attachment-ambiguity-2422" class="headerlink" title="Prepositional phrase attachment ambiguity.(2422)"></a>Prepositional phrase attachment ambiguity.(2422)</h2><p>There is some sentence to show it:</p>
<h3 id="San-Jose-cops-kill-man-with-knife"><a href="#San-Jose-cops-kill-man-with-knife" class="headerlink" title="San Jose cops kill man with knife"></a>San Jose cops kill man with knife</h3><p><strong>Scientists count whales from space</strong></p>
<p><strong>The board approved [its acquisition] [by Royal Trustco Ltd.] [of Toronto] [for $27 a share] [at its monthly meeting].</strong></p>
<h2 id="Coordination-scope-ambiguity-3614"><a href="#Coordination-scope-ambiguity-3614" class="headerlink" title="Coordination scope ambiguity(3614)"></a>Coordination scope ambiguity(3614)</h2><p>**Shuttle veteran and longtime NASA executive Fred Gregory appointed to board **</p>
<p><strong>Doctor: No heart, cognitive issues</strong></p>
<h2 id="Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755"><a href="#Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755" class="headerlink" title="Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)"></a>Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)</h2><p><strong>Students get [first hand job] experience</strong> <strong>Students get first [hand job] experience</strong></p>
<h2 id="Verb-Phrase-VP-attachment-ambiguity-4404"><a href="#Verb-Phrase-VP-attachment-ambiguity-4404" class="headerlink" title="Verb Phrase(VP) attachment ambiguity(4404)"></a>Verb Phrase(VP) attachment ambiguity(4404)</h2><p>Mutilated body washes up on Rio beach to be used for Olympics beach volleyball.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163226892.png" alt="image-20220215163226892"></p>
<h2 id="Dependency-Grammar-and-Dependency-structure-4355"><a href="#Dependency-Grammar-and-Dependency-structure-4355" class="headerlink" title="Dependency Grammar and Dependency structure(4355)"></a>Dependency Grammar and Dependency structure(4355)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163439157.png" alt="image-20220215163439157"></p>
<h3 id="Will-add-a-fake-ROOT-for-handy"><a href="#Will-add-a-fake-ROOT-for-handy" class="headerlink" title="Will add a fake ROOT for handy"></a>Will add a fake ROOT for handy</h3><h2 id="Dependency-Grammar-history-4742"><a href="#Dependency-Grammar-history-4742" class="headerlink" title="Dependency Grammar history(4742)"></a>Dependency Grammar history(4742)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215163821573.png" alt="image-20220215163821573"> </p>
<h2 id="The-rise-of-annotated-data-Universal-Dependency-tree-5100"><a href="#The-rise-of-annotated-data-Universal-Dependency-tree-5100" class="headerlink" title="The rise of annotated data Universal Dependency tree(5100)"></a>The rise of annotated data Universal Dependency tree(5100)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215164213166.png" alt="image-20220215164213166"></p>
<h3 id="Tree-bank-5400"><a href="#Tree-bank-5400" class="headerlink" title="Tree bank(5400)"></a>Tree bank(5400)</h3><p><strong>Its too slow to write a grammar by hand but its still worth,cause it can used in another place but not only nlp</strong> .</p>
<h2 id="how-to-build-parser-with-dependency-5738"><a href="#how-to-build-parser-with-dependency-5738" class="headerlink" title="how to build parser with dependency(5738)"></a>how to build parser with dependency(5738)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165030760.png" alt="image-20220215165030760"></p>
<h2 id="Dependency-Parsing"><a href="#Dependency-Parsing" class="headerlink" title="Dependency Parsing"></a>Dependency Parsing</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165444250.png" alt="image-20220215165444250"></p>
<h3 id="Projectivity-h0416"><a href="#Projectivity-h0416" class="headerlink" title="Projectivity(h0416)"></a>Projectivity(h0416)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215165801145.png" alt="image-20220215165801145"></p>
<h2 id="Methods-of-Dependency-Parsing-h0521"><a href="#Methods-of-Dependency-Parsing-h0521" class="headerlink" title="Methods of Dependency Parsing(h0521)"></a>Methods of Dependency Parsing(h0521)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170003800.png" alt="image-20220215170003800"></p>
<h2 id="Greedy-transition-based-parsing-h0621"><a href="#Greedy-transition-based-parsing-h0621" class="headerlink" title="Greedy transition-based parsing(h0621)"></a>Greedy transition-based parsing(h0621)</h2><h2 id="Basic-transition-based-dependency-parser-h0808"><a href="#Basic-transition-based-dependency-parser-h0808" class="headerlink" title="Basic transition-based dependency parser (h0808)"></a>Basic transition-based dependency parser (h0808)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215170303720.png" alt="image-20220215170303720"></p>
<p><strong>[root] I ate fish</strong></p>
<p><strong>[root I ate] fish</strong></p>
<p><strong>[root ate] fish</strong></p>
<p><strong>[root ate fish]</strong></p>
<p><strong>[root ate]</strong></p>
<p><strong>[root]</strong></p>
<h2 id="MaltParser-h1351-ToL"><a href="#MaltParser-h1351-ToL" class="headerlink" title="MaltParser(h1351)[ToL]"></a>MaltParser(h1351)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215171511327.png" alt="image-20220215171511327"></p>
<h2 id="Evaluation-of-Dependency-Parsing-h1845-ToL"><a href="#Evaluation-of-Dependency-Parsing-h1845-ToL" class="headerlink" title="Evaluation of Dependency Parsing (h1845)[ToL]"></a>Evaluation of Dependency Parsing (h1845)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215172606079.png" alt="image-20220215172606079"></p>
<h1 id="Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs"><a href="#Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs" class="headerlink" title="Lecture-5 Languages models and Recurrent Neural Networks(RNNs)"></a>Lecture-5 Languages models and Recurrent Neural Networks(RNNs)</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/PLryWeHPcBs?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>



<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215173841609.png" alt="image-20220215173841609"></p>
<h2 id="A-neural-dependency-parser-0624"><a href="#A-neural-dependency-parser-0624" class="headerlink" title="A neural dependency parser(0624)"></a>A neural dependency parser(0624)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215175916431.png" alt="image-20220215175916431"></p>
<h2 id="Distributed-Representations-0945"><a href="#Distributed-Representations-0945" class="headerlink" title="Distributed Representations(0945)"></a>Distributed Representations(0945)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180234046.png" alt="image-20220215180234046##"></p>
<h2 id="Deep-Learning-Classifier-are-non-linear-classifiers-1210"><a href="#Deep-Learning-Classifier-are-non-linear-classifiers-1210" class="headerlink" title="Deep Learning Classifier are non-linear classifiers(1210)"></a>Deep Learning Classifier are non-linear classifiers(1210)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180544369.png" alt="image-20220215180544369"></p>
<p>Deep Learning Classifiers non-linear classifiers:</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215180703045.png" alt="image-20220215180703045"></p>
<h2 id="Simple-feed-forward-neural-network-multi-class-classifier-1621"><a href="#Simple-feed-forward-neural-network-multi-class-classifier-1621" class="headerlink" title="Simple feed-forward neural network multi-class classifier (1621)"></a>Simple feed-forward neural network multi-class classifier (1621)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215181359982.png" alt="image-20220215181359982"></p>
<h2 id="Neural-Dependency-Parser-Model-Architecture-1730"><a href="#Neural-Dependency-Parser-Model-Architecture-1730" class="headerlink" title="Neural Dependency Parser Model Architecture(1730)"></a>Neural Dependency Parser Model Architecture(1730)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182714531.png" alt="image-20220215182714531"></p>
<h2 id="Graph-based-dependency-parsers-2044"><a href="#Graph-based-dependency-parsers-2044" class="headerlink" title="Graph-based dependency parsers (2044)"></a>Graph-based dependency parsers (2044)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215182932684.png" alt="image-20220215182932684"></p>
<h2 id="Regularization-amp-amp-Overfitting-2529"><a href="#Regularization-amp-amp-Overfitting-2529" class="headerlink" title="Regularization &amp;&amp; Overfitting (2529)"></a>Regularization &amp;&amp; Overfitting (2529)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215183327050.png" alt="image-20220215183327050"></p>
<h2 id="Dropout-3100-ToL"><a href="#Dropout-3100-ToL" class="headerlink" title="Dropout (3100)[ToL]"></a>Dropout (3100)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184016985.png" alt="image-20220215184016985"></p>
<h2 id="Vectorization-3333"><a href="#Vectorization-3333" class="headerlink" title="Vectorization(3333)"></a>Vectorization(3333)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215184453079.png" alt="image-20220215184453079"></p>
<h2 id="Non-linearities-4000"><a href="#Non-linearities-4000" class="headerlink" title="Non-linearities (4000)"></a>Non-linearities (4000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185618924.png" alt="image-20220215185618924"></p>
<h2 id="Parameter-Initialization-4357"><a href="#Parameter-Initialization-4357" class="headerlink" title="Parameter Initialization (4357)"></a>Parameter Initialization (4357)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185707615.png" alt="image-20220215185707615"></p>
<h2 id="Optimizers-4617"><a href="#Optimizers-4617" class="headerlink" title="Optimizers(4617)"></a>Optimizers(4617)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215185920518.png" alt="image-20220215185920518"></p>
<h2 id="Learning-Rates-4810"><a href="#Learning-Rates-4810" class="headerlink" title="Learning Rates(4810)"></a>Learning Rates(4810)</h2><p>It can be slow as the learning  go on.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190108626.png" alt="image-20220215190108626"></p>
<h2 id="Language-Modeling-5036"><a href="#Language-Modeling-5036" class="headerlink" title="Language Modeling (5036)"></a>Language Modeling (5036)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190413343.png" alt="image-20220215190413343"></p>
<h2 id="n-gram-Language-Models-5356"><a href="#n-gram-Language-Models-5356" class="headerlink" title="n-gram Language Models(5356)"></a>n-gram Language Models(5356)</h2><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190718037.png" alt="image-20220215190718037" style="zoom: 50%;" />

<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215190841180.png" alt="image-20220215190841180" style="zoom:50%;" />

<h2 id="Sparsity-Problems-5922"><a href="#Sparsity-Problems-5922" class="headerlink" title="Sparsity Problems (5922)"></a>Sparsity Problems (5922)</h2><p><em>Many situation didnt occur so it will be zero</em></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215191735246.png" alt="image-20220215191735246"></p>
<h2 id="Storage-Problems-h0117"><a href="#Storage-Problems-h0117" class="headerlink" title="Storage Problems(h0117)"></a>Storage Problems(h0117)</h2><h2 id="How-to-build-a-neural-language-model-h0609"><a href="#How-to-build-a-neural-language-model-h0609" class="headerlink" title="How to build a neural language model(h0609)"></a>How to build a neural language model(h0609)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220215192255066.png" alt="image-20220215192255066"></p>
<h2 id="A-fixed-window-neural-Language-Model-h1100"><a href="#A-fixed-window-neural-Language-Model-h1100" class="headerlink" title="A fixed-window neural Language Model(h1100)"></a>A fixed-window neural Language Model(h1100)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216103904942.png" alt="image-20220216103904942"></p>
<h2 id="Recurrent-Neural-Network-RNN-h1250"><a href="#Recurrent-Neural-Network-RNN-h1250" class="headerlink" title="Recurrent Neural Network (RNN)(h1250)"></a>Recurrent Neural Network (RNN)(h1250)</h2><p>x1 -&gt; y1</p>
<p>Wx1 x2 -&gt; y1</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216105731982.png" alt="image-20220216105731982"></p>
<h2 id="A-Simple-RNN-Language-Model-h1430"><a href="#A-Simple-RNN-Language-Model-h1430" class="headerlink" title="A Simple RNN Language Model(h1430)"></a>A Simple RNN Language Model(h1430)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110248289.png" alt="image-20220216110248289"></p>
<img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110444328.png" alt="image-20220216110444328" style="zoom: 67%;" />

<h1 id="Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks"><a href="#Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks" class="headerlink" title="Lecture 6 Simple and LSTM Recurrent Neural Networks."></a>Lecture 6 Simple and LSTM Recurrent Neural Networks.</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/0LixFSa7yts?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216110620895.png" alt="image-20220216110620895"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216111222942.png" alt="image-20220216111222942"></p>
<h2 id="The-Simple-RNN-Language-Model-0310"><a href="#The-Simple-RNN-Language-Model-0310" class="headerlink" title="The Simple RNN Language Model (0310)"></a>The Simple RNN Language Model (0310)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112005817.png" alt="image-20220216112005817"></p>
<h2 id="Training-an-RNN-Language-Model-0818"><a href="#Training-an-RNN-Language-Model-0818" class="headerlink" title="Training an RNN Language Model (0818)"></a>Training an RNN Language Model (0818)</h2><p>RNN takes more time.</p>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h3><p>penalize when dont take its advise</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112357329.png" alt="image-20220216112357329"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216112814935.png" alt="image-20220216112814935"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113456552.png" alt="image-20220216113456552"></p>
<p>But how do we get the answer?</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216113810612.png" alt="image-20220216113810612"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216114843011.png" alt="image-20220216114843011"></p>
<h2 id="Evaluating-Language-Models-2447-ToL"><a href="#Evaluating-Language-Models-2447-ToL" class="headerlink" title="Evaluating Language Models (2447)[ToL]"></a>Evaluating Language Models (2447)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216115442761.png" alt="image-20220216115442761"></p>
<h2 id="Language-Model-is-a-system-that-predicts-the-next-word-3130"><a href="#Language-Model-is-a-system-that-predicts-the-next-word-3130" class="headerlink" title="Language Model is a  system that predicts the next word(3130)"></a>Language Model is a  system that predicts the next word(3130)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120043119.png" alt="image-20220216120043119"></p>
<h2 id="Other-use-of-RNN-3229"><a href="#Other-use-of-RNN-3229" class="headerlink" title="Other use of RNN(3229)"></a>Other use of RNN(3229)</h2><h3 id="Tag-for-word"><a href="#Tag-for-word" class="headerlink" title="Tag for word"></a>Tag for word</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120154220.png" alt="image-20220216120154220"></p>
<h3 id="Used-for-classification-3420"><a href="#Used-for-classification-3420" class="headerlink" title="Used for classification(3420)"></a>Used for classification(3420)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120331039.png" alt="image-20220216120331039"></p>
<h3 id="Used-to-Language-encoder-module-3500"><a href="#Used-to-Language-encoder-module-3500" class="headerlink" title="Used to Language encoder module (3500)"></a>Used to Language encoder module (3500)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120515954.png" alt="image-20220216120515954"></p>
<h3 id="Used-to-generate-text-3600"><a href="#Used-to-generate-text-3600" class="headerlink" title="Used to generate text (3600)"></a>Used to generate text (3600)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120602654.png" alt="image-20220216120602654"></p>
<h2 id="Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT"><a href="#Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT" class="headerlink" title="Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]"></a>Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120728010.png" alt="image-20220216120728010"></p>
<p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216120836593.png" alt="image-20220216120836593"></p>
<h3 id="Why-This-is-a-problem-4400"><a href="#Why-This-is-a-problem-4400" class="headerlink" title="Why This is a  problem (4400)"></a>Why This is a  problem (4400)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121352667.png" alt="image-20220216121352667"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121537213.png" alt="image-20220216121537213"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121801767.png" alt="image-20220216121801767"></p>
<p>We can give him a limit.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216121845504.png" alt="image-20220216121845504"></p>
<h2 id="Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL"><a href="#Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL" class="headerlink" title="Long Short Term Memory RNNS(LSTMS)(5000)[ToL]"></a>Long Short Term Memory RNNS(LSTMS)(5000)[ToL]</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216142509947.png" alt="image-20220216142509947"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143131901.png" alt="image-20220216143131901"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216143953637.png" alt="image-20220216143953637"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216145201781.png" alt="image-20220216145201781"></p>
<h2 id="Bidirectional-RNN-h2000"><a href="#Bidirectional-RNN-h2000" class="headerlink" title="Bidirectional RNN (h2000)"></a>Bidirectional RNN (h2000)</h2><p>We need information from the word after</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150058982.png" alt="image-20220216150058982"></p>
<h1 id="Lecture-7-Translation-Seq2Seq-Attention"><a href="#Lecture-7-Translation-Seq2Seq-Attention" class="headerlink" title="Lecture-7 Translation, Seq2Seq, Attention"></a>Lecture-7 Translation, Seq2Seq, Attention</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/wzfWHP6SXxY?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216150827060.png" alt="image-20220216150827060"></p>
<h2 id="Machine-Translation-0245"><a href="#Machine-Translation-0245" class="headerlink" title="Machine Translation(0245)"></a>Machine Translation(0245)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216152638415.png" alt="image-20220216152638415"></p>
<h3 id="What-do-you-need-1200"><a href="#What-do-you-need-1200" class="headerlink" title="What do you need (1200)"></a>What do you need (1200)</h3><p><strong>you need parallel corpus,Then you need alignment</strong></p>
<h2 id="Decoding-for-SMT-1748"><a href="#Decoding-for-SMT-1748" class="headerlink" title="Decoding for SMT(1748)"></a>Decoding for SMT(1748)</h2><p>Try many possible sequences.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216153938352.png" alt="image-20220216153938352"></p>
<h2 id="What-is-Neural-Machine-Translation-NMT-2130"><a href="#What-is-Neural-Machine-Translation-NMT-2130" class="headerlink" title="What is Neural Machine Translation(NMT)(2130)"></a>What is Neural Machine Translation(NMT)(2130)</h2><p>Neural Machine Translation(NMT) is a way to do Machine Translation with a single end-to-end neural net work.</p>
<p>The neural network architecture is called sequence-to-sequence model(aka seq2seq) and it involves RNNs</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216154743629.png" alt="image-20220216154743629"></p>
<h2 id="Seq2seq-is-more-than-MT-2600"><a href="#Seq2seq-is-more-than-MT-2600" class="headerlink" title="Seq2seq is more than MT(2600)"></a>Seq2seq is more than MT(2600)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216155851923.png" alt="image-20220216155851923"></p>
<h2 id="2732-ToL"><a href="#2732-ToL" class="headerlink" title="(2732)[ToL]"></a>(2732)[ToL]</h2><h2 id="Multi-layer-RNNs-3323"><a href="#Multi-layer-RNNs-3323" class="headerlink" title="Multi-layer RNNs(3323)"></a>Multi-layer RNNs(3323)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216160937711.png" alt="image-20220216160937711"></p>
<p>Lower-level basic meaning</p>
<p>Higher-level overall meaning</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161044182.png" alt="image-20220216161044182"></p>
<h2 id="Greedy-decoding-4000"><a href="#Greedy-decoding-4000" class="headerlink" title="Greedy decoding(4000)"></a>Greedy decoding(4000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161822091.png" alt="image-20220216161822091"></p>
<h2 id="Exhaustive-search-decoding-4200"><a href="#Exhaustive-search-decoding-4200" class="headerlink" title="Exhaustive search decoding(4200)"></a>Exhaustive search decoding(4200)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216161859032.png" alt="image-20220216161859032"></p>
<h2 id="beam-search-decoding-4400"><a href="#beam-search-decoding-4400" class="headerlink" title="beam search decoding(4400)"></a>beam search decoding(4400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162108945.png" alt="image-20220216162108945"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216162654834.png" alt="image-20220216162654834"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163345111.png" alt="image-20220216163345111"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163610037.png" alt="image-20220216163610037"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163703962.png" alt="image-20220216163703962"></p>
<h2 id="How-do-we-evaluate-Machine-Translation-5550"><a href="#How-do-we-evaluate-Machine-Translation-5550" class="headerlink" title="How do we evaluate Machine Translation(5550)"></a>How do we evaluate Machine Translation(5550)</h2><h3 id="BLEU"><a href="#BLEU" class="headerlink" title="BLEU"></a>BLEU</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216163928786.png" alt="image-20220216163928786"></p>
<h2 id="NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000"><a href="#NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000" class="headerlink" title="NMT perhaps the biggest success story of NLP Deep Learning(h00000)"></a>NMT perhaps the biggest success story of NLP Deep Learning(h00000)</h2><h2 id="Attention-h1300"><a href="#Attention-h1300" class="headerlink" title="Attention(h1300)"></a>Attention(h1300)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165707869.png" alt="image-20220216165707869"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216165937488.png" alt="image-20220216165937488"></p>
<h1 id="Lecture-8-Final-Projects-Practical-Tips"><a href="#Lecture-8-Final-Projects-Practical-Tips" class="headerlink" title="Lecture 8  Final Projects; Practical Tips"></a>Lecture 8  Final Projects; Practical Tips</h1><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216170053324.png" alt="image-20220216170053324"></p>
<h2 id="Sequence-to-Sequence-with-attention-0235"><a href="#Sequence-to-Sequence-with-attention-0235" class="headerlink" title="Sequence to Sequence with attention(0235)"></a>Sequence to Sequence with attention(0235)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216173442920.png" alt="image-20220216173442920"></p>
<h2 id="Attention-in-equations-0800"><a href="#Attention-in-equations-0800" class="headerlink" title="Attention: in equations(0800)"></a>Attention: in equations(0800)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174203323.png" alt="image-20220216174203323"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174430719.png" alt="image-20220216174430719"></p>
<h2 id="there-are-several-attention-variants-1500"><a href="#there-are-several-attention-variants-1500" class="headerlink" title="there are several attention variants(1500)"></a>there are several attention variants(1500)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216174747222.png" alt="image-20220216174747222"></p>
<h2 id="Attention-is-a-general-Deep-Learning-technique-2240"><a href="#Attention-is-a-general-Deep-Learning-technique-2240" class="headerlink" title="Attention is a general Deep Learning technique(2240)"></a>Attention is a general Deep Learning technique(2240)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216175744427.png" alt="image-20220216175744427"></p>
<h2 id="Final-Project-3000"><a href="#Final-Project-3000" class="headerlink" title="Final Project(3000)"></a>Final Project(3000)</h2><h1 id="Lecture-9-Self-Attention-and-Transformers"><a href="#Lecture-9-Self-Attention-and-Transformers" class="headerlink" title="Lecture-9  Self- Attention and Transformers"></a>Lecture-9  Self- Attention and Transformers</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/ptuGllU5SQQ?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h2 id="Issues-with-recurrent-models-0434"><a href="#Issues-with-recurrent-models-0434" class="headerlink" title="Issues with recurrent models (0434)"></a>Issues with recurrent models (0434)</h2><h3 id="Linear-interaction-distance"><a href="#Linear-interaction-distance" class="headerlink" title="Linear interaction distance"></a>Linear interaction distance</h3><p>Sometimes it is too far too learn from the words.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184249889.png" alt="image-20220216184249889"></p>
<h3 id="Lack-of-parallelizability-0723"><a href="#Lack-of-parallelizability-0723" class="headerlink" title="Lack of parallelizability(0723)"></a>Lack of parallelizability(0723)</h3><p>GPU can count parallelizable but RNN lacks that.</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220216184542395.png" alt="image-20220216184542395"></p>
<h2 id="If-not-recurrence"><a href="#If-not-recurrence" class="headerlink" title="If not recurrence"></a>If not recurrence</h2><h3 id="Word-window-models-aggregate-local-contexts-1031"><a href="#Word-window-models-aggregate-local-contexts-1031" class="headerlink" title="Word window models aggregate local contexts (1031)"></a>Word window models aggregate local contexts (1031)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113153381.png" alt="image-20220217113153381"></p>
<h3 id="Attention-1406"><a href="#Attention-1406" class="headerlink" title="Attention(1406)"></a>Attention(1406)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217113459930.png" alt="image-20220217113459930"></p>
<h2 id="Self-Attention-1638"><a href="#Self-Attention-1638" class="headerlink" title="Self-Attention(1638)"></a>Self-Attention(1638)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217114733959.png" alt="image-20220217114733959"></p>
<h2 id="Self-attention-as-an-nlp-building-block-2222"><a href="#Self-attention-as-an-nlp-building-block-2222" class="headerlink" title="Self-attention as an nlp building block(2222)"></a>Self-attention as an nlp building block(2222)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217115247771.png" alt="image-20220217115247771"></p>
<h2 id="Fix-the-first-self-attention-problem"><a href="#Fix-the-first-self-attention-problem" class="headerlink" title="Fix the first self-attention problem"></a>Fix the first self-attention problem</h2><h3 id="sequence-order-2423"><a href="#sequence-order-2423" class="headerlink" title="sequence order (2423)"></a>sequence order (2423)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120240889.png" alt="image-20220217120240889"></p>
<h4 id="Position-representation-vector-through-sinusoids-2624"><a href="#Position-representation-vector-through-sinusoids-2624" class="headerlink" title="Position representation vector through sinusoids(2624)"></a>Position representation vector through sinusoids(2624)</h4><h5 id="Sinusoidal-position-representations-2730"><a href="#Sinusoidal-position-representations-2730" class="headerlink" title="Sinusoidal position representations(2730)"></a>Sinusoidal position representations(2730)</h5><h5 id="Position-representation-vector-from-scratch-2830"><a href="#Position-representation-vector-from-scratch-2830" class="headerlink" title="Position representation vector from scratch(2830)"></a>Position representation vector from scratch(2830)</h5><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220217120619459.png" alt="image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459image-20220217120619459"></p>
<h3 id="Adding-nonlinearities-in-self-attention-2953"><a href="#Adding-nonlinearities-in-self-attention-2953" class="headerlink" title="Adding nonlinearities in self-attention(2953)"></a>Adding nonlinearities in self-attention(2953)</h3><h2 id="Barriers-and-solutions-for-Self-Attention-as-building-block-2945"><a href="#Barriers-and-solutions-for-Self-Attention-as-building-block-2945" class="headerlink" title="Barriers and solutions for Self-Attention as building block(2945)"></a>Barriers and solutions for Self-Attention as building block(2945)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185604333.png" alt="image-20220221185604333"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185720186.png" alt="image-20220221185720186"></p>
<p>(3040)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185116405.png" alt="image-20220221185116405"></p>
<p>(3428)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185521157.png" alt="image-20220221185521157"></p>
<h2 id="The-transformer-encoder-decoder-3638"><a href="#The-transformer-encoder-decoder-3638" class="headerlink" title="The transformer encoder-decoder(3638)"></a>The transformer encoder-decoder(3638)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221185909509.png" alt="image-20220221185909509"></p>
<p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190102912.png" alt="image-20220221190102912"></p>
<h3 id="key-query-value-4000"><a href="#key-query-value-4000" class="headerlink" title="key query value(4000)"></a>key query value(4000)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190217303.png" alt="image-20220221190217303"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190523039.png" alt="image-20220221190523039"></p>
<h3 id="Multi-headed-attention-4322"><a href="#Multi-headed-attention-4322" class="headerlink" title="Multi-headed attention (4322)"></a>Multi-headed attention (4322)</h3><p>(4450)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190908268.png" alt="image-20220221190908268"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221190957705.png" alt="image-20220221190957705"></p>
<h2 id="Residual-connections-4723"><a href="#Residual-connections-4723" class="headerlink" title="Residual connections(4723)"></a>Residual connections(4723)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191310743.png" alt="image-20220221191310743"></p>
<h2 id="Layer-normalization-5045"><a href="#Layer-normalization-5045" class="headerlink" title="Layer normalization(5045)"></a>Layer normalization(5045)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220221191749317.png" alt="image-20220221191749317"></p>
<h2 id="Scaled-fot-product-5415"><a href="#Scaled-fot-product-5415" class="headerlink" title="Scaled fot product(5415)"></a>Scaled fot product(5415)</h2><h1 id="Lecture-10-Transformers-and-Pretraining"><a href="#Lecture-10-Transformers-and-Pretraining" class="headerlink" title="Lecture 10 - Transformers and Pretraining"></a>Lecture 10 - Transformers and Pretraining</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/j9AcEI98C0o?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224134741859.png" alt="image-20220224134741859"></p>
<h2 id="Word-structure-and-subword-models-0300"><a href="#Word-structure-and-subword-models-0300" class="headerlink" title="Word structure and subword models(0300)"></a>Word structure and subword models(0300)</h2><p>transform transformerify</p>
<p>taaaasty</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224135937734.png" alt="image-20220224135937734"></p>
<h2 id="The-byte-pair-encoding-0659"><a href="#The-byte-pair-encoding-0659" class="headerlink" title="The byte-pair encoding(0659)"></a>The byte-pair encoding(0659)</h2><p>Subwords model learn the structure of word. The byte-pair between it and  dont learn structure.</p>
<p>(0943)</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145251761.png" alt="image-20220224145251761"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145105071.png" alt="image-20220224145105071"></p>
<h2 id="Motivating-word-meaning-and-context-1556"><a href="#Motivating-word-meaning-and-context-1556" class="headerlink" title="Motivating word meaning and context(1556)"></a>Motivating word meaning and context(1556)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145804570.png" alt="image-20220224145804570"></p>
<h2 id="Pretraining-whole-models-2000"><a href="#Pretraining-whole-models-2000" class="headerlink" title="Pretraining whole models(2000)"></a>Pretraining whole models(2000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224145922233.png" alt="image-20220224145922233"></p>
<p>Wordv2vec dont consider context but we can use LSTM to achieve that.</p>
<p><strong>Mask some data and pretrain the model with them.</strong></p>
<h2 id="this-model-havent-met-overfitting-now-you-can-save-some-data-to-test-it-2811"><a href="#this-model-havent-met-overfitting-now-you-can-save-some-data-to-test-it-2811" class="headerlink" title="this model havent met overfitting now, you can save some data to test it.(2811)"></a>this model havent met overfitting now, you can save some data to test it.(2811)</h2><h2 id="transformers-for-encoding-and-decoding-3030"><a href="#transformers-for-encoding-and-decoding-3030" class="headerlink" title="transformers for encoding and decoding (3030)"></a>transformers for encoding and decoding (3030)</h2><h2 id="Pretraining-through-language-modeling-3400"><a href="#Pretraining-through-language-modeling-3400" class="headerlink" title="Pretraining through language modeling(3400)"></a>Pretraining through language modeling(3400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151624946.png" alt="image-20220224151624946"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224151950866.png" alt="image-20220224151950866"></p>
<h2 id="Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740"><a href="#Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740" class="headerlink" title="Stochastic gradient descent and pretrain&#x2F;finetune(3740)"></a>Stochastic gradient descent and pretrain&#x2F;finetune(3740)</h2><h2 id="Model-pretraining-has-three-ways-4021"><a href="#Model-pretraining-has-three-ways-4021" class="headerlink" title="Model pretraining has three ways (4021)"></a>Model pretraining has three ways (4021)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152730308.png" alt="image-20220224152730308"></p>
<p><strong>Decoder can see the history, the Encoder can also the future.</strong></p>
<p>Encoder-Decoder maybe is the better.</p>
<h3 id="Decoder-4300"><a href="#Decoder-4300" class="headerlink" title="Decoder(4300)"></a>Decoder(4300)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224152938046.png" alt="image-20220224152938046"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153716173.png" alt="image-20220224153716173"></p>
<h2 id="Generative-Pretrained-Transformer-GPT-4818"><a href="#Generative-Pretrained-Transformer-GPT-4818" class="headerlink" title="Generative Pretrained Transformer(GPT) (4818)"></a>Generative Pretrained Transformer(GPT) (4818)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224153928012.png" alt="image-20220224153928012"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154243901.png" alt="image-20220224154243901"></p>
<h2 id="GPT2-5400"><a href="#GPT2-5400" class="headerlink" title="GPT2(5400)"></a>GPT2(5400)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/image-20220224154759716.png" alt="image-20220224154759716"></p>
<h2 id="Pretraining-Encoding-5545"><a href="#Pretraining-Encoding-5545" class="headerlink" title="Pretraining Encoding(5545)"></a>Pretraining Encoding(5545)</h2><h3 id="Bert-5654"><a href="#Bert-5654" class="headerlink" title="(Bert)(5654)"></a>(Bert)(5654)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241654601.png" alt="image-20220224165457421"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241652887.png" alt="image-20220224165235710"></p>
<p><strong>Bert will mask some words, ask what have I mask</strong></p>
<h2 id="Bidirectional-encoder-representations-from-transformers-h0100"><a href="#Bidirectional-encoder-representations-from-transformers-h0100" class="headerlink" title="Bidirectional encoder representations from transformers(h0100)"></a>Bidirectional encoder representations from transformers(h0100)</h2><p>[ToL]</p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241703566.png" alt="image-20220224170312332"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241704798.png" alt="image-20220224170413603"></p>
<h2 id="Limitations-of-pretrained-encoders-h0900"><a href="#Limitations-of-pretrained-encoders-h0900" class="headerlink" title="Limitations of pretrained encoders(h0900)"></a>Limitations of pretrained encoders(h0900)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241712192.png" alt="image-20220224171252011"></p>
<h2 id="Extensions-of-BERT-h1000"><a href="#Extensions-of-BERT-h1000" class="headerlink" title="Extensions of BERT(h1000)"></a>Extensions of BERT(h1000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241714640.png" alt="image-20220224171454465"></p>
<h2 id="Pretraining-Encoder-Decoder-h1200"><a href="#Pretraining-Encoder-Decoder-h1200" class="headerlink" title="Pretraining Encoder-Decoder (h1200)"></a>Pretraining Encoder-Decoder (h1200)</h2><h3 id="T5-h1500"><a href="#T5-h1500" class="headerlink" title="T5(h1500)"></a>T5(h1500)</h3><p><strong>The model even dont know how many words are masked</strong></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241723663.png" alt="image-20220224172344435"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241725878.png" alt="image-20220224172541657"></p>
<p><strong>In the pretraining the model learned a lot, but it is not always good</strong></p>
<h2 id="GPT3-h1800"><a href="#GPT3-h1800" class="headerlink" title="GPT3(h1800)"></a>GPT3(h1800)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241727692.png" alt="image-20220224172754530"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241729302.png" alt="image-20220224172922203"></p>
<h2 id="Lecture-11-Question-Answering"><a href="#Lecture-11-Question-Answering" class="headerlink" title="Lecture 11 Question Answering"></a>Lecture 11 Question Answering</h2><iframe width="1217" height="685" src="https://www.youtube.com/embed/NcqfHa0_YmU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241741555.png" alt="image-20220224174146459"></p>
<h2 id="What-is-question-answering-0414"><a href="#What-is-question-answering-0414" class="headerlink" title="What is question answering(0414)"></a>What is question answering(0414)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241752253.png" alt="image-20220224175257101"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241753477.png" alt="image-20220224175334367"></p>
<p><strong>There are lots of practical applications(0629)</strong></p>
<h2 id="Beyond-textual-QA-problems-1100"><a href="#Beyond-textual-QA-problems-1100" class="headerlink" title="Beyond textual QA problems(1100)"></a>Beyond textual QA problems(1100)</h2><h2 id="Reading-comprehension-1223"><a href="#Reading-comprehension-1223" class="headerlink" title="Reading comprehension(1223)"></a>Reading comprehension(1223)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241801824.png" alt="image-20220224180147691"></p>
<p><strong>They are useful for many practical applications</strong></p>
<p>Reading comprehension is an important tested for evaluating how well computer systems understand human language</p>
<h2 id="Standord-question-answering-dataset-1815"><a href="#Standord-question-answering-dataset-1815" class="headerlink" title="Standord question answering dataset (1815)"></a>Standord question answering dataset (1815)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241808087.png" alt="image-20220224180828915"></p>
<h2 id="Neural-models-for-reading-comprehension-2428"><a href="#Neural-models-for-reading-comprehension-2428" class="headerlink" title="Neural models for reading comprehension(2428)"></a>Neural models for reading comprehension(2428)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241814453.png" alt="image-20220224181443258"></p>
<h2 id="LSTM-based-vs-BERT-models-2713"><a href="#LSTM-based-vs-BERT-models-2713" class="headerlink" title="LSTM-based vs BERT models (2713)"></a>LSTM-based vs BERT models (2713)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241815904.png" alt="image-20220224181551779"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818432.png" alt="image-20220224181815290"></p>
<h2 id="BiDAF-3200"><a href="#BiDAF-3200" class="headerlink" title="BiDAF(3200)"></a>BiDAF(3200)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241818897.png" alt="image-20220224181853733"></p>
<h3 id="Encoding-3200"><a href="#Encoding-3200" class="headerlink" title="Encoding(3200)"></a>Encoding(3200)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241821498.png" alt="image-20220224182135349"></p>
<h3 id="Attention-3400"><a href="#Attention-3400" class="headerlink" title="Attention(3400)"></a>Attention(3400)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241824459.png" alt="image-20220224182405343"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241829033.png" alt="image-20220224182904883"></p>
<h3 id="Modeling-and-output-layers-4640"><a href="#Modeling-and-output-layers-4640" class="headerlink" title="Modeling and output layers(4640)"></a>Modeling and output layers(4640)</h3><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241836707.png" alt="image-20220224183615556"></p>
<p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241838035.png" alt="image-20220224183819872"></p>
<h2 id="BERT-for-reading-comprehension-5227"><a href="#BERT-for-reading-comprehension-5227" class="headerlink" title="BERT for reading comprehension (5227)"></a>BERT for reading comprehension (5227)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241840230.png" alt="image-20220224184028029"></p>
<h2 id="Comparisons-between-BiDAF-and-BERT-models-2734"><a href="#Comparisons-between-BiDAF-and-BERT-models-2734" class="headerlink" title="Comparisons between BiDAF and BERT models(2734)"></a>Comparisons between BiDAF and BERT models(2734)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241851401.png" alt="image-20220224185118280"></p>
<h2 id="Can-we-design-better-pre-training-objectives-h0000"><a href="#Can-we-design-better-pre-training-objectives-h0000" class="headerlink" title="Can we design better pre-training objectives(h0000)"></a>Can we design better pre-training objectives(h0000)</h2><p><img src="https://juggler.oss-cn-beijing.aliyuncs.com/Picgo/202202241855709.png" alt="image-20220224185550578"></p>
<h2 id="open-domain-question-answering-h1000"><a href="#open-domain-question-answering-h1000" class="headerlink" title="open domain question answering(h1000)"></a>open domain question answering(h1000)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251049797.png" alt="image-20220225104946631"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241912138.png" alt="image-20220224191246022"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251053842.png" alt="image-20220225105306708"></p>
<h2 id="DPR-H1400"><a href="#DPR-H1400" class="headerlink" title="DPR(H1400)"></a>DPR(H1400)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202241926002.png" alt="image-20220224192658862"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251056150.png" alt="image-20220225105652971"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202202251057843.png" alt="image-20220225105747670"></p>
<h2 id="DensePhrase-Demo-h1800"><a href="#DensePhrase-Demo-h1800" class="headerlink" title="DensePhrase:Demo(h1800)"></a>DensePhrase:Demo(h1800)</h2><h1 id="Lecture-12-Natural-Language-Generation-ToL"><a href="#Lecture-12-Natural-Language-Generation-ToL" class="headerlink" title="Lecture 12 - Natural Language Generation[ToL]"></a>Lecture 12 - Natural Language Generation[ToL]</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/1uMo8olr5ng?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011431487.png" alt="image-20220301143159380"></p>
<h2 id="What-is-neural-language-generation-0300"><a href="#What-is-neural-language-generation-0300" class="headerlink" title="What is neural language generation?(0300)"></a>What is neural language generation?(0300)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011424191.png" alt="image-20220301142422083"></p>
<p><strong>Mache Translate</strong></p>
<p><strong>Dialogue Systems</strong> &#x2F;&#x2F;siri</p>
<p><strong>Summarization</strong></p>
<p><strong>Visual Description</strong></p>
<p><strong>Creative Generation</strong> &#x2F;&#x2F;story</p>
<h2 id="Components-of-NLG-Systems-0845"><a href="#Components-of-NLG-Systems-0845" class="headerlink" title="Components of NLG Systems(0845)"></a>Components of NLG Systems(0845)</h2><h3 id="Basic-of-natural-language-generation-0916"><a href="#Basic-of-natural-language-generation-0916" class="headerlink" title="Basic of natural language generation(0916)"></a>Basic of natural language generation(0916)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011433316.png" alt="image-20220301143317131"></p>
<h3 id="A-look-at-a-single-step-1024"><a href="#A-look-at-a-single-step-1024" class="headerlink" title="A look at a single step(1024)"></a>A look at a single step(1024)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011434716.png" alt="image-20220301143429583"></p>
<h3 id="then-select-and-train-1115"><a href="#then-select-and-train-1115" class="headerlink" title="then  select and train(1115)"></a>then  select and train(1115)</h3><p>teacher forcing need to be leaned</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011436047.png" alt="image-20220301143650876"></p>
<h2 id="Decoding-1317"><a href="#Decoding-1317" class="headerlink" title="Decoding(1317)"></a>Decoding(1317)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439775.png" alt="image-20220301143923558"></p>
<h3 id="Greedy-methods-1432"><a href="#Greedy-methods-1432" class="headerlink" title="Greedy methods(1432)"></a>Greedy methods(1432)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011439087.png" alt="image-20220301143958990"></p>
<h3 id="Greedy-methods-get-repetitive-1545"><a href="#Greedy-methods-get-repetitive-1545" class="headerlink" title="Greedy methods get repetitive(1545)"></a>Greedy methods get repetitive(1545)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011441769.png" alt="image-20220301144123549"></p>
<h3 id="why-do-repetition-happen-1613"><a href="#why-do-repetition-happen-1613" class="headerlink" title="why do repetition happen(1613)"></a>why do repetition happen(1613)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011442409.png" alt="image-20220301144237210"></p>
<h3 id="How-can-we-reduce-repetition-1824-ToL"><a href="#How-can-we-reduce-repetition-1824-ToL" class="headerlink" title="How can we reduce repetition (1824)[ToL]"></a>How can we reduce repetition (1824)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011445898.png" alt="image-20220301144518763"></p>
<h3 id="People-is-not-always-choose-the-greedy-methods-1930"><a href="#People-is-not-always-choose-the-greedy-methods-1930" class="headerlink" title="People is not always choose the greedy methods(1930)"></a>People is not always choose the greedy methods(1930)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011446786.png" alt="image-20220301144630546"></p>
<h3 id="Time-to-get-random-Sampling-2047"><a href="#Time-to-get-random-Sampling-2047" class="headerlink" title="Time to get random: Sampling(2047)"></a>Time to get random: Sampling(2047)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011447561.png" alt="image-20220301144729442"></p>
<h3 id="Decoding-Top-k-sampling-2100"><a href="#Decoding-Top-k-sampling-2100" class="headerlink" title="Decoding : Top-k sampling(2100)"></a>Decoding : Top-k sampling(2100)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450298.png" alt="image-20220301145000174"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011450273.png" alt="image-20220301145018125"></p>
<h3 id="Issues-with-Top-k-sampling-2339"><a href="#Issues-with-Top-k-sampling-2339" class="headerlink" title="Issues with Top-k sampling(2339)"></a>Issues with Top-k sampling(2339)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011451093.png" alt="image-20220301145153941"></p>
<h3 id="Decoding-Top-p-nucleus-sampling-2421"><a href="#Decoding-Top-p-nucleus-sampling-2421" class="headerlink" title="Decoding: Top-p(nucleus)sampling(2421)"></a>Decoding: Top-p(nucleus)sampling(2421)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011452969.png" alt="image-20220301145243854"></p>
<h3 id="Scaling-randomness-Softmax-temperature-2500-ToL"><a href="#Scaling-randomness-Softmax-temperature-2500-ToL" class="headerlink" title="Scaling randomness: Softmax temperature (2500)[ToL]"></a>Scaling randomness: Softmax temperature (2500)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011458368.png" alt="image-20220301145837161"></p>
<h3 id="improving-decoding-re-balancing-distributions-2710"><a href="#improving-decoding-re-balancing-distributions-2710" class="headerlink" title="improving decoding: re-balancing distributions(2710)"></a>improving decoding: re-balancing distributions(2710)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011500149.png" alt="image-20220301150002936"></p>
<h3 id="Backpropagation-based-distribution-re-balancing-3027"><a href="#Backpropagation-based-distribution-re-balancing-3027" class="headerlink" title="Backpropagation-based distribution re-balancing(3027)"></a>Backpropagation-based distribution re-balancing(3027)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011506509.png" alt="image-20220301150637319"></p>
<h3 id="Improving-Decoding-Re-ranking-3300-ToL"><a href="#Improving-Decoding-Re-ranking-3300-ToL" class="headerlink" title="Improving Decoding: Re-ranking(3300)[ToL]"></a>Improving Decoding: Re-ranking(3300)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011511660.png" alt="image-20220301151136510"></p>
<h3 id="Decoding-Takeaways-3540"><a href="#Decoding-Takeaways-3540" class="headerlink" title="Decoding: Takeaways(3540)"></a>Decoding: Takeaways(3540)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011512124.png" alt="image-20220301151258962"></p>
<h2 id="Training-NLG-models-4114"><a href="#Training-NLG-models-4114" class="headerlink" title="Training  NLG models(4114)"></a>Training  NLG models(4114)</h2><h3 id="Maximum-Likelihood-Training-4200"><a href="#Maximum-Likelihood-Training-4200" class="headerlink" title="Maximum Likelihood Training(4200)"></a>Maximum Likelihood Training(4200)</h3><p><strong>Are greedy decoders bad because of how theyre trained?</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011521846.png" alt="image-20220301152118621"></p>
<h3 id="Unlikelihood-Training-4427-ToL"><a href="#Unlikelihood-Training-4427-ToL" class="headerlink" title="Unlikelihood Training(4427)[ToL]"></a>Unlikelihood Training(4427)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011535301.png" alt="image-20220301153527149"></p>
<h3 id="Exposure-Bias-4513-ToL"><a href="#Exposure-Bias-4513-ToL" class="headerlink" title="Exposure Bias(4513)[ToL]"></a>Exposure Bias(4513)[ToL]</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011536542.png" alt="image-20220301153610391"></p>
<h3 id="Exposure-Bias-Solutions-4645"><a href="#Exposure-Bias-Solutions-4645" class="headerlink" title="Exposure Bias Solutions(4645)"></a>Exposure Bias Solutions(4645)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011537922.png" alt="image-20220301153742775"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539222.png" alt="image-20220301153907117"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011539740.png" alt="image-20220301153919593"></p>
<h3 id="Reinforce-Basics-4900"><a href="#Reinforce-Basics-4900" class="headerlink" title="Reinforce Basics(4900)"></a>Reinforce Basics(4900)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011540129.png" alt="image-20220301154050890"></p>
<h3 id="Reward-Estimation-5020"><a href="#Reward-Estimation-5020" class="headerlink" title="Reward Estimation(5020)"></a>Reward Estimation(5020)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542624.png" alt="image-20220301154205522"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011542000.png" alt="image-20220301154243893"></p>
<h3 id="reinforces-dark-side-5300"><a href="#reinforces-dark-side-5300" class="headerlink" title="reinforces dark side(5300)"></a>reinforces dark side(5300)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011544880.png" alt="image-20220301154452756"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011545691.png" alt="image-20220301154547630"></p>
<h3 id="Training-Takeways-5423"><a href="#Training-Takeways-5423" class="headerlink" title="Training: Takeways(5423)"></a>Training: Takeways(5423)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011547174.png" alt="image-20220301154732991"></p>
<h2 id="Evaluating-NLG-Systems-5613"><a href="#Evaluating-NLG-Systems-5613" class="headerlink" title="Evaluating NLG Systems(5613)"></a>Evaluating NLG Systems(5613)</h2><h2 id="Types-of-evaluation-methods-for-text-generation-5734"><a href="#Types-of-evaluation-methods-for-text-generation-5734" class="headerlink" title="Types of evaluation methods for text generation(5734)"></a>Types of evaluation methods for text generation(5734)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011557750.png" alt="image-20220301155705613"></p>
<h3 id="Content-Overlap-metrics-5800"><a href="#Content-Overlap-metrics-5800" class="headerlink" title="Content Overlap metrics(5800)"></a>Content Overlap metrics(5800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011559304.png" alt="image-20220301155931178"></p>
<h3 id="A-simple-failure-case-5900"><a href="#A-simple-failure-case-5900" class="headerlink" title="A simple failure case(5900)"></a>A simple failure case(5900)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011600766.png" alt="image-20220301160050567"></p>
<h3 id="Semantic-overlap-metrics-h0100"><a href="#Semantic-overlap-metrics-h0100" class="headerlink" title="Semantic overlap metrics(h0100)"></a>Semantic overlap metrics(h0100)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011603407.png" alt="image-20220301160319080"></p>
<h3 id="Model-based-metrics-h0120"><a href="#Model-based-metrics-h0120" class="headerlink" title="Model-based metrics(h0120)"></a>Model-based metrics(h0120)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011604213.png" alt="image-20220301160406112"></p>
<h4 id="word-distance-functions-h0234"><a href="#word-distance-functions-h0234" class="headerlink" title="word distance functions(h0234)"></a>word distance functions(h0234)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605672.png" alt="image-20220301160511479"></p>
<h4 id="Beyond-word-matching-h0350"><a href="#Beyond-word-matching-h0350" class="headerlink" title="Beyond word matching(h0350)"></a>Beyond word matching(h0350)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011605432.png" alt="image-20220301160556251"></p>
<h3 id="Human-evaluations-h0433"><a href="#Human-evaluations-h0433" class="headerlink" title="Human evaluations(h0433)"></a>Human evaluations(h0433)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011606672.png" alt="image-20220301160658568"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011607851.png" alt="image-20220301160747509"></p>
<h4 id="Issues-h0700"><a href="#Issues-h0700" class="headerlink" title="Issues(h0700)"></a>Issues(h0700)</h4><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011609267.png" alt="image-20220301160937146"></p>
<h3 id="Takeways-h0912"><a href="#Takeways-h0912" class="headerlink" title="Takeways(h0912)"></a>Takeways(h0912)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011614202.png" alt="image-20220301161428035"></p>
<h2 id="Ethical-Considerations-h1025"><a href="#Ethical-Considerations-h1025" class="headerlink" title="Ethical Considerations(h1025)"></a>Ethical Considerations(h1025)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011615331.png" alt="image-20220301161515113"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011616579.png" alt="image-20220301161639415"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011617673.png" alt="image-20220301161723483"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011618324.png" alt="image-20220301161839135"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011619216.png" alt="image-20220301161931109"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011621427.png" alt="image-20220301162101280"></p>
<h1 id="Lecture-13-Coreference-Resolution"><a href="#Lecture-13-Coreference-Resolution" class="headerlink" title="Lecture 13 - Coreference Resolution"></a>Lecture 13 - Coreference Resolution</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/FFRnDRcbQQU?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011625743.png" alt="image-20220301162522611"></p>
<h2 id="What-is-Coreference-Resolution-0604"><a href="#What-is-Coreference-Resolution-0604" class="headerlink" title="What is Coreference Resolution?(0604)"></a>What is Coreference Resolution?(0604)</h2><p><strong>Identify all mentions that refer to the same entity in the world</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011654767.png" alt="image-20220301165446496"></p>
<h2 id="Applications-1712"><a href="#Applications-1712" class="headerlink" title="Applications (1712)"></a>Applications (1712)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011656858.png" alt="image-20220301165651721"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011658422.png" alt="image-20220301165822337"></p>
<h2 id="Coreference-Resolution-in-Two-steps-1947"><a href="#Coreference-Resolution-in-Two-steps-1947" class="headerlink" title="Coreference Resolution in Two steps(1947)"></a>Coreference Resolution in Two steps(1947)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011659852.png" alt="image-20220301165948737"></p>
<h2 id="Mention-Detection-2049"><a href="#Mention-Detection-2049" class="headerlink" title="Mention Detection(2049)"></a>Mention Detection(2049)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011700078.png" alt="image-20220301170016948"></p>
<h3 id="Not-quite-so-simple-2255"><a href="#Not-quite-so-simple-2255" class="headerlink" title="Not quite so simple(2255)"></a>Not quite so simple(2255)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011702656.png" alt="image-20220301170236541"></p>
<p>It is the best donut.</p>
<p>I want to find the best donut.</p>
<h2 id="Avoiding-a-traditional-pipeline-system-2811"><a href="#Avoiding-a-traditional-pipeline-system-2811" class="headerlink" title="Avoiding a traditional pipeline system(2811)"></a>Avoiding a traditional pipeline system(2811)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011705194.png" alt="image-20220301170543068"></p>
<p><strong>End to End[ToL]</strong></p>
<h2 id="Onto-Coreference-First-some-linguistics-3035"><a href="#Onto-Coreference-First-some-linguistics-3035" class="headerlink" title="Onto Coreference! First, some linguistics (3035)"></a>Onto Coreference! First, some linguistics (3035)</h2><p><strong>Coreference and Anaphor</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011712593.png" alt="image-20220301171220450"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011713580.png" alt="image-20220301171334445"></p>
<h3 id="not-all-anaphoric-relations-are-coreferential-3349"><a href="#not-all-anaphoric-relations-are-coreferential-3349" class="headerlink" title="not all anaphoric relations are coreferential (3349)"></a>not all anaphoric relations are coreferential (3349)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011715286.png" alt="image-20220301171524154"></p>
<h2 id="Anaphora-vs-Cataphora-3610"><a href="#Anaphora-vs-Cataphora-3610" class="headerlink" title="Anaphora vs Cataphora(3610)"></a>Anaphora vs Cataphora(3610)</h2><p>One look its reference before it the other is after it.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011717048.png" alt="image-20220301171753920"></p>
<h2 id="Taking-stock-3801"><a href="#Taking-stock-3801" class="headerlink" title="Taking stock (3801)"></a>Taking stock (3801)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011719341.png" alt="image-20220301171920183"></p>
<h2 id="Four-kinds-of-coreference-Models-4018"><a href="#Four-kinds-of-coreference-Models-4018" class="headerlink" title="Four kinds of coreference Models(4018)"></a>Four kinds of coreference Models(4018)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011721240.png" alt="image-20220301172140149"></p>
<h2 id="Traditional-pronominal-anaphora-resolution-Hobbss-naive-algorithm-4130"><a href="#Traditional-pronominal-anaphora-resolution-Hobbss-naive-algorithm-4130" class="headerlink" title="Traditional pronominal anaphora resolution:Hobbss naive algorithm(4130)"></a>Traditional pronominal anaphora resolution:Hobbss naive algorithm(4130)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723580.png" alt="image-20220301172320435"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011723916.png" alt="image-20220301172342791"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011724568.png" alt="image-20220301172431380"></p>
<h2 id="Knowledge-based-Pronominal-Coreference-4820"><a href="#Knowledge-based-Pronominal-Coreference-4820" class="headerlink" title="Knowledge-based Pronominal Coreference(4820)"></a>Knowledge-based Pronominal Coreference(4820)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011727409.png" alt="image-20220301172732198"></p>
<p>Hobbs method can not really solve the questions, the model should really understand the sentence.</p>
<h2 id="Coreference-Models-Mention-Pair-5624"><a href="#Coreference-Models-Mention-Pair-5624" class="headerlink" title="Coreference Models: Mention Pair(5624)"></a>Coreference Models: Mention Pair(5624)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738690.png" alt="image-20220301173814531"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011738116.png" alt="image-20220301173826974"></p>
<h3 id="Mention-Pair-Test-Time-5800"><a href="#Mention-Pair-Test-Time-5800" class="headerlink" title="Mention Pair Test Time(5800)"></a>Mention Pair Test Time(5800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011739666.png" alt="image-20220301173911539"></p>
<h3 id="Disadvantage-5953"><a href="#Disadvantage-5953" class="headerlink" title="Disadvantage(5953)"></a>Disadvantage(5953)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011741350.png" alt="image-20220301174101225"></p>
<h2 id="Coreference-Models-Mention-Ranking-h0050"><a href="#Coreference-Models-Mention-Ranking-h0050" class="headerlink" title="Coreference Models: Mention Ranking(h0050)"></a>Coreference Models: Mention Ranking(h0050)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743065.png" alt="image-20220301174326929"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011743795.png" alt="image-20220301174335701"></p>
<h2 id="Convolutional-Neural-Nets-h0341"><a href="#Convolutional-Neural-Nets-h0341" class="headerlink" title="Convolutional Neural Nets(h0341)"></a>Convolutional Neural Nets(h0341)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011745334.png" alt="image-20220301174555163"></p>
<h2 id="What-is-convolution-anyway-h0452"><a href="#What-is-convolution-anyway-h0452" class="headerlink" title="What is convolution anyway?(h0452)"></a>What is convolution anyway?(h0452)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011842759.png" alt="image-20220301184216564"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011843829.png" alt="image-20220301184306662"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011844092.png" alt="image-20220301184445934"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011845881.png" alt="image-20220301184526687"></p>
<p><strong>Summarize what we have usually use pooling</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011846697.png" alt="image-20220301184655490"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011847112.png" alt="image-20220301184706063"></p>
<p>Max pooling is usually better.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011848032.png" alt="image-20220301184805861"></p>
<h2 id="End-to-End-Neural-Coref-Model-h1206"><a href="#End-to-End-Neural-Coref-Model-h1206" class="headerlink" title="End-to-End Neural Coref Model(h1206)"></a>End-to-End Neural Coref Model(h1206)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011849948.png" alt="image-20220301184935797"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850188.png" alt="image-20220301185015078"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011850940.png" alt="image-20220301185022792"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011851616.png" alt="image-20220301185132395"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011852860.png" alt="image-20220301185213638"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853116.png" alt="image-20220301185316970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011853483.png" alt="image-20220301185347334"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011854783.png" alt="image-20220301185443640"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011855774.png" alt="image-20220301185551550"></p>
<h2 id="Conclusion-h2017"><a href="#Conclusion-h2017" class="headerlink" title="Conclusion (h2017)"></a>Conclusion (h2017)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203011857080.png" alt="image-20220301185734941"></p>
<h1 id="Lecture-14-T5-and-Large-Language-Models"><a href="#Lecture-14-T5-and-Large-Language-Models" class="headerlink" title="Lecture 14 - T5 and Large Language Models"></a>Lecture 14 - T5 and Large Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/iHWkLvoSpTg?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021447359.png" alt="image-20220302144735211"></p>
<p>(0243)</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021451322.png" alt="image-20220302145100222"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021453717.png" alt="image-20220302145356635"></p>
<h2 id="T5-with-a-task-prefix-0800"><a href="#T5-with-a-task-prefix-0800" class="headerlink" title="T5 with a task prefix(0800)"></a>T5 with a task prefix(0800)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021454368.png" alt="image-20220302145406303"></p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021455282.png" alt="image-20220302145536205"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456327.png" alt="image-20220302145606261"></p>
<h3 id="STSB"><a href="#STSB" class="headerlink" title="STSB"></a>STSB</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456444.png" alt="image-20220302145658323"></p>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021456947.png" alt="image-20220302145646869"></p>
<h2 id="T5-change-little-from-original-transformer-1300"><a href="#T5-change-little-from-original-transformer-1300" class="headerlink" title="T5 change little from original transformer(1300)"></a>T5 change little from original transformer(1300)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021459690.png" alt="image-20220302145917510"></p>
<h2 id="what-should-my-pre-training-data-set-be-1325"><a href="#what-should-my-pre-training-data-set-be-1325" class="headerlink" title="what should my pre-training data set be?(1325)"></a>what should my pre-training data set be?(1325)</h2><p><strong>Get from open source data source and then wipe them and get c4 1500</strong></p>
<h2 id="Then-is-how-to-train-from-a-start-1659"><a href="#Then-is-how-to-train-from-a-start-1659" class="headerlink" title="Then is how to train from a start(1659)"></a>Then is how to train from a start(1659)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021511473.png" alt="image-20220302151128378"></p>
<h2 id="pretrain-1805"><a href="#pretrain-1805" class="headerlink" title="pretrain(1805)"></a>pretrain(1805)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021515266.png" alt="image-20220302151510138"></p>
<h2 id="choose-the-model-2412"><a href="#choose-the-model-2412" class="headerlink" title="choose the model(2412)"></a>choose the model(2412)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021520528.png" alt="image-20220302152005363"></p>
<p>They use the encoder-Decoder model, It turns out it works well.</p>
<p><strong>They dont change hyper paramenters because of the cost</strong></p>
<h2 id="pre-training-objective-2629"><a href="#pre-training-objective-2629" class="headerlink" title="pre-training objective(2629)"></a>pre-training objective(2629)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021539312.png" alt="image-20220302153925164"></p>
<p><strong>Choose different train method</strong></p>
<h2 id="different-structure-of-data-source-2822"><a href="#different-structure-of-data-source-2822" class="headerlink" title="different structure of data source(2822)"></a>different structure of data source(2822)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021546645.png" alt="image-20220302154612488"></p>
<h2 id="Multi-task-learning-3443"><a href="#Multi-task-learning-3443" class="headerlink" title="Multi task learning (3443)"></a>Multi task learning (3443)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021551343.png" alt="image-20220302155158191"></p>
<h2 id="close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621"><a href="#close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621" class="headerlink" title="close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)"></a>close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021557083.png" alt="image-20220302155756918"></p>
<h2 id="What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737"><a href="#What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737" class="headerlink" title="What if it happens there are four times computes as much as before  (3737)"></a>What if it happens there are four times computes as much as before  (3737)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021600593.png" alt="image-20220302160009440"></p>
<h2 id="Overview-3840"><a href="#Overview-3840" class="headerlink" title="Overview(3840)"></a>Overview(3840)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021601735.png" alt="image-20220302160104583"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021602559.png" alt="image-20220302160234452"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021605914.png" alt="image-20220302160555766"></p>
<p> <img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021606666.png" alt="image-20220302160612550"></p>
<h2 id="What-about-all-of-the-other-languages-mT5-4735"><a href="#What-about-all-of-the-other-languages-mT5-4735" class="headerlink" title="What about all of the other languages?(mT5)(4735)"></a>What about all of the other languages?(mT5)(4735)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021611309.png" alt="image-20220302161124160"></p>
<p>Same model different corpus.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021612178.png" alt="image-20220302161211041"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021613249.png" alt="image-20220302161358092"></p>
<h2 id="XTREME-5000"><a href="#XTREME-5000" class="headerlink" title="XTREME (5000)"></a>XTREME (5000)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021614579.png" alt="image-20220302161445454"></p>
<h2 id="How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225"><a href="#How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225" class="headerlink" title="How much knowledge does a language model pick up during pre-training?(5225)"></a>How much knowledge does a language model pick up during pre-training?(5225)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619700.png" alt="image-20220302161913596"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619203.png" alt="image-20220302161932089"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021619946.png" alt="image-20220302161949876"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021620563.png" alt="image-20220302162028438"></p>
<h2 id="Salient-span-masking-5631"><a href="#Salient-span-masking-5631" class="headerlink" title="Salient span masking (5631)"></a>Salient span masking (5631)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021623948.png" alt="image-20220302162316816"></p>
<p><strong>Instead of mask randomly, it mask username please date, etc.</strong></p>
<h2 id="Do-large-language-models-memorize-their-training-data-h0100"><a href="#Do-large-language-models-memorize-their-training-data-h0100" class="headerlink" title="Do large language models memorize their training data(h0100)"></a>Do large language models memorize their training data(h0100)</h2><p><strong>It seems it did</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021629154.png" alt="image-20220302162918979"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021630287.png" alt="image-20220302163050189"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021631372.png" alt="image-20220302163113267"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635048.png" alt="image-20220302163505954"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021635716.png" alt="image-20220302163519627"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021637986.png" alt="image-20220302163719877"></p>
<p>They need to see examples, they need to see particular examples fewer times in order!</p>
<h2 id="Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010"><a href="#Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010" class="headerlink" title="Can we close the gap between large and small models by improving the transformer architecture(h1010)"></a>Can we close the gap between large and small models by improving the transformer architecture(h1010)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021649670.png" alt="image-20220302164909562"></p>
<p>in these test, they change some architecture such as RELu. </p>
<p><strong>there actually were very few, if any modifications that improved performance meaningfully.</strong></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021652560.png" alt="image-20220302165203416"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021653903.png" alt="image-20220302165316814">(h1700)</p>
<h2 id="QA-h1915"><a href="#QA-h1915" class="headerlink" title="QA(h1915)"></a>QA(h1915)</h2><h1 id="Lecture-15-Add-Knowledge-to-Language-Models"><a href="#Lecture-15-Add-Knowledge-to-Language-Models" class="headerlink" title="Lecture 15 - Add Knowledge to Language Models"></a>Lecture 15 - Add Knowledge to Language Models</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/y68RJVfGoto?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021723936.png" alt="image-20220302172329814"></p>
<h2 id="Recap-LM-0232"><a href="#Recap-LM-0232" class="headerlink" title="Recap: LM(0232)"></a>Recap: LM(0232)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021726699.png" alt="image-20220302172634570"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727605.png" alt="image-20220302172712490"></p>
<h2 id="What-does-a-language-model-know-0423"><a href="#What-does-a-language-model-know-0423" class="headerlink" title="What does a language model know?(0423)"></a>What does a language model know?(0423)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021727649.png" alt="image-20220302172753547"></p>
<p>Thing may right in logic but wrong in fact.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021729763.png" alt="image-20220302172916623"></p>
<h2 id="The-importance-of-know-ledge-aware-language-models-0700"><a href="#The-importance-of-know-ledge-aware-language-models-0700" class="headerlink" title="The importance of know ledge-aware language models(0700)"></a>The importance of know ledge-aware language models(0700)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733793.png" alt="image-20220302173300654"></p>
<h2 id="Query-traditional-knowledge-bases-0750"><a href="#Query-traditional-knowledge-bases-0750" class="headerlink" title="Query traditional knowledge bases(0750)"></a>Query traditional knowledge bases(0750)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021733338.png" alt="image-20220302173336194"></p>
<h2 id="Query-language-models-as-knowledge-bases-0955"><a href="#Query-language-models-as-knowledge-bases-0955" class="headerlink" title="Query language models as knowledge bases(0955)"></a>Query language models as knowledge bases(0955)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021735054.png" alt="image-20220302173553905"></p>
<h2 id="Compare-and-disadvantage-1010"><a href="#Compare-and-disadvantage-1010" class="headerlink" title="Compare and disadvantage(1010)"></a>Compare and disadvantage(1010)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021738604.png" alt="image-20220302173820443"></p>
<h2 id="Techniques-to-add-knowledge-to-LMs-130"><a href="#Techniques-to-add-knowledge-to-LMs-130" class="headerlink" title="Techniques to add knowledge to LMs(130)"></a>Techniques to add knowledge to LMs(130)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021739919.png" alt="image-20220302173937785"></p>
<h2 id="Add-pretrained-embeddings-1403"><a href="#Add-pretrained-embeddings-1403" class="headerlink" title="Add pretrained embeddings(1403)"></a>Add pretrained embeddings(1403)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021743165.png" alt="image-20220302174313016"></p>
<h2 id="Aside-What-is-entity-linking-1516"><a href="#Aside-What-is-entity-linking-1516" class="headerlink" title="Aside: What is entity linking?(1516)"></a>Aside: What is entity linking?(1516)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021746116.png" alt="image-20220302174603921"></p>
<h2 id="Method-1-Add-pretrained-entity-embeddings-1815"><a href="#Method-1-Add-pretrained-entity-embeddings-1815" class="headerlink" title="Method 1: Add pretrained entity embeddings(1815)"></a>Method 1: Add pretrained entity embeddings(1815)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021747337.png" alt="image-20220302174729224"></p>
<h3 id="How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000"><a href="#How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000" class="headerlink" title="How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)"></a>How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021749944.png" alt="image-20220302174927805"></p>
<h2 id="ERNIE-Enhanced-language-representation-with-informative-entities-2143"><a href="#ERNIE-Enhanced-language-representation-with-informative-entities-2143" class="headerlink" title="ERNIE: Enhanced language representation with informative entities(2143)"></a>ERNIE: Enhanced language representation with informative entities(2143)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021752214.png" alt="image-20220302175236060"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021754765.png" alt="image-20220302175420597"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757296.png" alt="image-20220302175702140"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021757888.png" alt="image-20220302175713761"></p>
<h3 id="strengths-amp-remaining-challenges-2610"><a href="#strengths-amp-remaining-challenges-2610" class="headerlink" title="strengths &amp; remaining challenges(2610)"></a>strengths &amp; remaining challenges(2610)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021758503.png" alt="image-20220302175826353"></p>
<h2 id="Jointly-learn-to-link-entities-with-KnowBERT-2958"><a href="#Jointly-learn-to-link-entities-with-KnowBERT-2958" class="headerlink" title="Jointly learn to link entities with KnowBERT(2958)"></a>Jointly learn to link entities with KnowBERT(2958)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021804637.png" alt="image-20220302180440491"></p>
<h2 id="Use-an-external-memory-3140"><a href="#Use-an-external-memory-3140" class="headerlink" title="Use an external memory(3140)"></a>Use an external memory(3140)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021807795.png" alt="image-20220302180727662"></p>
<h3 id="KGLM-3355"><a href="#KGLM-3355" class="headerlink" title="KGLM(3355)"></a>KGLM(3355)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021808462.png" alt="image-20220302180818299"></p>
<h3 id="Local-knowledge-and-full-knowledge"><a href="#Local-knowledge-and-full-knowledge" class="headerlink" title="Local knowledge and full knowledge"></a>Local knowledge and full knowledge</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021810608.png" alt="image-20220302181037473"></p>
<h3 id="When-should-the-model-use-the-external-knowledge-3600"><a href="#When-should-the-model-use-the-external-knowledge-3600" class="headerlink" title="When should the model use the external knowledge(3600)"></a>When should the model use the external knowledge(3600)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021811716.png" alt="image-20220302181146581"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021814810.png" alt="image-20220302181436660"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815905.png" alt="image-20220302181526770"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021815447.png" alt="image-20220302181538323"></p>
<h2 id="Compare-to-the-others-4334"><a href="#Compare-to-the-others-4334" class="headerlink" title="Compare to the others(4334)"></a>Compare to the others(4334)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021818819.png" alt="image-20220302181801664"></p>
<h2 id="More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730"><a href="#More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730" class="headerlink" title="More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)"></a>More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021823462.png" alt="image-20220302182325290"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021825650.png" alt="image-20220302182507490"></p>
<h2 id="Modify-the-training-data-5230"><a href="#Modify-the-training-data-5230" class="headerlink" title="Modify the training data(5230)"></a>Modify the training data(5230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021828456.png" alt="image-20220302182823268"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021829477.png" alt="image-20220302182959293"></p>
<h2 id="WKLM-5458"><a href="#WKLM-5458" class="headerlink" title="WKLM(5458)"></a>WKLM(5458)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021830774.png" alt="image-20220302183028613"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021831311.png" alt="image-20220302183142193"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021832124.png" alt="image-20220302183255968"></p>
<h2 id="Learn-inductive-biases-through-masking-5811"><a href="#Learn-inductive-biases-through-masking-5811" class="headerlink" title="Learn inductive biases through masking(5811)"></a>Learn inductive biases through masking(5811)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021833826.png" alt="image-20220302183351631"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834994.png" alt="image-20220302183427849"></p>
<h2 id="Salient-span-masking-5927"><a href="#Salient-span-masking-5927" class="headerlink" title="Salient span masking(5927)"></a>Salient span masking(5927)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021834166.png" alt="image-20220302183458012"></p>
<h2 id="Recap-h0053"><a href="#Recap-h0053" class="headerlink" title="Recap(h0053)"></a>Recap(h0053)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021837032.png" alt="image-20220302183700886"></p>
<h2 id="Evaluating-knowledge-in-LMS-h0211"><a href="#Evaluating-knowledge-in-LMS-h0211" class="headerlink" title="Evaluating knowledge in LMS(h0211)"></a>Evaluating knowledge in LMS(h0211)</h2><h3 id="LAMA-h0250"><a href="#LAMA-h0250" class="headerlink" title="LAMA(h0250)"></a>LAMA(h0250)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021838823.png" alt="image-20220302183849664"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021839294.png" alt="image-20220302183927125"></p>
<h3 id="The-limitations-h0650"><a href="#The-limitations-h0650" class="headerlink" title="The limitations (h0650)"></a>The limitations (h0650)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021841791.png" alt="image-20220302184139639"></p>
<h2 id="LAMA-UnHelpful-Names-LAMA-UHN"><a href="#LAMA-UnHelpful-Names-LAMA-UHN" class="headerlink" title="LAMA_UnHelpful Names(LAMA-UHN)"></a>LAMA_UnHelpful Names(LAMA-UHN)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021842799.png" alt="image-20220302184226621"></p>
<p>** They delete something that may caused by co-occurrence **</p>
<h3 id="Developing-better-prompts-to-query-knowledge-in-LMS"><a href="#Developing-better-prompts-to-query-knowledge-in-LMS" class="headerlink" title="Developing better prompts to query knowledge in LMS"></a>Developing better prompts to query knowledge in LMS</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021844225.png" alt="image-20220302184443068"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021845853.png" alt="image-20220302184528706"></p>
<h3 id="Knowledge-driven-downstream-tasks-h1253"><a href="#Knowledge-driven-downstream-tasks-h1253" class="headerlink" title="Knowledge-driven downstream tasks(h1253)"></a>Knowledge-driven downstream tasks(h1253)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847354.png" alt="image-20220302184702209"></p>
<h2 id="Relation-extraction-performance-on-TACED-h1400"><a href="#Relation-extraction-performance-on-TACED-h1400" class="headerlink" title="Relation extraction performance on TACED(h1400)"></a>Relation extraction performance on TACED(h1400)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021847359.png" alt="image-20220302184753193"></p>
<h2 id="Entity-typing-performance-on-Open-Entuty"><a href="#Entity-typing-performance-on-Open-Entuty" class="headerlink" title="Entity typing performance on Open Entuty"></a>Entity typing performance on Open Entuty</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021848691.png" alt="image-20220302184828514"></p>
<h2 id="Recap-Evaluating-knowledge-in-LMs-h1600"><a href="#Recap-Evaluating-knowledge-in-LMs-h1600" class="headerlink" title="Recap: Evaluating knowledge in LMs(h1600)"></a>Recap: Evaluating knowledge in LMs(h1600)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021849200.png" alt="image-20220302184929078"></p>
<h2 id="Other-exciting-progress-amp-whats-next-h1652"><a href="#Other-exciting-progress-amp-whats-next-h1652" class="headerlink" title="Other exciting progress &amp; whats next?(h1652)"></a>Other exciting progress &amp; whats next?(h1652)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203021850845.png" alt="image-20220302185006721"></p>
<h1 id="Lecture-17-Model-Analysis-and-Explanation"><a href="#Lecture-17-Model-Analysis-and-Explanation" class="headerlink" title="Lecture 17 - Model Analysis and Explanation"></a>Lecture 17 - Model Analysis and Explanation</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/f_qmSSBWV_E?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031042434.png" alt="image-20220303104239293"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031043574.png" alt="image-20220303104308448"></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><h3 id="what-are-our-models-doing-0415"><a href="#what-are-our-models-doing-0415" class="headerlink" title="what are our models doing(0415)"></a>what are our models doing(0415)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031044256.png" alt="image-20220303104435113"></p>
<h3 id="how-do-we-make-tomorrows-model-0515"><a href="#how-do-we-make-tomorrows-model-0515" class="headerlink" title="how do we make tomorrows model?(0515)"></a>how do we make tomorrows model?(0515)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031046845.png" alt="image-20220303104651667"></p>
<h3 id="What-biases-are-built-into-model-0700"><a href="#What-biases-are-built-into-model-0700" class="headerlink" title="What biases are built into model?(0700)"></a>What biases are built into model?(0700)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031050696.png" alt="image-20220303105015554"></p>
<h3 id="how-do-we-make-in-the-following-25years-0800"><a href="#how-do-we-make-in-the-following-25years-0800" class="headerlink" title="how do we make in the following 25years(0800)"></a>how do we make in the following 25years(0800)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031051800.png" alt="image-20220303105141648"></p>
<h2 id="Model-analysis-at-varying-levels-of-abstraction-0904"><a href="#Model-analysis-at-varying-levels-of-abstraction-0904" class="headerlink" title="Model analysis at varying levels of abstraction(0904)"></a>Model analysis at varying levels of abstraction(0904)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031056169.png" alt="image-20220303105647998"></p>
<h2 id="Model-evaluation-as-model-analysis-1117"><a href="#Model-evaluation-as-model-analysis-1117" class="headerlink" title="Model evaluation as model analysis(1117)"></a>Model evaluation as model analysis(1117)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031059574.png" alt="image-20220303105924421"></p>
<h2 id="Model-evaluation-as-model-analysis-in-natural-language-inference-1344"><a href="#Model-evaluation-as-model-analysis-in-natural-language-inference-1344" class="headerlink" title="Model evaluation as model analysis in natural language inference(1344)"></a>Model evaluation as model analysis in natural language inference(1344)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031102348.png" alt="image-20220303110240168"></p>
<h3 id="What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558"><a href="#What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558" class="headerlink" title="What if the model is simple using heuristics to get good accuracy?(1558)"></a>What if the model is simple using heuristics to get good accuracy?(1558)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031108392.png" alt="image-20220303110832177"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031109573.png" alt="image-20220303110953359"></p>
<h2 id="Language-models-as-linguistic-test-subjects-2023"><a href="#Language-models-as-linguistic-test-subjects-2023" class="headerlink" title="Language models as linguistic test subjects(2023)"></a>Language models as linguistic test subjects(2023)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031117718.png" alt="image-20220303111752546"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031123611.png" alt="image-20220303112316410"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031126322.png" alt="image-20220303112622131"></p>
<h2 id="Careful-test-sets-as-unit-test-suites-CheckListing-3230"><a href="#Careful-test-sets-as-unit-test-suites-CheckListing-3230" class="headerlink" title="Careful  test sets as unit test suites: CheckListing(3230)"></a>Careful  test sets as unit test suites: CheckListing(3230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031150003.png" alt="image-20220303115000790"></p>
<h2 id="Fitting-the-dataset-vs-learning-the-task-3500"><a href="#Fitting-the-dataset-vs-learning-the-task-3500" class="headerlink" title="Fitting the dataset vs learning the task(3500)"></a>Fitting the dataset vs learning the task(3500)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031151961.png" alt="image-20220303115116821"></p>
<h2 id="Knowledge-evaluation-as-model-analysis-3642"><a href="#Knowledge-evaluation-as-model-analysis-3642" class="headerlink" title="Knowledge evaluation as model analysis(3642)"></a>Knowledge evaluation as model analysis(3642)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031152782.png" alt="image-20220303115222614"></p>
<h2 id="Input-influence-does-my-model-really-use-long-distance-context-3822"><a href="#Input-influence-does-my-model-really-use-long-distance-context-3822" class="headerlink" title="Input influence: does my model really use long-distance context?(3822)"></a>Input influence: does my model really use long-distance context?(3822)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031154169.png" alt="image-20220303115456959"></p>
<h2 id="Prediction-explanations-what-in-the-input-led-to-this-output-4054"><a href="#Prediction-explanations-what-in-the-input-led-to-this-output-4054" class="headerlink" title="Prediction explanations: what in the input led to this output?(4054)"></a>Prediction explanations: what in the input led to this output?(4054)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031158656.png" alt="image-20220303115848462"></p>
<h2 id="Prediction-explanations-simple-saliency-maps-4230"><a href="#Prediction-explanations-simple-saliency-maps-4230" class="headerlink" title="Prediction explanations: simple saliency maps(4230)"></a>Prediction explanations: simple saliency maps(4230)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031201539.png" alt="image-20220303120124359"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031332993.png" alt="image-20220303133241797"></p>
<h2 id="Explanation-by-input-reduction-4607"><a href="#Explanation-by-input-reduction-4607" class="headerlink" title="Explanation by input reduction (4607)"></a>Explanation by input reduction (4607)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031341312.png" alt="image-20220303134148143"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031343962.png" alt="image-20220303134313746"></p>
<h2 id="Analyzing-models-by-breaking-them-5106"><a href="#Analyzing-models-by-breaking-them-5106" class="headerlink" title="Analyzing models by breaking them(5106)"></a>Analyzing models by breaking them(5106)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346413.png" alt="image-20220303134604267"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031346603.png" alt="image-20220303134644433"></p>
<p>They add a nonsense sentence at the end and the prediction changed.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031347898.png" alt="image-20220303134756682"></p>
<p><strong>Change the Q also make the prediction changed</strong></p>
<h2 id="Are-models-robust-to-noise-in-their-input-5518"><a href="#Are-models-robust-to-noise-in-their-input-5518" class="headerlink" title="Are models robust to noise in their input?(5518)"></a>Are models robust to noise in their input?(5518)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031350084.png" alt="image-20220303135054871"></p>
<p>It seems not.</p>
<h2 id="Analysis-of-interpretable-architecture-components-5719"><a href="#Analysis-of-interpretable-architecture-components-5719" class="headerlink" title="Analysis of interpretable architecture components(5719)"></a>Analysis of interpretable architecture components(5719)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031356980.png" alt="image-20220303135659761"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031357241.png" alt="image-20220303135716017"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031400358.png" alt="image-20220303140006202"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031401626.png" alt="image-20220303140154452"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031403011.png" alt="image-20220303140306747"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031404517.png" alt="image-20220303140430315"></p>
<h2 id="Probing-supervised-analysis-of-neural-networks-h0408"><a href="#Probing-supervised-analysis-of-neural-networks-h0408" class="headerlink" title="Probing: supervised analysis of neural networks(h0408)"></a>Probing: supervised analysis of neural networks(h0408)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031407337.png" alt="image-20220303140720120"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031408146.png" alt="image-20220303140831970"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031410797.png" alt="image-20220303141059579"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413065.png" alt="image-20220303141301877"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031413295.png" alt="image-20220303141354126"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031414069.png" alt="image-20220303141443881"></p>
<p>the most efficient layer is in the middlwe.</p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031415636.png" alt="image-20220303141554363"></p>
<p>deeper, more abstract</p>
<h2 id="Emergent-simple-structure-in-neural-networks-h1019"><a href="#Emergent-simple-structure-in-neural-networks-h1019" class="headerlink" title="Emergent simple structure in neural networks(h1019)"></a>Emergent simple structure in neural networks(h1019)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031417261.png" alt="image-20220303141709095"></p>
<h2 id="Probing-tress-simply-recoverable-from-BERT-representations-h1136"><a href="#Probing-tress-simply-recoverable-from-BERT-representations-h1136" class="headerlink" title="Probing: tress simply recoverable from BERT representations(h1136)"></a>Probing: tress simply recoverable from BERT representations(h1136)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031419210.png" alt="image-20220303141908032"></p>
<h2 id="Final-thoughts-on-probing-and-correlation-studies-h1341"><a href="#Final-thoughts-on-probing-and-correlation-studies-h1341" class="headerlink" title="Final thoughts on probing and correlation studies(h1341)"></a>Final thoughts on probing and correlation studies(h1341)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031421004.png" alt="image-20220303142155844"></p>
<p>Not causal study</p>
<h2 id="Recasting-model-tweaks-and-ablations-as-analysis-h1406"><a href="#Recasting-model-tweaks-and-ablations-as-analysis-h1406" class="headerlink" title="Recasting model tweaks and ablations as analysis(h1406)"></a>Recasting model tweaks and ablations as analysis(h1406)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031423815.png" alt="image-20220303142341661"></p>
<h3 id="Ablation-analysis-do-we-need-all-these-attension-heads-h1445"><a href="#Ablation-analysis-do-we-need-all-these-attension-heads-h1445" class="headerlink" title="Ablation analysis: do we need all these attension heads?(h1445)"></a>Ablation analysis: do we need all these attension heads?(h1445)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031424764.png" alt="image-20220303142453543"></p>
<h2 id="Whats-the-right-layer-order-for-a-transformer-h1537"><a href="#Whats-the-right-layer-order-for-a-transformer-h1537" class="headerlink" title="Whats the right layer order for a transformer?(h1537)"></a>Whats the right layer order for a transformer?(h1537)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031425391.png" alt="image-20220303142557160"></p>
<h2 id="Parting-thoughts-h1612"><a href="#Parting-thoughts-h1612" class="headerlink" title="Parting thoughts(h1612)"></a>Parting thoughts(h1612)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031426427.png" alt="image-20220303142651251"></p>
<h1 id="Lecture-18-Future-of-NLP-Deep-Learning"><a href="#Lecture-18-Future-of-NLP-Deep-Learning" class="headerlink" title="Lecture 18 - Future of NLP + Deep Learning"></a>Lecture 18 - Future of NLP + Deep Learning</h1><iframe width="1217" height="685" src="https://www.youtube.com/embed/2t7Q9WVUaf8?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456172.png" alt="image-20220303145634077"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031456187.png" alt="image-20220303145648087"></p>
<h2 id="General-Representation-Learning-Recipe-0312"><a href="#General-Representation-Learning-Recipe-0312" class="headerlink" title="General Representation Learning Recipe(0312)"></a>General Representation Learning Recipe(0312)</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031458027.png" alt="image-20220303145813909"></p>
<p>Certain properties emerge only when we scale up the model size!</p>
<h2 id="Large-Language-Models-and-GPT-3-0358"><a href="#Large-Language-Models-and-GPT-3-0358" class="headerlink" title="Large Language Models and GPT-3(0358)"></a>Large Language Models and GPT-3(0358)</h2><h3 id="Large-Language-models-and-GPT-3-0514"><a href="#Large-Language-models-and-GPT-3-0514" class="headerlink" title="Large Language models and GPT-3(0514)"></a>Large Language models and GPT-3(0514)</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031501186.png" alt="image-20220303150148074"></p>
<h3 id="Whats-new-about-GPT-3"><a href="#Whats-new-about-GPT-3" class="headerlink" title="Whats new about GPT-3"></a>Whats new about GPT-3</h3><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502616.png" alt="image-20220303150225480"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031502821.png" alt="image-20220303150257686"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203031503577.png" alt="image-20220303150317443"></p>

        </div>
        
<blockquote class="copyright">
    <p><strong>Link to this article : </strong><a class="permalink" href="http://juggler.fun/NLP/NLP/">http://juggler.fun/NLP/NLP/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        

        
    </section>


    

	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	<span id="busuanzi_container_site_pv"><span id="busuanzi_value_site_pv"></span>  visits  |  </span>	
	<span id="busuanzi_container_site_uv"><span id="busuanzi_value_site_uv"></span>  visitors</span>
</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">Catalogue</h3>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abbreviation"><span class="toc-number">1.</span> <span class="toc-text">Abbreviation</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-1-Introduction-and-Word-Vectors"><span class="toc-number">2.</span> <span class="toc-text">Lecture 1 - Introduction and Word Vectors</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NLP"><span class="toc-number">2.1.</span> <span class="toc-text">NLP</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word2vec"><span class="toc-number">2.2.</span> <span class="toc-text">Word2vec</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Use-two-vector-in-one-word-centor-word-context-word"><span class="toc-number">2.2.1.</span> <span class="toc-text">Use two vector in one word: centor word context word.</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#softmax-function"><span class="toc-number">2.2.2.</span> <span class="toc-text">softmax function</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Train-the-model-gradient-descent"><span class="toc-number">2.2.3.</span> <span class="toc-text">Train the model: gradient descent</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Show-some-achievement-with-code-5640-h0516"><span class="toc-number">2.3.</span> <span class="toc-text">Show some achievement with code(5640-h0516)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QA"><span class="toc-number">2.4.</span> <span class="toc-text">QA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-2-Word-Vectors-Word-Senses-and-Neural-Classifiers"><span class="toc-number">3.</span> <span class="toc-text">Lecture 2 Word Vectors,Word Senses,and Neural Classifiers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Bag-models-0245"><span class="toc-number">3.1.</span> <span class="toc-text">Bag models (0245)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-descent-0600"><span class="toc-number">3.2.</span> <span class="toc-text">Gradient descent (0600)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#stochastic-gradient-descent-SGD-TOBELM-0920"><span class="toc-number">3.2.1.</span> <span class="toc-text">stochastic gradient descent SGD  TOBELM (0920)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#more-details-of-word2vec-1400"><span class="toc-number">3.3.</span> <span class="toc-text">more details of word2vec(1400)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SG-use-center-to-predict-context"><span class="toc-number">3.3.1.</span> <span class="toc-text">SG use center to predict context</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#SGNS-negative-sampling-ToBLO"><span class="toc-number">3.3.1.1.</span> <span class="toc-text">SGNS negative sampling  [ToBLO]</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CBOW-opposite"><span class="toc-number">3.3.2.</span> <span class="toc-text">CBOW opposite.</span></a></li><li class="toc-item toc-level-3"><a class="toc-link"><span class="toc-number">3.3.3.</span> <span class="toc-text"></span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-use-two-vectors-1500"><span class="toc-number">3.4.</span> <span class="toc-text">Why use two vectors(1500)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-not-capture-co-occurrence-counts-directly-2337"><span class="toc-number">3.5.</span> <span class="toc-text">Why not capture co-occurrence counts directly?(2337)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD-3230-ToL"><span class="toc-number">3.6.</span> <span class="toc-text">SVD(3230) [ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Count-based-vs-direct-prediction"><span class="toc-number">3.7.</span> <span class="toc-text">Count based vs direct prediction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Encoing-meaning-components-in-vector-differences-3948"><span class="toc-number">3.8.</span> <span class="toc-text">Encoing meaning components in vector differences(3948)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GloVe-4313"><span class="toc-number">3.9.</span> <span class="toc-text">GloVe (4313)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#How-to-evaluate-word-vectors-Intrinsic-vs-extrinsic-4756"><span class="toc-number">3.10.</span> <span class="toc-text">How to evaluate word vectors Intrinsic vs. extrinsic(4756)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Analogy-evaluation-and-hyperparameters-intrinsic-5515"><span class="toc-number">3.10.1.</span> <span class="toc-text">Analogy evaluation and hyperparameters (intrinsic)(5515)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-vector-distances-and-their-correlation-with-human-judgements-5640"><span class="toc-number">3.10.2.</span> <span class="toc-text">Word vector distances and their correlation with human judgements(5640)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Data-shows-that-300-dimensional-word-vector-is-good-5536"><span class="toc-number">3.11.</span> <span class="toc-text">Data shows that 300 dimensional word vector is good(5536)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-objective-function-for-the-GloVe-model-and-What-log-bilinear-means-5739"><span class="toc-number">3.12.</span> <span class="toc-text">The objective function for the GloVe model and What log-bilinear means(5739)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-senses-and-word-sense-ambiguity-h0353"><span class="toc-number">3.13.</span> <span class="toc-text">Word senses and word sense ambiguity(h0353)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-3-Gradients-by-hand-matric-calculus-and-algorithmically-the-backpropagation-algorithm-all-the-math-details-of-doing-nerual-net-learning"><span class="toc-number">4.</span> <span class="toc-text">Lecture 3  Gradients by hand(matric calculus) and algorithmically(the backpropagation algorithm) all the math details of doing nerual net learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Need-to-be-learn-again-it-is-not-totally-understanded"><span class="toc-number">4.1.</span> <span class="toc-text">Need to be learn again, it is not totally understanded.</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Named-Entity-Recognition-0530"><span class="toc-number">4.2.</span> <span class="toc-text">Named Entity Recognition(0530)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Simple-NER-0636"><span class="toc-number">4.3.</span> <span class="toc-text">Simple NER (0636)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#How-the-sample-model-run-0836"><span class="toc-number">4.3.1.</span> <span class="toc-text">How the sample model run (0836)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#update-equation-1220"><span class="toc-number">4.4.</span> <span class="toc-text">update equation(1220)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#jacobian-1811"><span class="toc-number">4.5.</span> <span class="toc-text">jacobian(1811)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Chain-Rule-2015"><span class="toc-number">4.6.</span> <span class="toc-text">Chain Rule(2015)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#do-one-example-step-2650"><span class="toc-number">4.7.</span> <span class="toc-text">do one example step (2650)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#-1"><span class="toc-number">4.8.</span> <span class="toc-text"></span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reusing-Computation-3402"><span class="toc-number">4.9.</span> <span class="toc-text">Reusing Computation(3402)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ds-x2F-dw"><span class="toc-number">4.9.1.</span> <span class="toc-text">ds&#x2F;dw</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Forward-and-backward-propagation-5000"><span class="toc-number">4.10.</span> <span class="toc-text">Forward and backward propagation(5000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#An-example-5507"><span class="toc-number">4.11.</span> <span class="toc-text">An example(5507)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compute-all-gradients-at-once-h0005"><span class="toc-number">4.12.</span> <span class="toc-text">Compute all gradients at once (h0005)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Back-prop-in-general-computation-graph-h0800-ToL"><span class="toc-number">4.13.</span> <span class="toc-text">Back-prop in general computation graph(h0800)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Automatic-Differentiation-h1346"><span class="toc-number">4.14.</span> <span class="toc-text">Automatic Differentiation(h1346)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Manual-Gradient-checking-Numeric-Gradient-h1900"><span class="toc-number">4.15.</span> <span class="toc-text">Manual Gradient checking : Numeric Gradient(h1900)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-4-Dependency-Parsing"><span class="toc-number">5.</span> <span class="toc-text">Lecture 4 Dependency Parsing</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Two-views-of-linguistic-structure"><span class="toc-number">5.1.</span> <span class="toc-text">Two views of linguistic structure</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Constituency-x3D-phrase-structure-grammar-x3D-context-free-grammars-CFGs-0331"><span class="toc-number">5.1.1.</span> <span class="toc-text">Constituency &#x3D; phrase structure grammar &#x3D; context-free grammars(CFGs)(0331)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dependency-structure-1449"><span class="toc-number">5.1.2.</span> <span class="toc-text">Dependency structure(1449)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-do-we-need-sentence-structure-2205"><span class="toc-number">5.2.</span> <span class="toc-text">Why do  we need sentence structure?(2205)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prepositional-phrase-attachment-ambiguity-2422"><span class="toc-number">5.3.</span> <span class="toc-text">Prepositional phrase attachment ambiguity.(2422)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#San-Jose-cops-kill-man-with-knife"><span class="toc-number">5.3.1.</span> <span class="toc-text">San Jose cops kill man with knife</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Coordination-scope-ambiguity-3614"><span class="toc-number">5.4.</span> <span class="toc-text">Coordination scope ambiguity(3614)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Adjectival-x2F-Adverbial-Modifier-Ambiguity-3755"><span class="toc-number">5.5.</span> <span class="toc-text">Adjectival&#x2F;Adverbial Modifier Ambiguity(3755)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Verb-Phrase-VP-attachment-ambiguity-4404"><span class="toc-number">5.6.</span> <span class="toc-text">Verb Phrase(VP) attachment ambiguity(4404)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dependency-Grammar-and-Dependency-structure-4355"><span class="toc-number">5.7.</span> <span class="toc-text">Dependency Grammar and Dependency structure(4355)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Will-add-a-fake-ROOT-for-handy"><span class="toc-number">5.7.1.</span> <span class="toc-text">Will add a fake ROOT for handy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dependency-Grammar-history-4742"><span class="toc-number">5.8.</span> <span class="toc-text">Dependency Grammar history(4742)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-rise-of-annotated-data-Universal-Dependency-tree-5100"><span class="toc-number">5.9.</span> <span class="toc-text">The rise of annotated data Universal Dependency tree(5100)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tree-bank-5400"><span class="toc-number">5.9.1.</span> <span class="toc-text">Tree bank(5400)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#how-to-build-parser-with-dependency-5738"><span class="toc-number">5.10.</span> <span class="toc-text">how to build parser with dependency(5738)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dependency-Parsing"><span class="toc-number">5.11.</span> <span class="toc-text">Dependency Parsing</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Projectivity-h0416"><span class="toc-number">5.11.1.</span> <span class="toc-text">Projectivity(h0416)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Methods-of-Dependency-Parsing-h0521"><span class="toc-number">5.12.</span> <span class="toc-text">Methods of Dependency Parsing(h0521)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Greedy-transition-based-parsing-h0621"><span class="toc-number">5.13.</span> <span class="toc-text">Greedy transition-based parsing(h0621)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Basic-transition-based-dependency-parser-h0808"><span class="toc-number">5.14.</span> <span class="toc-text">Basic transition-based dependency parser (h0808)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MaltParser-h1351-ToL"><span class="toc-number">5.15.</span> <span class="toc-text">MaltParser(h1351)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluation-of-Dependency-Parsing-h1845-ToL"><span class="toc-number">5.16.</span> <span class="toc-text">Evaluation of Dependency Parsing (h1845)[ToL]</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-5-Languages-models-and-Recurrent-Neural-Networks-RNNs"><span class="toc-number">6.</span> <span class="toc-text">Lecture-5 Languages models and Recurrent Neural Networks(RNNs)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#A-neural-dependency-parser-0624"><span class="toc-number">6.1.</span> <span class="toc-text">A neural dependency parser(0624)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Distributed-Representations-0945"><span class="toc-number">6.2.</span> <span class="toc-text">Distributed Representations(0945)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Learning-Classifier-are-non-linear-classifiers-1210"><span class="toc-number">6.3.</span> <span class="toc-text">Deep Learning Classifier are non-linear classifiers(1210)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Simple-feed-forward-neural-network-multi-class-classifier-1621"><span class="toc-number">6.4.</span> <span class="toc-text">Simple feed-forward neural network multi-class classifier (1621)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Neural-Dependency-Parser-Model-Architecture-1730"><span class="toc-number">6.5.</span> <span class="toc-text">Neural Dependency Parser Model Architecture(1730)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Graph-based-dependency-parsers-2044"><span class="toc-number">6.6.</span> <span class="toc-text">Graph-based dependency parsers (2044)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Regularization-amp-amp-Overfitting-2529"><span class="toc-number">6.7.</span> <span class="toc-text">Regularization &amp;&amp; Overfitting (2529)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dropout-3100-ToL"><span class="toc-number">6.8.</span> <span class="toc-text">Dropout (3100)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Vectorization-3333"><span class="toc-number">6.9.</span> <span class="toc-text">Vectorization(3333)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Non-linearities-4000"><span class="toc-number">6.10.</span> <span class="toc-text">Non-linearities (4000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parameter-Initialization-4357"><span class="toc-number">6.11.</span> <span class="toc-text">Parameter Initialization (4357)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Optimizers-4617"><span class="toc-number">6.12.</span> <span class="toc-text">Optimizers(4617)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-Rates-4810"><span class="toc-number">6.13.</span> <span class="toc-text">Learning Rates(4810)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Language-Modeling-5036"><span class="toc-number">6.14.</span> <span class="toc-text">Language Modeling (5036)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#n-gram-Language-Models-5356"><span class="toc-number">6.15.</span> <span class="toc-text">n-gram Language Models(5356)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Sparsity-Problems-5922"><span class="toc-number">6.16.</span> <span class="toc-text">Sparsity Problems (5922)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Storage-Problems-h0117"><span class="toc-number">6.17.</span> <span class="toc-text">Storage Problems(h0117)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#How-to-build-a-neural-language-model-h0609"><span class="toc-number">6.18.</span> <span class="toc-text">How to build a neural language model(h0609)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-fixed-window-neural-Language-Model-h1100"><span class="toc-number">6.19.</span> <span class="toc-text">A fixed-window neural Language Model(h1100)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recurrent-Neural-Network-RNN-h1250"><span class="toc-number">6.20.</span> <span class="toc-text">Recurrent Neural Network (RNN)(h1250)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#A-Simple-RNN-Language-Model-h1430"><span class="toc-number">6.21.</span> <span class="toc-text">A Simple RNN Language Model(h1430)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-6-Simple-and-LSTM-Recurrent-Neural-Networks"><span class="toc-number">7.</span> <span class="toc-text">Lecture 6 Simple and LSTM Recurrent Neural Networks.</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Simple-RNN-Language-Model-0310"><span class="toc-number">7.1.</span> <span class="toc-text">The Simple RNN Language Model (0310)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-an-RNN-Language-Model-0818"><span class="toc-number">7.2.</span> <span class="toc-text">Training an RNN Language Model (0818)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Teacher-Forcing"><span class="toc-number">7.2.1.</span> <span class="toc-text">Teacher Forcing</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluating-Language-Models-2447-ToL"><span class="toc-number">7.3.</span> <span class="toc-text">Evaluating Language Models (2447)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Language-Model-is-a-system-that-predicts-the-next-word-3130"><span class="toc-number">7.4.</span> <span class="toc-text">Language Model is a  system that predicts the next word(3130)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-use-of-RNN-3229"><span class="toc-number">7.5.</span> <span class="toc-text">Other use of RNN(3229)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Tag-for-word"><span class="toc-number">7.5.1.</span> <span class="toc-text">Tag for word</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Used-for-classification-3420"><span class="toc-number">7.5.2.</span> <span class="toc-text">Used for classification(3420)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Used-to-Language-encoder-module-3500"><span class="toc-number">7.5.3.</span> <span class="toc-text">Used to Language encoder module (3500)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Used-to-generate-text-3600"><span class="toc-number">7.5.4.</span> <span class="toc-text">Used to generate text (3600)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Problems-with-Vanishing-and-Exploding-Gradients-3750-IMPORTANT"><span class="toc-number">7.6.</span> <span class="toc-text">Problems with Vanishing and Exploding Gradients(3750)[IMPORTANT]</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Why-This-is-a-problem-4400"><span class="toc-number">7.6.1.</span> <span class="toc-text">Why This is a  problem (4400)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Long-Short-Term-Memory-RNNS-LSTMS-5000-ToL"><span class="toc-number">7.7.</span> <span class="toc-text">Long Short Term Memory RNNS(LSTMS)(5000)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bidirectional-RNN-h2000"><span class="toc-number">7.8.</span> <span class="toc-text">Bidirectional RNN (h2000)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-7-Translation-Seq2Seq-Attention"><span class="toc-number">8.</span> <span class="toc-text">Lecture-7 Translation, Seq2Seq, Attention</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Machine-Translation-0245"><span class="toc-number">8.1.</span> <span class="toc-text">Machine Translation(0245)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#What-do-you-need-1200"><span class="toc-number">8.1.1.</span> <span class="toc-text">What do you need (1200)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decoding-for-SMT-1748"><span class="toc-number">8.2.</span> <span class="toc-text">Decoding for SMT(1748)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-Neural-Machine-Translation-NMT-2130"><span class="toc-number">8.3.</span> <span class="toc-text">What is Neural Machine Translation(NMT)(2130)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Seq2seq-is-more-than-MT-2600"><span class="toc-number">8.4.</span> <span class="toc-text">Seq2seq is more than MT(2600)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2732-ToL"><span class="toc-number">8.5.</span> <span class="toc-text">(2732)[ToL]</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi-layer-RNNs-3323"><span class="toc-number">8.6.</span> <span class="toc-text">Multi-layer RNNs(3323)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Greedy-decoding-4000"><span class="toc-number">8.7.</span> <span class="toc-text">Greedy decoding(4000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Exhaustive-search-decoding-4200"><span class="toc-number">8.8.</span> <span class="toc-text">Exhaustive search decoding(4200)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#beam-search-decoding-4400"><span class="toc-number">8.9.</span> <span class="toc-text">beam search decoding(4400)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#How-do-we-evaluate-Machine-Translation-5550"><span class="toc-number">8.10.</span> <span class="toc-text">How do we evaluate Machine Translation(5550)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#BLEU"><span class="toc-number">8.10.1.</span> <span class="toc-text">BLEU</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NMT-perhaps-the-biggest-success-story-of-NLP-Deep-Learning-h00000"><span class="toc-number">8.11.</span> <span class="toc-text">NMT perhaps the biggest success story of NLP Deep Learning(h00000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Attention-h1300"><span class="toc-number">8.12.</span> <span class="toc-text">Attention(h1300)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-8-Final-Projects-Practical-Tips"><span class="toc-number">9.</span> <span class="toc-text">Lecture 8  Final Projects; Practical Tips</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Sequence-to-Sequence-with-attention-0235"><span class="toc-number">9.1.</span> <span class="toc-text">Sequence to Sequence with attention(0235)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Attention-in-equations-0800"><span class="toc-number">9.2.</span> <span class="toc-text">Attention: in equations(0800)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#there-are-several-attention-variants-1500"><span class="toc-number">9.3.</span> <span class="toc-text">there are several attention variants(1500)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Attention-is-a-general-Deep-Learning-technique-2240"><span class="toc-number">9.4.</span> <span class="toc-text">Attention is a general Deep Learning technique(2240)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Final-Project-3000"><span class="toc-number">9.5.</span> <span class="toc-text">Final Project(3000)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-9-Self-Attention-and-Transformers"><span class="toc-number">10.</span> <span class="toc-text">Lecture-9  Self- Attention and Transformers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Issues-with-recurrent-models-0434"><span class="toc-number">10.1.</span> <span class="toc-text">Issues with recurrent models (0434)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Linear-interaction-distance"><span class="toc-number">10.1.1.</span> <span class="toc-text">Linear interaction distance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Lack-of-parallelizability-0723"><span class="toc-number">10.1.2.</span> <span class="toc-text">Lack of parallelizability(0723)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#If-not-recurrence"><span class="toc-number">10.2.</span> <span class="toc-text">If not recurrence</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Word-window-models-aggregate-local-contexts-1031"><span class="toc-number">10.2.1.</span> <span class="toc-text">Word window models aggregate local contexts (1031)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attention-1406"><span class="toc-number">10.2.2.</span> <span class="toc-text">Attention(1406)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Self-Attention-1638"><span class="toc-number">10.3.</span> <span class="toc-text">Self-Attention(1638)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Self-attention-as-an-nlp-building-block-2222"><span class="toc-number">10.4.</span> <span class="toc-text">Self-attention as an nlp building block(2222)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fix-the-first-self-attention-problem"><span class="toc-number">10.5.</span> <span class="toc-text">Fix the first self-attention problem</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#sequence-order-2423"><span class="toc-number">10.5.1.</span> <span class="toc-text">sequence order (2423)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Position-representation-vector-through-sinusoids-2624"><span class="toc-number">10.5.1.1.</span> <span class="toc-text">Position representation vector through sinusoids(2624)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Sinusoidal-position-representations-2730"><span class="toc-number">10.5.1.1.1.</span> <span class="toc-text">Sinusoidal position representations(2730)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Position-representation-vector-from-scratch-2830"><span class="toc-number">10.5.1.1.2.</span> <span class="toc-text">Position representation vector from scratch(2830)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Adding-nonlinearities-in-self-attention-2953"><span class="toc-number">10.5.2.</span> <span class="toc-text">Adding nonlinearities in self-attention(2953)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Barriers-and-solutions-for-Self-Attention-as-building-block-2945"><span class="toc-number">10.6.</span> <span class="toc-text">Barriers and solutions for Self-Attention as building block(2945)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-transformer-encoder-decoder-3638"><span class="toc-number">10.7.</span> <span class="toc-text">The transformer encoder-decoder(3638)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#key-query-value-4000"><span class="toc-number">10.7.1.</span> <span class="toc-text">key query value(4000)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-headed-attention-4322"><span class="toc-number">10.7.2.</span> <span class="toc-text">Multi-headed attention (4322)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Residual-connections-4723"><span class="toc-number">10.8.</span> <span class="toc-text">Residual connections(4723)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Layer-normalization-5045"><span class="toc-number">10.9.</span> <span class="toc-text">Layer normalization(5045)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scaled-fot-product-5415"><span class="toc-number">10.10.</span> <span class="toc-text">Scaled fot product(5415)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-10-Transformers-and-Pretraining"><span class="toc-number">11.</span> <span class="toc-text">Lecture 10 - Transformers and Pretraining</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Word-structure-and-subword-models-0300"><span class="toc-number">11.1.</span> <span class="toc-text">Word structure and subword models(0300)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-byte-pair-encoding-0659"><span class="toc-number">11.2.</span> <span class="toc-text">The byte-pair encoding(0659)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivating-word-meaning-and-context-1556"><span class="toc-number">11.3.</span> <span class="toc-text">Motivating word meaning and context(1556)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pretraining-whole-models-2000"><span class="toc-number">11.4.</span> <span class="toc-text">Pretraining whole models(2000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#this-model-haven%E2%80%99t-met-overfitting-now-you-can-save-some-data-to-test-it-2811"><span class="toc-number">11.5.</span> <span class="toc-text">this model havent met overfitting now, you can save some data to test it.(2811)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#transformers-for-encoding-and-decoding-3030"><span class="toc-number">11.6.</span> <span class="toc-text">transformers for encoding and decoding (3030)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pretraining-through-language-modeling-3400"><span class="toc-number">11.7.</span> <span class="toc-text">Pretraining through language modeling(3400)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Stochastic-gradient-descent-and-pretrain-x2F-finetune-3740"><span class="toc-number">11.8.</span> <span class="toc-text">Stochastic gradient descent and pretrain&#x2F;finetune(3740)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-pretraining-has-three-ways-4021"><span class="toc-number">11.9.</span> <span class="toc-text">Model pretraining has three ways (4021)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoder-4300"><span class="toc-number">11.9.1.</span> <span class="toc-text">Decoder(4300)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Generative-Pretrained-Transformer-GPT-4818"><span class="toc-number">11.10.</span> <span class="toc-text">Generative Pretrained Transformer(GPT) (4818)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPT2-5400"><span class="toc-number">11.11.</span> <span class="toc-text">GPT2(5400)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pretraining-Encoding-5545"><span class="toc-number">11.12.</span> <span class="toc-text">Pretraining Encoding(5545)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Bert-5654"><span class="toc-number">11.12.1.</span> <span class="toc-text">(Bert)(5654)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bidirectional-encoder-representations-from-transformers-h0100"><span class="toc-number">11.13.</span> <span class="toc-text">Bidirectional encoder representations from transformers(h0100)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Limitations-of-pretrained-encoders-h0900"><span class="toc-number">11.14.</span> <span class="toc-text">Limitations of pretrained encoders(h0900)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extensions-of-BERT-h1000"><span class="toc-number">11.15.</span> <span class="toc-text">Extensions of BERT(h1000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pretraining-Encoder-Decoder-h1200"><span class="toc-number">11.16.</span> <span class="toc-text">Pretraining Encoder-Decoder (h1200)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#T5-h1500"><span class="toc-number">11.16.1.</span> <span class="toc-text">T5(h1500)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GPT3-h1800"><span class="toc-number">11.17.</span> <span class="toc-text">GPT3(h1800)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Lecture-11-Question-Answering"><span class="toc-number">11.18.</span> <span class="toc-text">Lecture 11 Question Answering</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-question-answering-0414"><span class="toc-number">11.19.</span> <span class="toc-text">What is question answering(0414)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Beyond-textual-QA-problems-1100"><span class="toc-number">11.20.</span> <span class="toc-text">Beyond textual QA problems(1100)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reading-comprehension-1223"><span class="toc-number">11.21.</span> <span class="toc-text">Reading comprehension(1223)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Standord-question-answering-dataset-1815"><span class="toc-number">11.22.</span> <span class="toc-text">Standord question answering dataset (1815)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Neural-models-for-reading-comprehension-2428"><span class="toc-number">11.23.</span> <span class="toc-text">Neural models for reading comprehension(2428)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM-based-vs-BERT-models-2713"><span class="toc-number">11.24.</span> <span class="toc-text">LSTM-based vs BERT models (2713)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BiDAF-3200"><span class="toc-number">11.25.</span> <span class="toc-text">BiDAF(3200)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Encoding-3200"><span class="toc-number">11.25.1.</span> <span class="toc-text">Encoding(3200)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Attention-3400"><span class="toc-number">11.25.2.</span> <span class="toc-text">Attention(3400)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Modeling-and-output-layers-4640"><span class="toc-number">11.25.3.</span> <span class="toc-text">Modeling and output layers(4640)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BERT-for-reading-comprehension-5227"><span class="toc-number">11.26.</span> <span class="toc-text">BERT for reading comprehension (5227)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Comparisons-between-BiDAF-and-BERT-models-2734"><span class="toc-number">11.27.</span> <span class="toc-text">Comparisons between BiDAF and BERT models(2734)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Can-we-design-better-pre-training-objectives-h0000"><span class="toc-number">11.28.</span> <span class="toc-text">Can we design better pre-training objectives(h0000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#open-domain-question-answering-h1000"><span class="toc-number">11.29.</span> <span class="toc-text">open domain question answering(h1000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DPR-H1400"><span class="toc-number">11.30.</span> <span class="toc-text">DPR(H1400)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DensePhrase-Demo-h1800"><span class="toc-number">11.31.</span> <span class="toc-text">DensePhrase:Demo(h1800)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-12-Natural-Language-Generation-ToL"><span class="toc-number">12.</span> <span class="toc-text">Lecture 12 - Natural Language Generation[ToL]</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-neural-language-generation-0300"><span class="toc-number">12.1.</span> <span class="toc-text">What is neural language generation?(0300)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Components-of-NLG-Systems-0845"><span class="toc-number">12.2.</span> <span class="toc-text">Components of NLG Systems(0845)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Basic-of-natural-language-generation-0916"><span class="toc-number">12.2.1.</span> <span class="toc-text">Basic of natural language generation(0916)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#A-look-at-a-single-step-1024"><span class="toc-number">12.2.2.</span> <span class="toc-text">A look at a single step(1024)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#then-select-and-train-1115"><span class="toc-number">12.2.3.</span> <span class="toc-text">then  select and train(1115)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Decoding-1317"><span class="toc-number">12.3.</span> <span class="toc-text">Decoding(1317)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Greedy-methods-1432"><span class="toc-number">12.3.1.</span> <span class="toc-text">Greedy methods(1432)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Greedy-methods-get-repetitive-1545"><span class="toc-number">12.3.2.</span> <span class="toc-text">Greedy methods get repetitive(1545)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#why-do-repetition-happen-1613"><span class="toc-number">12.3.3.</span> <span class="toc-text">why do repetition happen(1613)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#How-can-we-reduce-repetition-1824-ToL"><span class="toc-number">12.3.4.</span> <span class="toc-text">How can we reduce repetition (1824)[ToL]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#People-is-not-always-choose-the-greedy-methods-1930"><span class="toc-number">12.3.5.</span> <span class="toc-text">People is not always choose the greedy methods(1930)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Time-to-get-random-Sampling-2047"><span class="toc-number">12.3.6.</span> <span class="toc-text">Time to get random: Sampling(2047)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoding-Top-k-sampling-2100"><span class="toc-number">12.3.7.</span> <span class="toc-text">Decoding : Top-k sampling(2100)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Issues-with-Top-k-sampling-2339"><span class="toc-number">12.3.8.</span> <span class="toc-text">Issues with Top-k sampling(2339)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoding-Top-p-nucleus-sampling-2421"><span class="toc-number">12.3.9.</span> <span class="toc-text">Decoding: Top-p(nucleus)sampling(2421)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scaling-randomness-Softmax-temperature-2500-ToL"><span class="toc-number">12.3.10.</span> <span class="toc-text">Scaling randomness: Softmax temperature (2500)[ToL]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#improving-decoding-re-balancing-distributions-2710"><span class="toc-number">12.3.11.</span> <span class="toc-text">improving decoding: re-balancing distributions(2710)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Backpropagation-based-distribution-re-balancing-3027"><span class="toc-number">12.3.12.</span> <span class="toc-text">Backpropagation-based distribution re-balancing(3027)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Improving-Decoding-Re-ranking-3300-ToL"><span class="toc-number">12.3.13.</span> <span class="toc-text">Improving Decoding: Re-ranking(3300)[ToL]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoding-Takeaways-3540"><span class="toc-number">12.3.14.</span> <span class="toc-text">Decoding: Takeaways(3540)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-NLG-models-4114"><span class="toc-number">12.4.</span> <span class="toc-text">Training  NLG models(4114)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Maximum-Likelihood-Training-4200"><span class="toc-number">12.4.1.</span> <span class="toc-text">Maximum Likelihood Training(4200)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Unlikelihood-Training-4427-ToL"><span class="toc-number">12.4.2.</span> <span class="toc-text">Unlikelihood Training(4427)[ToL]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Exposure-Bias-4513-ToL"><span class="toc-number">12.4.3.</span> <span class="toc-text">Exposure Bias(4513)[ToL]</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Exposure-Bias-Solutions-4645"><span class="toc-number">12.4.4.</span> <span class="toc-text">Exposure Bias Solutions(4645)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reinforce-Basics-4900"><span class="toc-number">12.4.5.</span> <span class="toc-text">Reinforce Basics(4900)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reward-Estimation-5020"><span class="toc-number">12.4.6.</span> <span class="toc-text">Reward Estimation(5020)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reinforce%E2%80%99s-dark-side-5300"><span class="toc-number">12.4.7.</span> <span class="toc-text">reinforces dark side(5300)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-Takeways-5423"><span class="toc-number">12.4.8.</span> <span class="toc-text">Training: Takeways(5423)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluating-NLG-Systems-5613"><span class="toc-number">12.5.</span> <span class="toc-text">Evaluating NLG Systems(5613)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Types-of-evaluation-methods-for-text-generation-5734"><span class="toc-number">12.6.</span> <span class="toc-text">Types of evaluation methods for text generation(5734)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Content-Overlap-metrics-5800"><span class="toc-number">12.6.1.</span> <span class="toc-text">Content Overlap metrics(5800)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#A-simple-failure-case-5900"><span class="toc-number">12.6.2.</span> <span class="toc-text">A simple failure case(5900)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Semantic-overlap-metrics-h0100"><span class="toc-number">12.6.3.</span> <span class="toc-text">Semantic overlap metrics(h0100)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Model-based-metrics-h0120"><span class="toc-number">12.6.4.</span> <span class="toc-text">Model-based metrics(h0120)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#word-distance-functions-h0234"><span class="toc-number">12.6.4.1.</span> <span class="toc-text">word distance functions(h0234)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Beyond-word-matching-h0350"><span class="toc-number">12.6.4.2.</span> <span class="toc-text">Beyond word matching(h0350)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Human-evaluations-h0433"><span class="toc-number">12.6.5.</span> <span class="toc-text">Human evaluations(h0433)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Issues-h0700"><span class="toc-number">12.6.5.1.</span> <span class="toc-text">Issues(h0700)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Takeways-h0912"><span class="toc-number">12.6.6.</span> <span class="toc-text">Takeways(h0912)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ethical-Considerations-h1025"><span class="toc-number">12.7.</span> <span class="toc-text">Ethical Considerations(h1025)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-13-Coreference-Resolution"><span class="toc-number">13.</span> <span class="toc-text">Lecture 13 - Coreference Resolution</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-Coreference-Resolution-0604"><span class="toc-number">13.1.</span> <span class="toc-text">What is Coreference Resolution?(0604)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Applications-1712"><span class="toc-number">13.2.</span> <span class="toc-text">Applications (1712)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Coreference-Resolution-in-Two-steps-1947"><span class="toc-number">13.3.</span> <span class="toc-text">Coreference Resolution in Two steps(1947)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Mention-Detection-2049"><span class="toc-number">13.4.</span> <span class="toc-text">Mention Detection(2049)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Not-quite-so-simple-2255"><span class="toc-number">13.4.1.</span> <span class="toc-text">Not quite so simple(2255)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Avoiding-a-traditional-pipeline-system-2811"><span class="toc-number">13.5.</span> <span class="toc-text">Avoiding a traditional pipeline system(2811)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Onto-Coreference-First-some-linguistics-3035"><span class="toc-number">13.6.</span> <span class="toc-text">Onto Coreference! First, some linguistics (3035)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#not-all-anaphoric-relations-are-coreferential-3349"><span class="toc-number">13.6.1.</span> <span class="toc-text">not all anaphoric relations are coreferential (3349)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Anaphora-vs-Cataphora-3610"><span class="toc-number">13.7.</span> <span class="toc-text">Anaphora vs Cataphora(3610)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Taking-stock-3801"><span class="toc-number">13.8.</span> <span class="toc-text">Taking stock (3801)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Four-kinds-of-coreference-Models-4018"><span class="toc-number">13.9.</span> <span class="toc-text">Four kinds of coreference Models(4018)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Traditional-pronominal-anaphora-resolution-Hobbs%E2%80%99s-naive-algorithm-4130"><span class="toc-number">13.10.</span> <span class="toc-text">Traditional pronominal anaphora resolution:Hobbss naive algorithm(4130)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-based-Pronominal-Coreference-4820"><span class="toc-number">13.11.</span> <span class="toc-text">Knowledge-based Pronominal Coreference(4820)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Coreference-Models-Mention-Pair-5624"><span class="toc-number">13.12.</span> <span class="toc-text">Coreference Models: Mention Pair(5624)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Mention-Pair-Test-Time-5800"><span class="toc-number">13.12.1.</span> <span class="toc-text">Mention Pair Test Time(5800)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Disadvantage-5953"><span class="toc-number">13.12.2.</span> <span class="toc-text">Disadvantage(5953)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Coreference-Models-Mention-Ranking-h0050"><span class="toc-number">13.13.</span> <span class="toc-text">Coreference Models: Mention Ranking(h0050)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolutional-Neural-Nets-h0341"><span class="toc-number">13.14.</span> <span class="toc-text">Convolutional Neural Nets(h0341)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-convolution-anyway-h0452"><span class="toc-number">13.15.</span> <span class="toc-text">What is convolution anyway?(h0452)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#End-to-End-Neural-Coref-Model-h1206"><span class="toc-number">13.16.</span> <span class="toc-text">End-to-End Neural Coref Model(h1206)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion-h2017"><span class="toc-number">13.17.</span> <span class="toc-text">Conclusion (h2017)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-14-T5-and-Large-Language-Models"><span class="toc-number">14.</span> <span class="toc-text">Lecture 14 - T5 and Large Language Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#T5-with-a-task-prefix-0800"><span class="toc-number">14.1.</span> <span class="toc-text">T5 with a task prefix(0800)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Others"><span class="toc-number">14.2.</span> <span class="toc-text">Others</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#STSB"><span class="toc-number">14.2.1.</span> <span class="toc-text">STSB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Summarize"><span class="toc-number">14.2.2.</span> <span class="toc-text">Summarize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#T5-change-little-from-original-transformer-1300"><span class="toc-number">14.3.</span> <span class="toc-text">T5 change little from original transformer(1300)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#what-should-my-pre-training-data-set-be-1325"><span class="toc-number">14.4.</span> <span class="toc-text">what should my pre-training data set be?(1325)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Then-is-how-to-train-from-a-start-1659"><span class="toc-number">14.5.</span> <span class="toc-text">Then is how to train from a start(1659)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pretrain-1805"><span class="toc-number">14.6.</span> <span class="toc-text">pretrain(1805)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#choose-the-model-2412"><span class="toc-number">14.7.</span> <span class="toc-text">choose the model(2412)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pre-training-objective-2629"><span class="toc-number">14.8.</span> <span class="toc-text">pre-training objective(2629)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#different-structure-of-data-source-2822"><span class="toc-number">14.9.</span> <span class="toc-text">different structure of data source(2822)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Multi-task-learning-3443"><span class="toc-number">14.10.</span> <span class="toc-text">Multi task learning (3443)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#close-the-gap-between-multi-task-training-and-this-pre-training-followed-by-separate-fine-tuning-3621"><span class="toc-number">14.11.</span> <span class="toc-text">close the gap between multi-task training and this pre-training followed by separate fine tuning(3621)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-if-it-happens-there-are-four-times-computes-as-much-as-before-3737"><span class="toc-number">14.12.</span> <span class="toc-text">What if it happens there are four times computes as much as before  (3737)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview-3840"><span class="toc-number">14.13.</span> <span class="toc-text">Overview(3840)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-about-all-of-the-other-languages-mT5-4735"><span class="toc-number">14.14.</span> <span class="toc-text">What about all of the other languages?(mT5)(4735)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#XTREME-5000"><span class="toc-number">14.15.</span> <span class="toc-text">XTREME (5000)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#How-much-knowledge-does-a-language-model-pick-up-during-pre-training-5225"><span class="toc-number">14.16.</span> <span class="toc-text">How much knowledge does a language model pick up during pre-training?(5225)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Salient-span-masking-5631"><span class="toc-number">14.17.</span> <span class="toc-text">Salient span masking (5631)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Do-large-language-models-memorize-their-training-data-h0100"><span class="toc-number">14.18.</span> <span class="toc-text">Do large language models memorize their training data(h0100)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Can-we-close-the-gap-between-large-and-small-models-by-improving-the-transformer-architecture-h1010"><span class="toc-number">14.19.</span> <span class="toc-text">Can we close the gap between large and small models by improving the transformer architecture(h1010)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#QA-h1915"><span class="toc-number">14.20.</span> <span class="toc-text">QA(h1915)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-15-Add-Knowledge-to-Language-Models"><span class="toc-number">15.</span> <span class="toc-text">Lecture 15 - Add Knowledge to Language Models</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Recap-LM-0232"><span class="toc-number">15.1.</span> <span class="toc-text">Recap: LM(0232)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What-does-a-language-model-know-0423"><span class="toc-number">15.2.</span> <span class="toc-text">What does a language model know?(0423)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#The-importance-of-know-ledge-aware-language-models-0700"><span class="toc-number">15.3.</span> <span class="toc-text">The importance of know ledge-aware language models(0700)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Query-traditional-knowledge-bases-0750"><span class="toc-number">15.4.</span> <span class="toc-text">Query traditional knowledge bases(0750)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Query-language-models-as-knowledge-bases-0955"><span class="toc-number">15.5.</span> <span class="toc-text">Query language models as knowledge bases(0955)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compare-and-disadvantage-1010"><span class="toc-number">15.6.</span> <span class="toc-text">Compare and disadvantage(1010)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Techniques-to-add-knowledge-to-LMs-130"><span class="toc-number">15.7.</span> <span class="toc-text">Techniques to add knowledge to LMs(130)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Add-pretrained-embeddings-1403"><span class="toc-number">15.8.</span> <span class="toc-text">Add pretrained embeddings(1403)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Aside-What-is-entity-linking-1516"><span class="toc-number">15.9.</span> <span class="toc-text">Aside: What is entity linking?(1516)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Method-1-Add-pretrained-entity-embeddings-1815"><span class="toc-number">15.10.</span> <span class="toc-text">Method 1: Add pretrained entity embeddings(1815)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#How-to-we-incorporate-pretrained-entity-embeddings-from-a-different-embedding-space-2000"><span class="toc-number">15.10.1.</span> <span class="toc-text">How to we incorporate pretrained entity embeddings from  a different embedding space?(2000)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ERNIE-Enhanced-language-representation-with-informative-entities-2143"><span class="toc-number">15.11.</span> <span class="toc-text">ERNIE: Enhanced language representation with informative entities(2143)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#strengths-amp-remaining-challenges-2610"><span class="toc-number">15.11.1.</span> <span class="toc-text">strengths &amp; remaining challenges(2610)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Jointly-learn-to-link-entities-with-KnowBERT-2958"><span class="toc-number">15.12.</span> <span class="toc-text">Jointly learn to link entities with KnowBERT(2958)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Use-an-external-memory-3140"><span class="toc-number">15.13.</span> <span class="toc-text">Use an external memory(3140)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#KGLM-3355"><span class="toc-number">15.13.1.</span> <span class="toc-text">KGLM(3355)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-knowledge-and-full-knowledge"><span class="toc-number">15.13.2.</span> <span class="toc-text">Local knowledge and full knowledge</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#When-should-the-model-use-the-external-knowledge-3600"><span class="toc-number">15.13.3.</span> <span class="toc-text">When should the model use the external knowledge(3600)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Compare-to-the-others-4334"><span class="toc-number">15.14.</span> <span class="toc-text">Compare to the others(4334)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#More-recent-takes-Nearest-Neighbor-Language-Models-kNN-LM-4730"><span class="toc-number">15.15.</span> <span class="toc-text">More recent takes: Nearest Neighbor Language Models(kNN-LM)(4730)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Modify-the-training-data-5230"><span class="toc-number">15.16.</span> <span class="toc-text">Modify the training data(5230)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#WKLM-5458"><span class="toc-number">15.17.</span> <span class="toc-text">WKLM(5458)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learn-inductive-biases-through-masking-5811"><span class="toc-number">15.18.</span> <span class="toc-text">Learn inductive biases through masking(5811)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Salient-span-masking-5927"><span class="toc-number">15.19.</span> <span class="toc-text">Salient span masking(5927)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recap-h0053"><span class="toc-number">15.20.</span> <span class="toc-text">Recap(h0053)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluating-knowledge-in-LMS-h0211"><span class="toc-number">15.21.</span> <span class="toc-text">Evaluating knowledge in LMS(h0211)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LAMA-h0250"><span class="toc-number">15.21.1.</span> <span class="toc-text">LAMA(h0250)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-limitations-h0650"><span class="toc-number">15.21.2.</span> <span class="toc-text">The limitations (h0650)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LAMA-UnHelpful-Names-LAMA-UHN"><span class="toc-number">15.22.</span> <span class="toc-text">LAMA_UnHelpful Names(LAMA-UHN)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Developing-better-prompts-to-query-knowledge-in-LMS"><span class="toc-number">15.22.1.</span> <span class="toc-text">Developing better prompts to query knowledge in LMS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Knowledge-driven-downstream-tasks-h1253"><span class="toc-number">15.22.2.</span> <span class="toc-text">Knowledge-driven downstream tasks(h1253)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Relation-extraction-performance-on-TACED-h1400"><span class="toc-number">15.23.</span> <span class="toc-text">Relation extraction performance on TACED(h1400)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Entity-typing-performance-on-Open-Entuty"><span class="toc-number">15.24.</span> <span class="toc-text">Entity typing performance on Open Entuty</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recap-Evaluating-knowledge-in-LMs-h1600"><span class="toc-number">15.25.</span> <span class="toc-text">Recap: Evaluating knowledge in LMs(h1600)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-exciting-progress-amp-what%E2%80%99s-next-h1652"><span class="toc-number">15.26.</span> <span class="toc-text">Other exciting progress &amp; whats next?(h1652)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-17-Model-Analysis-and-Explanation"><span class="toc-number">16.</span> <span class="toc-text">Lecture 17 - Model Analysis and Explanation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Motivation"><span class="toc-number">16.1.</span> <span class="toc-text">Motivation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#what-are-our-models-doing-0415"><span class="toc-number">16.1.1.</span> <span class="toc-text">what are our models doing(0415)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#how-do-we-make-tomorrow%E2%80%99s-model-0515"><span class="toc-number">16.1.2.</span> <span class="toc-text">how do we make tomorrows model?(0515)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What-biases-are-built-into-model-0700"><span class="toc-number">16.1.3.</span> <span class="toc-text">What biases are built into model?(0700)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#how-do-we-make-in-the-following-25years-0800"><span class="toc-number">16.1.4.</span> <span class="toc-text">how do we make in the following 25years(0800)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-analysis-at-varying-levels-of-abstraction-0904"><span class="toc-number">16.2.</span> <span class="toc-text">Model analysis at varying levels of abstraction(0904)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-evaluation-as-model-analysis-1117"><span class="toc-number">16.3.</span> <span class="toc-text">Model evaluation as model analysis(1117)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-evaluation-as-model-analysis-in-natural-language-inference-1344"><span class="toc-number">16.4.</span> <span class="toc-text">Model evaluation as model analysis in natural language inference(1344)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#What-if-the-model-is-simple-using-heuristics-to-get-good-accuracy-1558"><span class="toc-number">16.4.1.</span> <span class="toc-text">What if the model is simple using heuristics to get good accuracy?(1558)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Language-models-as-linguistic-test-subjects-2023"><span class="toc-number">16.5.</span> <span class="toc-text">Language models as linguistic test subjects(2023)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Careful-test-sets-as-unit-test-suites-CheckListing-3230"><span class="toc-number">16.6.</span> <span class="toc-text">Careful  test sets as unit test suites: CheckListing(3230)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fitting-the-dataset-vs-learning-the-task-3500"><span class="toc-number">16.7.</span> <span class="toc-text">Fitting the dataset vs learning the task(3500)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Knowledge-evaluation-as-model-analysis-3642"><span class="toc-number">16.8.</span> <span class="toc-text">Knowledge evaluation as model analysis(3642)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Input-influence-does-my-model-really-use-long-distance-context-3822"><span class="toc-number">16.9.</span> <span class="toc-text">Input influence: does my model really use long-distance context?(3822)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction-explanations-what-in-the-input-led-to-this-output-4054"><span class="toc-number">16.10.</span> <span class="toc-text">Prediction explanations: what in the input led to this output?(4054)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction-explanations-simple-saliency-maps-4230"><span class="toc-number">16.11.</span> <span class="toc-text">Prediction explanations: simple saliency maps(4230)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Explanation-by-input-reduction-4607"><span class="toc-number">16.12.</span> <span class="toc-text">Explanation by input reduction (4607)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Analyzing-models-by-breaking-them-5106"><span class="toc-number">16.13.</span> <span class="toc-text">Analyzing models by breaking them(5106)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Are-models-robust-to-noise-in-their-input-5518"><span class="toc-number">16.14.</span> <span class="toc-text">Are models robust to noise in their input?(5518)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Analysis-of-%E2%80%9Cinterpretable%E2%80%9D-architecture-components-5719"><span class="toc-number">16.15.</span> <span class="toc-text">Analysis of interpretable architecture components(5719)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Probing-supervised-analysis-of-neural-networks-h0408"><span class="toc-number">16.16.</span> <span class="toc-text">Probing: supervised analysis of neural networks(h0408)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Emergent-simple-structure-in-neural-networks-h1019"><span class="toc-number">16.17.</span> <span class="toc-text">Emergent simple structure in neural networks(h1019)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Probing-tress-simply-recoverable-from-BERT-representations-h1136"><span class="toc-number">16.18.</span> <span class="toc-text">Probing: tress simply recoverable from BERT representations(h1136)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Final-thoughts-on-probing-and-correlation-studies-h1341"><span class="toc-number">16.19.</span> <span class="toc-text">Final thoughts on probing and correlation studies(h1341)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Recasting-model-tweaks-and-ablations-as-analysis-h1406"><span class="toc-number">16.20.</span> <span class="toc-text">Recasting model tweaks and ablations as analysis(h1406)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Ablation-analysis-do-we-need-all-these-attension-heads-h1445"><span class="toc-number">16.20.1.</span> <span class="toc-text">Ablation analysis: do we need all these attension heads?(h1445)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#What%E2%80%99s-the-right-layer-order-for-a-transformer-h1537"><span class="toc-number">16.21.</span> <span class="toc-text">Whats the right layer order for a transformer?(h1537)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parting-thoughts-h1612"><span class="toc-number">16.22.</span> <span class="toc-text">Parting thoughts(h1612)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Lecture-18-Future-of-NLP-Deep-Learning"><span class="toc-number">17.</span> <span class="toc-text">Lecture 18 - Future of NLP + Deep Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#General-Representation-Learning-Recipe-0312"><span class="toc-number">17.1.</span> <span class="toc-text">General Representation Learning Recipe(0312)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Large-Language-Models-and-GPT-3-0358"><span class="toc-number">17.2.</span> <span class="toc-text">Large Language Models and GPT-3(0358)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Large-Language-models-and-GPT-3-0514"><span class="toc-number">17.2.1.</span> <span class="toc-text">Large Language models and GPT-3(0514)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#What%E2%80%99s-new-about-GPT-3"><span class="toc-number">17.2.2.</span> <span class="toc-text">Whats new about GPT-3</span></a></li></ol></li></ol></li></ol>
        </nav>
    </div>
</aside>






        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/LoveinSun">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont icon-telegram"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont icon-twitter"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>


    <script src="//cdn.jsdelivr.net/npm/gitalk@1.5.2/dist/gitalk.min.js"></script>
<script src="//cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script>
<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: '40e1002206dc11748978',
        clientSecret: '027043262cdf608cfa6b1c20173bc245b1cff702',
        repo: 'blog-comment',
        owner: 'LoveinSun',
        admin: ['LoveinSun'],
	proxy: ['https://proxy.juggler.fun:9013/login/oauth/access_token'],
        id: md5(location.pathname),
        distractionFreeMode: true
    })
    gitalk.render('comments')
</script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
