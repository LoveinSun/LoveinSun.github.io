<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"juggler.fun","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s 基本操作1234567891011121314151617181920212223242526272829303132import torchimport numpy as npdevice &#x3D; torch.device(&quot;cpu&quot;)if torch.cuda.is_available">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch">
<meta property="og:url" content="https://juggler.fun/python/Pytorch/index.html">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s 基本操作1234567891011121314151617181920212223242526272829303132import torchimport numpy as npdevice &#x3D; torch.device(&quot;cpu&quot;)if torch.cuda.is_available">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png">
<meta property="article:published_time" content="2022-03-22T02:41:44.000Z">
<meta property="article:modified_time" content="2022-03-23T03:23:41.569Z">
<meta property="article:author" content="Juggler">
<meta property="article:tag" content="python">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png">


<link rel="canonical" href="https://juggler.fun/python/Pytorch/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://juggler.fun/python/Pytorch/","path":"python/Pytorch/","title":"Pytorch"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Pytorch | JugglerDancing</title>
  





  <script src="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.js" integrity="sha256-6Y7CJDaltoeNgk+ZftgCD9jLgmGv4xKUo8nQ0HgAwVo=" crossorigin="anonymous"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/aplayer/1.10.1/APlayer.min.css" integrity="sha256-uqQQGnDcmRKvhKwc5Vm4XT1GQ2oV6t1U0NR2N9tV+BQ=" crossorigin="anonymous" />
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
<div id="aplayer"></div>
<script type="text/javascript" src="/dist/music.js"></script>
	<div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">JugglerDancing</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Juggler is dancing</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li>
        <li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container">
  <div class="algolia-stats"><hr></div>
  <div class="algolia-hits"></div>
  <div class="algolia-pagination"></div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="nav-number">1.</span> <span class="nav-text">基本操作</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Gradients"><span class="nav-number">2.</span> <span class="nav-text">Gradients</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Backpropagation"><span class="nav-number">2.1.</span> <span class="nav-text">Backpropagation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gradient-Descent"><span class="nav-number">2.2.</span> <span class="nav-text">Gradient Descent</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Training-pipeline"><span class="nav-number">3.</span> <span class="nav-text">Training pipeline</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Linear-Regression"><span class="nav-number">4.</span> <span class="nav-text">Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistic-Regression"><span class="nav-number">4.1.</span> <span class="nav-text">Logistic Regression</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dataset-and-Dataloader"><span class="nav-number">5.</span> <span class="nav-text">Dataset and Dataloader</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dataset-transformers"><span class="nav-number">6.</span> <span class="nav-text">Dataset transformers</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SoftMax-and-Crossentropy"><span class="nav-number">7.</span> <span class="nav-text">SoftMax and Crossentropy</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-network"><span class="nav-number">8.</span> <span class="nav-text">Neural network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Activation-Function"><span class="nav-number">9.</span> <span class="nav-text">Activation Function</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Feed-Forward-Neural-Net"><span class="nav-number">10.</span> <span class="nav-text">Feed-Forward Neural Net</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN"><span class="nav-number">11.</span> <span class="nav-text">CNN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transfer-Learning"><span class="nav-number">12.</span> <span class="nav-text">Transfer Learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorboard"><span class="nav-number">13.</span> <span class="nav-text">Tensorboard</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Save-amp-Load"><span class="nav-number">14.</span> <span class="nav-text">Save &amp; Load</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Juggler"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Juggler</p>
  <div class="site-description" itemprop="description">吾之生命如流星，誓要从全世界路过。</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://juggler.fun/python/Pytorch/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Juggler">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JugglerDancing">
      <meta itemprop="description" content="吾之生命如流星，誓要从全世界路过。">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Pytorch | JugglerDancing">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Pytorch<a href="https://github.com/LoveinSun/LoveinSun.github.io/tree/master_posts/Pytorch.md" class="post-edit-link" title="Edit this post" rel="noopener" target="_blank"><i class="fa fa-pen-nib"></i></a>
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-03-22 10:41:44" itemprop="dateCreated datePublished" datetime="2022-03-22T10:41:44+08:00">2022-03-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-03-23 11:23:41" itemprop="dateModified" datetime="2022-03-23T11:23:41+08:00">2022-03-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s</p>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,dtype=torch.double)</span><br><span class="line">x.size()</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>,device=device)</span><br><span class="line">y = torch.rand(<span class="number">2</span>,<span class="number">2</span>,device=device)</span><br><span class="line">z = x+y <span class="comment">#+-*/</span></span><br><span class="line">z = torch.add(x,y)<span class="comment">#add sub mul</span></span><br><span class="line">y.add_(x)<span class="comment"># sub_ div_ 原地操作</span></span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">x[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line"></span><br><span class="line">y=x.view(-<span class="number">1</span>,<span class="number">2</span>) <span class="comment">#插眼</span></span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">a.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">a.add_(<span class="number">13</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"></span><br><span class="line">a = np.ones(<span class="number">6</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)<span class="comment">#***</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = x+<span class="number">2</span></span><br><span class="line">z = y*y*<span class="number">2</span></span><br><span class="line"><span class="comment">#z = z.mean()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.001</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">z.backward(v)<span class="comment"># 插眼：如果不是标量则必须给vecor ***</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dont calculate 插眼</span></span><br><span class="line"><span class="comment">#x.requires_grad_(False)</span></span><br><span class="line"><span class="comment">#y = x.detach()</span></span><br><span class="line"><span class="comment">#with torch.no_grad():</span></span><br><span class="line"><span class="comment">#    y = x + 2</span></span><br><span class="line"><span class="comment">#    print(y)</span></span><br><span class="line"></span><br><span class="line">weights = torch.ones(<span class="number">4</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model_output = (weights*<span class="number">3</span>).<span class="built_in">sum</span>()</span><br><span class="line">    model_output.backward()</span><br><span class="line">    <span class="built_in">print</span>(weights.grad)</span><br><span class="line"></span><br><span class="line">    weights.grad.zero_() <span class="comment">#将积累的计算清零 插眼，需要深入理解 ***</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#optimizer</span></span><br><span class="line"><span class="comment">#optimizer = torch.optim.SGD([weights], lr=0.01)</span></span><br><span class="line"><span class="comment">#optimizer.step()</span></span><br><span class="line"><span class="comment">#optimizer.zero_grad()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">w = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_hat = w * x</span><br><span class="line">loss = (y_hat-y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>

<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png" alt="image-20220316151942503"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=np.float32)</span><br><span class="line">w = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    dw = gradient(x,y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    w-=learning_rate * dw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png" alt="image-20220316145349626"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= learning_rate * w.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    w.grad.zero_()        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Training-pipeline"><a href="#Training-pipeline" class="headerlink" title="Training pipeline"></a>Training pipeline</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png" alt="image-20220316153456524"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="comment">#y_pred = model(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png" alt="image-20220316153507880"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line"><span class="comment">#w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    <span class="comment">#y_pred = forward(x)</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">x_numpy,y_numpy = datasets.make_regression(n_samples=<span class="number">100</span>,n_features=<span class="number">1</span>,noise=<span class="number">20</span>,random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = torch.from_numpy(x_numpy.astype(np.float32))</span><br><span class="line">y = torch.from_numpy(y_numpy.astype(np.float32))</span><br><span class="line">y = y.view(y.shape[<span class="number">0</span>],<span class="number">1</span>)<span class="comment"># 插眼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = nn.Linear(input_size,output_size)</span><br><span class="line">pr = model(x).detach().numpy()</span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># forward pss and loss</span></span><br><span class="line">    y_predicted = model(x)</span><br><span class="line">    loss = criterion(y_predicted,y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">predicted = model(x).detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(x_numpy,y_numpy,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x_numpy,predicted,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">bc = datasets.load_breast_cancer()</span><br><span class="line">x,y = bc.data,bc.target</span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#sclae</span></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">x_train = sc.fit_transform(x_train)</span><br><span class="line">x_test = sc.transform(x_test)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train.astype(np.float32))</span><br><span class="line">x_test = torch.from_numpy(x_test.astype(np.float32))</span><br><span class="line">y_train = torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">y_test = torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line">y_train = y_train.view(y_train.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line">y_test = y_test.view(y_test.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"><span class="comment"># f = wx+b, sigmod at the end</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_predicted = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_predicted</span><br><span class="line">model = LogisticRegression(n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.03</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="comment">#forward pass and loss</span></span><br><span class="line">    y_predicted = model(x_train)</span><br><span class="line">    loss = criterion(y_predicted,y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y_predicted = model(x_test)</span><br><span class="line">    y_predicted_cls = y_predicted.<span class="built_in">round</span>()</span><br><span class="line">    acc = y_predicted_cls.eq(y_test).<span class="built_in">sum</span>()/<span class="built_in">float</span>(y_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,</span><br><span class="line">                        skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = torch.from_numpy(xy[:, <span class="number">1</span>:])</span><br><span class="line">        self.y = torch.from_numpy(xy[:, [<span class="number">0</span>]])</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = WineDataSet()</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datatiter = iter(dataloader)</span></span><br><span class="line"><span class="comment"># data = datatiter.next()</span></span><br><span class="line"><span class="comment"># features, labels = data</span></span><br><span class="line"><span class="comment"># print(features,labels)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line">n_iterations = math.ceil(total_samples / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(total_samples, n_iterations)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># forward backward, update</span></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_iterations&#125;</span>,inputs <span class="subst">&#123;inputs.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-transformers"><a href="#Dataset-transformers" class="headerlink" title="Dataset transformers"></a>Dataset transformers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = xy[:, <span class="number">1</span>:]</span><br><span class="line">        self.y = xy[:, [<span class="number">0</span>]]</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        sample = self.x[index],self.y[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToTensor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,targets = sample</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(inputs),torch.from_numpy(targets)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulTransform</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,factor</span>):</span><br><span class="line">        self.factor = factor</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,target = sample</span><br><span class="line">        inputs *= self.factor</span><br><span class="line">        <span class="keyword">return</span> inputs,target</span><br><span class="line"></span><br><span class="line">dataset = WineDataSet(transform=<span class="literal">None</span>)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br><span class="line"></span><br><span class="line">composed = torchvision.transforms.Compose([ToTensor(),MulTransform(<span class="number">2</span>)])</span><br><span class="line">dataset = WineDataSet(transform=composed)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br></pre></td></tr></table></figure>

<h1 id="SoftMax-and-Crossentropy"><a href="#SoftMax-and-Crossentropy" class="headerlink" title="SoftMax and Crossentropy"></a>SoftMax and Crossentropy</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png" alt="image-20220317185503305"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x)/np.<span class="built_in">sum</span>(np.exp(x),axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = softmax(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;softmax numpy:&#x27;</span>,outputs)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = torch.softmax(x,dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">actual,predicted</span>):</span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(actual * np.log(predicted))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">Y_pred_good = np.array([<span class="number">0.7</span>,<span class="number">0.2</span>,<span class="number">0.1</span>])</span><br><span class="line">Y_pred_bad = np.array([<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>])</span><br><span class="line">l1 = cross_entropy(Y,Y_pred_good)</span><br><span class="line">l2 = cross_entropy(Y,Y_pred_bad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss1 numpy:<span class="subst">&#123;l1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss2 numpy:<span class="subst">&#123;l2:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#3 samples</span></span><br><span class="line"></span><br><span class="line">Y = torch.tensor([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">y_pred_good = torch.tensor([[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line">y_pred_bad = torch.tensor([[<span class="number">2.1</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">l1 = loss(y_pred_good,Y)</span><br><span class="line">l2 = loss(y_pred_bad,Y)</span><br><span class="line"><span class="built_in">print</span>(l1.item())</span><br><span class="line"><span class="built_in">print</span>(l2.item())</span><br><span class="line"></span><br><span class="line">_,pred1 = torch.<span class="built_in">max</span>(y_pred_good,<span class="number">1</span>)</span><br><span class="line">_,pred2 = torch.<span class="built_in">max</span>(y_pred_bad,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred1)</span><br><span class="line"><span class="built_in">print</span>(pred2)</span><br></pre></td></tr></table></figure>

<h1 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png" alt="image-20220318104226578"></p>
<p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png" alt="image-20220318104246948"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiclass problem</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line"></span><br><span class="line">        y_pred = torch.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = NeuralNet2(input_size=<span class="number">28</span>*<span class="number">28</span>,hidden_size=<span class="number">5</span>,num_classes=<span class="number">1</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># option1 create nn modules</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        <span class="comment">#nn.Sigmoid</span></span><br><span class="line">        <span class="comment">#nn.Softmax</span></span><br><span class="line">        <span class="comment">#nn.TanH</span></span><br><span class="line">        <span class="comment">#nn.LeakyReLU</span></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment"># option 2 use activation functions directly in forward pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        <span class="comment">#F.leaky_relu()</span></span><br><span class="line">        self.linear = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = torch.relu(self.linear1(x))</span><br><span class="line">        out = torch.simoid(self.linear2(out))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h1 id="Feed-Forward-Neural-Net"><a href="#Feed-Forward-Neural-Net" class="headerlink" title="Feed-Forward Neural Net"></a>Feed-Forward Neural Net</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># device config</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#hyper parameters</span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br><span class="line"><span class="comment"># DataLoader,Transformation</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">samples,labels = examples.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(samples.shape,labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(samples[i][<span class="number">0</span>],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = NeuralNet(input_size,hidden_size,num_classes)</span><br><span class="line">model=model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">## loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training loo</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#100,1,28,28</span></span><br><span class="line">        <span class="comment">#100,784</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#forward</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#backwards</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.n_ntotal_steps, loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#value,index</span></span><br><span class="line">        _,predictions = torch.<span class="built_in">max</span>(outputs,<span class="number">1</span>)</span><br><span class="line">        n_samples+= labels.shape[<span class="number">0</span>]</span><br><span class="line">        n_correct = (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = <span class="number">100.0</span>* n_correct/n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png" alt="image-20220318145648589"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset has PILImage images of range [0, 1]. </span></span><br><span class="line"><span class="comment"># We transform them to Tensors of normalized range [-1, 1]</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class</span></span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># -&gt; n, 3, 32, 32</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))  <span class="comment"># -&gt; n, 6, 14, 14</span></span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))  <span class="comment"># -&gt; n, 16, 5, 5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)            <span class="comment"># -&gt; n, 400</span></span><br><span class="line">        x = F.relu(self.fc1(x))               <span class="comment"># -&gt; n, 120</span></span><br><span class="line">        x = F.relu(self.fc2(x))               <span class="comment"># -&gt; n, 84</span></span><br><span class="line">        x = self.fc3(x)                       <span class="comment"># -&gt; n, 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet().to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># origin shape: [4, 3, 32, 32] = 4, 3, 1024</span></span><br><span class="line">        <span class="comment"># input_layer: 3 input channels, 6 output channels, 5 kernel size</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line">PATH = <span class="string">&#x27;./cnn.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    n_class_correct = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    n_class_samples = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            pred = predicted[i]</span><br><span class="line">            <span class="keyword">if</span> (label == pred):</span><br><span class="line">                n_class_correct[label] += <span class="number">1</span></span><br><span class="line">            n_class_samples[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        acc = <span class="number">100.0</span> * n_class_correct[i] / n_class_samples[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><p><img data-src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png" alt="image-20220318145729962"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">mean = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">std = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;data/hymenoptera_data&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=<span class="number">4</span>,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">25</span></span>):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        optimizer.zero_grad()</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Finetuning the convnet ####</span></span><br><span class="line"><span class="comment"># Load a pretrained model and reset final fully connected layer.</span></span><br><span class="line"></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 2.</span></span><br><span class="line"><span class="comment"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span></span><br><span class="line">model.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StepLR Decays the learning rate of each parameter group by gamma every step_size epochs</span></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Learning rate scheduling should be applied after optimizer’s update</span></span><br><span class="line"><span class="comment"># e.g., you should write your code this way:</span></span><br><span class="line"><span class="comment"># for epoch in range(100):</span></span><br><span class="line"><span class="comment">#     train(...)</span></span><br><span class="line"><span class="comment">#     validate(...)</span></span><br><span class="line"><span class="comment">#     scheduler.step()</span></span><br><span class="line"></span><br><span class="line">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### ConvNet as fixed feature extractor ####</span></span><br><span class="line"><span class="comment"># Here, we need to freeze all the network except the final layer.</span></span><br><span class="line"><span class="comment"># We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()</span></span><br><span class="line">model_conv = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that only parameters of final layer are being optimized as</span></span><br><span class="line"><span class="comment"># opposed to before.</span></span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># default `log_dir` is &quot;runs&quot; - we&#x27;ll be more specific here</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/mnist1&#x27;</span>)</span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment"># 28x28</span></span><br><span class="line">hidden_size = <span class="number">500</span> </span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST dataset </span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),  </span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, </span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, </span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">example_data, example_targets = examples.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(example_data)</span><br><span class="line">writer.add_image(<span class="string">&#x27;mnist_images&#x27;</span>, img_grid)</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully connected neural network with one hidden layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.l1 = nn.Linear(input_size, hidden_size) </span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="comment"># no activation and no softmax at the end</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = NeuralNet(input_size, hidden_size, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">writer.add_graph(model, example_data.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">running_correct = <span class="number">0</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        <span class="comment"># origin shape: [100, 1, 28, 28]</span></span><br><span class="line">        <span class="comment"># resized: [100, 784]</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        running_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>, running_loss / <span class="number">100</span>, epoch * n_total_steps + i)</span><br><span class="line">            running_accuracy = running_correct / <span class="number">100</span> / predicted.size(<span class="number">0</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, running_accuracy, epoch * n_total_steps + i)</span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            <span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="comment"># In test phase, we don&#x27;t need to compute gradients (for memory efficiency)</span></span><br><span class="line">class_labels = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        values, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        class_probs_batch = [F.softmax(output, dim=<span class="number">0</span>) <span class="keyword">for</span> output <span class="keyword">in</span> outputs]</span><br><span class="line"></span><br><span class="line">        class_preds.append(class_probs_batch)</span><br><span class="line">        class_labels.append(predicted)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000, 10, and 10000, 1</span></span><br><span class="line">    <span class="comment"># stack concatenates tensors along a new dimension</span></span><br><span class="line">    <span class="comment"># cat concatenates tensors in the given dimension</span></span><br><span class="line">    class_preds = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_preds])</span><br><span class="line">    class_labels = torch.cat(class_labels)</span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network on the 10000 test images: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">    classes = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">        labels_i = class_labels == i</span><br><span class="line">        preds_i = class_preds[:, i]</span><br><span class="line">        writer.add_pr_curve(<span class="built_in">str</span>(i), labels_i, preds_i, global_step=<span class="number">0</span>)</span><br><span class="line">        writer.close()</span><br><span class="line">    <span class="comment">###################################################</span></span><br></pre></td></tr></table></figure>

<h1 id="Save-amp-Load"><a href="#Save-amp-Load" class="headerlink" title="Save &amp; Load"></a>Save &amp; Load</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 3 DIFFERENT METHODS TO REMEMBER:</span></span><br><span class="line"><span class="string"> - torch.save(arg, PATH) # can be model, tensor, or dictionary</span></span><br><span class="line"><span class="string"> - torch.load(PATH)</span></span><br><span class="line"><span class="string"> - torch.load_state_dict(arg)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 2 DIFFERENT WAYS OF SAVING</span></span><br><span class="line"><span class="string"># 1) lazy way: save whole model</span></span><br><span class="line"><span class="string">torch.save(model, PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model class must be defined somewhere</span></span><br><span class="line"><span class="string">model = torch.load(PATH)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) recommended way: save only the state_dict</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model must be created again with parameters</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line"><span class="comment"># train your model...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################save all ######################################</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save and load entire model</span></span><br><span class="line"></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model, FILE)</span><br><span class="line"></span><br><span class="line">loaded_model = torch.load(FILE)</span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> loaded_model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############save only state dict #########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save only state dict</span></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model.state_dict(), FILE)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.state_dict())</span><br><span class="line">loaded_model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">loaded_model.load_state_dict(torch.load(FILE)) <span class="comment"># it takes the loaded dictionary, not the path file itself</span></span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loaded_model.state_dict())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########load checkpoint#####################</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="string">&quot;epoch&quot;</span>: <span class="number">90</span>,</span><br><span class="line"><span class="string">&quot;model_state&quot;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&quot;optim_state&quot;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line">FILE = <span class="string">&quot;checkpoint.pth&quot;</span></span><br><span class="line">torch.save(checkpoint, FILE)</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(FILE)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state&#x27;</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optim_state&#x27;</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line"><span class="comment"># model.train()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remember that you must call model.eval() to set dropout and batch normalization layers </span></span><br><span class="line"><span class="comment"># to evaluation mode before running inference. Failing to do this will yield </span></span><br><span class="line"><span class="comment"># inconsistent inference results. If you wish to resuming training, </span></span><br><span class="line"><span class="comment"># call model.train() to ensure these layers are in training mode.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; SAVING ON GPU/CPU </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 1) Save on GPU, Load on CPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=device))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) Save on GPU, Load on GPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note: Be sure to use the .to(torch.device(&#x27;cuda&#x27;)) function </span></span><br><span class="line"><span class="string"># on all model inputs, too!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 3) Save on CPU, Load on GPU</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># This loads the model to a given GPU device. </span></span><br><span class="line"><span class="string"># Next, be sure to call model.to(torch.device(&#x27;cuda&#x27;)) to convert the model’s parameter tensors to CUDA tensors</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





























    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/python/" rel="tag"># python</a>
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ML/%E6%9D%8E%E5%AE%8F%E6%AF%85-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" rel="prev" title="李宏毅-機器學習">
                  <i class="fa fa-chevron-left"></i> 李宏毅-機器學習
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/NLP/NLP/" rel="next" title="NLP">
                  NLP <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">冀ICP备2021011397号-1 </a>
  </div>

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Juggler</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script size="300" alpha="0.6" zIndex="-1" src="https://cdn.jsdelivr.net/npm/ribbon.js@1.0.2/dist/ribbon.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@next-theme/pjax@0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/lozad@1.16.0/dist/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/algoliasearch@4.12.1/dist/algoliasearch-lite.umd.js" integrity="sha256-gOvJ6W+j+t/cgnnl9iUU3cb6F1WFQGDdtTXhfPjU4bc=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4.39.0/dist/instantsearch.production.min.js" integrity="sha256-+ZlQZK9m82XOYGFZCIRrPOFh2kDdAGB6e7TjWGvoaSY=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.7/pdfobject.min.js","integrity":"sha256-ph3Dk89VmuTVXG6x/RDzk53SU9LPdAh1tpv0UvnDZ2I="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.14.0/dist/mermaid.min.js","integrity":"sha256-7wT34TI0pEBeEFoi4z+vhuSddGh6vUTMWdqJ2SDe2jg="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/pace.js"></script>

  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/quicklink@2.2.0/dist/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"https://juggler.fun/python/Pytorch/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"LoveinSun","repo":"blog-comment","client_id":"40e1002206dc11748978","client_secret":"027043262cdf608cfa6b1c20173bc245b1cff702","admin_user":"LoveinSun","distraction_free_mode":true,"proxy":"https://proxy.juggler.fun:9013/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"3e073ede09cc45c98a5320c7f680081a"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
