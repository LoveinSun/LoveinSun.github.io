<!DOCTYPE html>
<html  lang="en" >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>Pytorch | JugglerDancing</title>
    <meta name="description" content="&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s 基本操作1234567891011121314151617181920212223242526272829303132import torchimport numpy as npdevice &#x3D; torch.device(&quot;cpu&quot;)if torch.cuda.is_available">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch">
<meta property="og:url" content="http://juggler.fun/uncategorized/Pytorch">
<meta property="og:site_name" content="JugglerDancing">
<meta property="og:description" content="&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s 基本操作1234567891011121314151617181920212223242526272829303132import torchimport numpy as npdevice &#x3D; torch.device(&quot;cpu&quot;)if torch.cuda.is_available">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png">
<meta property="og:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png">
<meta property="article:published_time" content="2022-03-22T02:41:44.000Z">
<meta property="article:modified_time" content="2022-03-22T02:46:14.816Z">
<meta property="article:author" content="Juggler">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png">

    
    <link rel="icon" href="/images/favicon.ico" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 6.1.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/fengkx" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="https://www.gravatar.com/avatar/0bc83cb571cd1c50ba6f3e8a78ef1346?s=128" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">fengkx</h2>
            <h3 id="title" class="hidden xl:block">Student &amp; Coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Guangzhou, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="Search" class="inline-block w-full bg-gray-100 lg:bg-white">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<div id="content-json" data-placeholder="Search" class="invisible hidden">/content.json</div>
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="Search" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">Home</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">Archives</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-categories" role="menuitem">
                <a href="/categories">
                    <i class="iconfont icon-folder" aria-hidden="true"></i>
                    <span class="menu-title">Categories</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">Tags</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-repository" role="menuitem">
                <a href="/repository">
                    <i class="iconfont icon-project" aria-hidden="true"></i>
                    <span class="menu-title">Repository</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-links" role="menuitem">
                <a href="/links">
                    <i class="iconfont icon-friend" aria-hidden="true"></i>
                    <span class="menu-title">Links</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">About</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/fengkx">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont social-icon icon-telegram"></i>
                <span class="menu-title hidden lg:inline">menu.telegram</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont social-icon icon-twitter"></i>
                <span class="menu-title hidden lg:inline">menu.twitter</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-14 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            
    
        <h1 class="article-title text-lg" itemprop="name">
            Pytorch
        </h1>
    



            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/uncategorized/Pytorch" class="article-date">
	  <time datetime="2022-03-22T02:41:44.000Z" itemprop="datePublished">Mar 22</time>
	</a>
</span>

                

                

                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/uncategorized/Pytorch#comments" class="article-comment-link">
                        Comments
                    </a>
                </span>
                

            </p>
        </header>
        <div class="marked-body article-body">
            <p>&#x2F;watch?v&#x3D;c36lUUr864M&amp;t&#x3D;936s</p>
<h1 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>,<span class="number">2</span>,dtype=torch.double)</span><br><span class="line">x.size()</span><br><span class="line">x = torch.rand(<span class="number">2</span>,<span class="number">2</span>,requires_grad=<span class="literal">True</span>,device=device)</span><br><span class="line">y = torch.rand(<span class="number">2</span>,<span class="number">2</span>,device=device)</span><br><span class="line">z = x+y <span class="comment">#+-*/</span></span><br><span class="line">z = torch.add(x,y)<span class="comment">#add sub mul</span></span><br><span class="line">y.add_(x)<span class="comment"># sub_ div_ 原地操作</span></span><br><span class="line">x=torch.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">x[<span class="number">1</span>][<span class="number">1</span>].item()</span><br><span class="line"></span><br><span class="line">y=x.view(-<span class="number">1</span>,<span class="number">2</span>) <span class="comment">#插眼</span></span><br><span class="line"></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">a.to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">a.add_(<span class="number">13</span>)</span><br><span class="line">b = a.numpy()</span><br><span class="line"></span><br><span class="line">a = np.ones(<span class="number">6</span>)</span><br><span class="line">b = torch.from_numpy(a)</span><br><span class="line">b.to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="built_in">print</span>(b)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Gradients"><a href="#Gradients" class="headerlink" title="Gradients"></a>Gradients</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)<span class="comment">#***</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line">y = x+<span class="number">2</span></span><br><span class="line">z = y*y*<span class="number">2</span></span><br><span class="line"><span class="comment">#z = z.mean()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(z)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">0.001</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">z.backward(v)<span class="comment"># 插眼：如果不是标量则必须给vecor ***</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#dont calculate 插眼</span></span><br><span class="line"><span class="comment">#x.requires_grad_(False)</span></span><br><span class="line"><span class="comment">#y = x.detach()</span></span><br><span class="line"><span class="comment">#with torch.no_grad():</span></span><br><span class="line"><span class="comment">#    y = x + 2</span></span><br><span class="line"><span class="comment">#    print(y)</span></span><br><span class="line"></span><br><span class="line">weights = torch.ones(<span class="number">4</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model_output = (weights*<span class="number">3</span>).<span class="built_in">sum</span>()</span><br><span class="line">    model_output.backward()</span><br><span class="line">    <span class="built_in">print</span>(weights.grad)</span><br><span class="line"></span><br><span class="line">    weights.grad.zero_() <span class="comment">#将积累的计算清零 插眼，需要深入理解 ***</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#optimizer</span></span><br><span class="line"><span class="comment">#optimizer = torch.optim.SGD([weights], lr=0.01)</span></span><br><span class="line"><span class="comment">#optimizer.step()</span></span><br><span class="line"><span class="comment">#optimizer.zero_grad()</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">w = torch.tensor(<span class="number">1.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_hat = w * x</span><br><span class="line">loss = (y_hat-y)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(w.grad)</span><br></pre></td></tr></table></figure>

<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161519546.png" alt="image-20220316151942503"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=np.float32)</span><br><span class="line">w = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    dw = gradient(x,y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    w-=learning_rate * dw</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161453680.png" alt="image-20220316145349626"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;prediction before training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">n_iters = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w -= learning_rate * w.grad</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    w.grad.zero_()        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w:<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;forward(<span class="number">5</span>):<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Training-pipeline"><a href="#Training-pipeline" class="headerlink" title="Training pipeline"></a>Training pipeline</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161534581.png" alt="image-20220316153456524"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line">w = torch.tensor(<span class="number">0.0</span>,dtype=torch.float32,requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    y_pred = forward(x)</span><br><span class="line">    <span class="comment">#y_pred = model(x)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203161535941.png" alt="image-20220316153507880"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># f = w * x</span></span><br><span class="line"><span class="comment"># f = 2 * x</span></span><br><span class="line">x = torch.tensor([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">4</span>]],dtype=torch.float32)</span><br><span class="line">y = torch.tensor([[<span class="number">2</span>],[<span class="number">4</span>],[<span class="number">6</span>],[<span class="number">8</span>]],dtype=torch.float32)</span><br><span class="line"><span class="comment">#w = torch.tensor(0.0,dtype=torch.float32,requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">x_test = torch.tensor([<span class="number">5</span>],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"><span class="built_in">print</span>(n_samples,n_features)</span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = n_features</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_dim,output_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearRegression,self).__init__()</span><br><span class="line">        self.lin = nn.Linear(input_dim,output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.lin(x)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#model = nn.Linear(input_size,output_size)</span></span><br><span class="line">model = LinearRegression(input_size,output_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model prediction</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> w*x</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss MSE</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> ((y_predicted-y)**<span class="number">2</span>).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># gradient</span></span><br><span class="line"><span class="comment"># MSE = 1/N * (w*x -y)**2</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">x,y,y_predicted</span>):</span><br><span class="line">    <span class="keyword">return</span> np.dot(<span class="number">2</span>*x,y_predicted-y).mean()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction before training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">learning_rate = <span class="number">0.1</span></span><br><span class="line">n_iters = <span class="number">300</span></span><br><span class="line">loss = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    <span class="comment"># prediction = forward pass</span></span><br><span class="line">    <span class="comment">#y_pred = forward(x)</span></span><br><span class="line">    y_pred = model(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#loss</span></span><br><span class="line">    l = loss(y,y_pred)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradients</span></span><br><span class="line">    <span class="comment">#dw = gradient(x,y,y_pred)</span></span><br><span class="line">    l.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update weights</span></span><br><span class="line">    <span class="comment">#w-=learning_rate * dw</span></span><br><span class="line">    <span class="comment">#with torch.no_grad():</span></span><br><span class="line">    <span class="comment">#    w -= learning_rate * w.grad</span></span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    <span class="comment">#w.grad.zero_()</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch%<span class="number">1</span>==<span class="number">0</span>:</span><br><span class="line">        [w,b] = model.parameters()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>:w = <span class="subst">&#123;w[<span class="number">0</span>][<span class="number">0</span>].item():<span class="number">.3</span>f&#125;</span>,loss = <span class="subst">&#123;l:<span class="number">.8</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Prediction after training: f(5) = <span class="subst">&#123;model(x_test).item():<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ol>
<li>Design model (input,output size,forward pass)</li>
<li>Construct loss and optimizer</li>
<li>Training loop<ul>
<li>forward pass: compute and prediction</li>
<li>backward pass: gradients</li>
<li>update weights</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">x_numpy,y_numpy = datasets.make_regression(n_samples=<span class="number">100</span>,n_features=<span class="number">1</span>,noise=<span class="number">20</span>,random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x = torch.from_numpy(x_numpy.astype(np.float32))</span><br><span class="line">y = torch.from_numpy(y_numpy.astype(np.float32))</span><br><span class="line">y = y.view(y.shape[<span class="number">0</span>],<span class="number">1</span>)<span class="comment"># 插眼</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"></span><br><span class="line">input_size = n_features</span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">model = nn.Linear(input_size,output_size)</span><br><span class="line">pr = model(x).detach().numpy()</span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epochs = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># forward pss and loss</span></span><br><span class="line">    y_predicted = model(x)</span><br><span class="line">    loss = criterion(y_predicted,y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>)%<span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot</span></span><br><span class="line">predicted = model(x).detach().numpy()</span><br><span class="line"></span><br><span class="line">plt.plot(x_numpy,y_numpy,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x_numpy,predicted,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0)prepare data</span></span><br><span class="line">bc = datasets.load_breast_cancer()</span><br><span class="line">x,y = bc.data,bc.target</span><br><span class="line"></span><br><span class="line">n_samples,n_features = x.shape</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1234</span>)</span><br><span class="line"><span class="comment">#sclae</span></span><br><span class="line">sc = StandardScaler()</span><br><span class="line">x_train = sc.fit_transform(x_train)</span><br><span class="line">x_test = sc.transform(x_test)</span><br><span class="line"></span><br><span class="line">x_train = torch.from_numpy(x_train.astype(np.float32))</span><br><span class="line">x_test = torch.from_numpy(x_test.astype(np.float32))</span><br><span class="line">y_train = torch.from_numpy(y_train.astype(np.float32))</span><br><span class="line">y_test = torch.from_numpy(y_test.astype(np.float32))</span><br><span class="line"></span><br><span class="line">y_train = y_train.view(y_train.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line">y_test = y_test.view(y_test.shape[<span class="number">0</span>],<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1)model</span></span><br><span class="line"><span class="comment"># f = wx+b, sigmod at the end</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LogisticRegression</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(LogisticRegression,self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        y_predicted = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_predicted</span><br><span class="line">model = LogisticRegression(n_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2)loss and optimizer</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">0.03</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3)training loop</span></span><br><span class="line">num_epoch = <span class="number">10000</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    <span class="comment">#forward pass and loss</span></span><br><span class="line">    y_predicted = model(x_train)</span><br><span class="line">    loss = criterion(y_predicted,y_train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#update</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#zero gradients</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>)%<span class="number">10</span>==<span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch:<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>,loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y_predicted = model(x_test)</span><br><span class="line">    y_predicted_cls = y_predicted.<span class="built_in">round</span>()</span><br><span class="line">    acc = y_predicted_cls.eq(y_test).<span class="built_in">sum</span>()/<span class="built_in">float</span>(y_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,</span><br><span class="line">                        skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = torch.from_numpy(xy[:, <span class="number">1</span>:])</span><br><span class="line">        self.y = torch.from_numpy(xy[:, [<span class="number">0</span>]])</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = WineDataSet()</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># datatiter = iter(dataloader)</span></span><br><span class="line"><span class="comment"># data = datatiter.next()</span></span><br><span class="line"><span class="comment"># features, labels = data</span></span><br><span class="line"><span class="comment"># print(features,labels)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line">n_iterations = math.ceil(total_samples / <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(total_samples, n_iterations)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="comment"># forward backward, update</span></span><br><span class="line">        <span class="keyword">if</span> (i + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_iterations&#125;</span>,inputs <span class="subst">&#123;inputs.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Dataset-transformers"><a href="#Dataset-transformers" class="headerlink" title="Dataset transformers"></a>Dataset transformers</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WineDataSet</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># data loading</span></span><br><span class="line">        xy = np.loadtxt(<span class="string">&quot;K:\\Cloud\\data\\nlp\\pytorchTutorial\\data\\wine\\wine.csv&quot;</span>, delimiter=<span class="string">&quot;,&quot;</span>, dtype=np.float32,skiprows=<span class="number">1</span>)</span><br><span class="line">        self.x = xy[:, <span class="number">1</span>:]</span><br><span class="line">        self.y = xy[:, [<span class="number">0</span>]]</span><br><span class="line">        self.n_samplses = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="comment"># dataset[0]</span></span><br><span class="line">        sample = self.x[index],self.y[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># len(dataset)</span></span><br><span class="line">        <span class="keyword">return</span> self.n_samplses</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ToTensor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,targets = sample</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(inputs),torch.from_numpy(targets)</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MulTransform</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,factor</span>):</span><br><span class="line">        self.factor = factor</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self,sample</span>):</span><br><span class="line">        inputs,target = sample</span><br><span class="line">        inputs *= self.factor</span><br><span class="line">        <span class="keyword">return</span> inputs,target</span><br><span class="line"></span><br><span class="line">dataset = WineDataSet(transform=<span class="literal">None</span>)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br><span class="line"></span><br><span class="line">composed = torchvision.transforms.Compose([ToTensor(),MulTransform(<span class="number">2</span>)])</span><br><span class="line">dataset = WineDataSet(transform=composed)</span><br><span class="line">first_data = dataset[<span class="number">0</span>]</span><br><span class="line">features,labels = first_data</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(features),<span class="built_in">type</span>(labels))</span><br></pre></td></tr></table></figure>

<h1 id="SoftMax-and-Crossentropy"><a href="#SoftMax-and-Crossentropy" class="headerlink" title="SoftMax and Crossentropy"></a>SoftMax and Crossentropy</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203171855394.png" alt="image-20220317185503305"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">softmax</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.exp(x)/np.<span class="built_in">sum</span>(np.exp(x),axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = softmax(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;softmax numpy:&#x27;</span>,outputs)</span><br><span class="line"></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>])</span><br><span class="line">outputs = torch.softmax(x,dim=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(outputs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cross_entropy</span>(<span class="params">actual,predicted</span>):</span><br><span class="line">    loss = -np.<span class="built_in">sum</span>(actual * np.log(predicted))</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">Y = np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">Y_pred_good = np.array([<span class="number">0.7</span>,<span class="number">0.2</span>,<span class="number">0.1</span>])</span><br><span class="line">Y_pred_bad = np.array([<span class="number">0.1</span>,<span class="number">0.3</span>,<span class="number">0.6</span>])</span><br><span class="line">l1 = cross_entropy(Y,Y_pred_good)</span><br><span class="line">l2 = cross_entropy(Y,Y_pred_bad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss1 numpy:<span class="subst">&#123;l1:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Loss2 numpy:<span class="subst">&#123;l2:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment">#3 samples</span></span><br><span class="line"></span><br><span class="line">Y = torch.tensor([<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line">y_pred_good = torch.tensor([[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">2.0</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line">y_pred_bad = torch.tensor([[<span class="number">2.1</span>,<span class="number">1.0</span>,<span class="number">0.1</span>],[<span class="number">0.1</span>,<span class="number">1.0</span>,<span class="number">2.1</span>],[<span class="number">0.1</span>,<span class="number">3.0</span>,<span class="number">0.1</span>]],dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">l1 = loss(y_pred_good,Y)</span><br><span class="line">l2 = loss(y_pred_bad,Y)</span><br><span class="line"><span class="built_in">print</span>(l1.item())</span><br><span class="line"><span class="built_in">print</span>(l2.item())</span><br><span class="line"></span><br><span class="line">_,pred1 = torch.<span class="built_in">max</span>(y_pred_good,<span class="number">1</span>)</span><br><span class="line">_,pred2 = torch.<span class="built_in">max</span>(y_pred_bad,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(pred1)</span><br><span class="line"><span class="built_in">print</span>(pred2)</span><br></pre></td></tr></table></figure>

<h1 id="Neural-network"><a href="#Neural-network" class="headerlink" title="Neural network"></a>Neural network</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042702.png" alt="image-20220318104226578"></p>
<p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181042047.png" alt="image-20220318104246948"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiclass problem</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line"></span><br><span class="line">        y_pred = torch.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = NeuralNet2(input_size=<span class="number">28</span>*<span class="number">28</span>,hidden_size=<span class="number">5</span>,num_classes=<span class="number">1</span>)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>

<h1 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># option1 create nn modules</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet2</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet2,self).__init__()</span><br><span class="line">        self.linear1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        <span class="comment">#nn.Sigmoid</span></span><br><span class="line">        <span class="comment">#nn.Softmax</span></span><br><span class="line">        <span class="comment">#nn.TanH</span></span><br><span class="line">        <span class="comment">#nn.LeakyReLU</span></span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.linear1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.linear2(out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="comment"># option 2 use activation functions directly in forward pass</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        <span class="comment">#F.leaky_relu()</span></span><br><span class="line">        self.linear = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.linear2 = nn.Linear(hidden_size,<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = torch.relu(self.linear1(x))</span><br><span class="line">        out = torch.simoid(self.linear2(out))</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<h1 id="Feed-Forward-Neural-Net"><a href="#Feed-Forward-Neural-Net" class="headerlink" title="Feed-Forward Neural Net"></a>Feed-Forward Neural Net</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># device config</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#hyper parameters</span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment">#28*28</span></span><br><span class="line">hidden_size = <span class="number">100</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&quot;./data&quot;</span>,train=<span class="literal">False</span>,transform=transforms.ToTensor())</span><br><span class="line"><span class="comment"># DataLoader,Transformation</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">samples,labels = examples.<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(samples.shape,labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(samples[i][<span class="number">0</span>],cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,input_size,hidden_size,num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet,self).__init__()</span><br><span class="line">        self.l1 = nn.Linear(input_size,hidden_size)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size,num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line">model = NeuralNet(input_size,hidden_size,num_classes)</span><br><span class="line">model=model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment">## loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment">#training loo</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i,(images,labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment">#100,1,28,28</span></span><br><span class="line">        <span class="comment">#100,784</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#forward</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs,labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#backwards</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(i+<span class="number">1</span>)%<span class="number">100</span>==<span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>,step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>.n_ntotal_steps, loss = <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># test</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images,labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>,<span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#value,index</span></span><br><span class="line">        _,predictions = torch.<span class="built_in">max</span>(outputs,<span class="number">1</span>)</span><br><span class="line">        n_samples+= labels.shape[<span class="number">0</span>]</span><br><span class="line">        n_correct = (predictions == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    acc = <span class="number">100.0</span>* n_correct/n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;accuracy = <span class="subst">&#123;acc&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181456713.png" alt="image-20220318145648589"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset has PILImage images of range [0, 1]. </span></span><br><span class="line"><span class="comment"># We transform them to Tensors of normalized range [-1, 1]</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class</span></span><br><span class="line">train_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">img</span>):</span><br><span class="line">    img = img / <span class="number">2</span> + <span class="number">0.5</span>  <span class="comment"># unnormalize</span></span><br><span class="line">    npimg = img.numpy()</span><br><span class="line">    plt.imshow(np.transpose(npimg, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)))</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># get some random training images</span></span><br><span class="line">dataiter = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">images, labels = dataiter.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># show images</span></span><br><span class="line">imshow(torchvision.utils.make_grid(images))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># -&gt; n, 3, 32, 32</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))  <span class="comment"># -&gt; n, 6, 14, 14</span></span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))  <span class="comment"># -&gt; n, 16, 5, 5</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)            <span class="comment"># -&gt; n, 400</span></span><br><span class="line">        x = F.relu(self.fc1(x))               <span class="comment"># -&gt; n, 120</span></span><br><span class="line">        x = F.relu(self.fc2(x))               <span class="comment"># -&gt; n, 84</span></span><br><span class="line">        x = self.fc3(x)                       <span class="comment"># -&gt; n, 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ConvNet().to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># origin shape: [4, 3, 32, 32] = 4, 3, 1024</span></span><br><span class="line">        <span class="comment"># input_layer: 3 input channels, 6 output channels, 5 kernel size</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">2000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line">PATH = <span class="string">&#x27;./cnn.pth&#x27;</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    n_class_correct = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    n_class_samples = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(batch_size):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            pred = predicted[i]</span><br><span class="line">            <span class="keyword">if</span> (label == pred):</span><br><span class="line">                n_class_correct[label] += <span class="number">1</span></span><br><span class="line">            n_class_samples[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        acc = <span class="number">100.0</span> * n_class_correct[i] / n_class_samples[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of <span class="subst">&#123;classes[i]&#125;</span>: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br></pre></td></tr></table></figure>



<h1 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h1><p><img src="https://juggler-1256897757.cos.ap-chengdu.myqcloud.com/picgo/202203181457133.png" alt="image-20220318145729962"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, models, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">mean = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">std = np.array([<span class="number">0.25</span>, <span class="number">0.25</span>, <span class="number">0.25</span>])</span><br><span class="line"></span><br><span class="line">data_transforms = &#123;</span><br><span class="line">    <span class="string">&#x27;train&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.RandomResizedCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">    <span class="string">&#x27;val&#x27;</span>: transforms.Compose([</span><br><span class="line">        transforms.Resize(<span class="number">256</span>),</span><br><span class="line">        transforms.CenterCrop(<span class="number">224</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean, std)</span><br><span class="line">    ]),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data_dir = <span class="string">&#x27;data/hymenoptera_data&#x27;</span></span><br><span class="line">image_datasets = &#123;x: datasets.ImageFolder(os.path.join(data_dir, x),</span><br><span class="line">                                          data_transforms[x])</span><br><span class="line">                  <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataloaders = &#123;x: torch.utils.data.DataLoader(image_datasets[x], batch_size=<span class="number">4</span>,</span><br><span class="line">                                             shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">              <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">dataset_sizes = &#123;x: <span class="built_in">len</span>(image_datasets[x]) <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]&#125;</span><br><span class="line">class_names = image_datasets[<span class="string">&#x27;train&#x27;</span>].classes</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(class_names)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">imshow</span>(<span class="params">inp, title</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span></span><br><span class="line">    inp = inp.numpy().transpose((<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">    inp = std * inp + mean</span><br><span class="line">    inp = np.clip(inp, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.imshow(inp)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a batch of training data</span></span><br><span class="line">inputs, classes = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataloaders[<span class="string">&#x27;train&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make a grid from batch</span></span><br><span class="line">out = torchvision.utils.make_grid(inputs)</span><br><span class="line"></span><br><span class="line">imshow(out, title=[class_names[x] <span class="keyword">for</span> x <span class="keyword">in</span> classes])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, criterion, optimizer, scheduler, num_epochs=<span class="number">25</span></span>):</span><br><span class="line">    since = time.time()</span><br><span class="line"></span><br><span class="line">    best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line">    best_acc = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, num_epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Each epoch has a training and validation phase</span></span><br><span class="line">        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                model.train()  <span class="comment"># Set model to training mode</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                model.<span class="built_in">eval</span>()   <span class="comment"># Set model to evaluate mode</span></span><br><span class="line"></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            running_corrects = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Iterate over data.</span></span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> dataloaders[phase]:</span><br><span class="line">                inputs = inputs.to(device)</span><br><span class="line">                labels = labels.to(device)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># forward</span></span><br><span class="line">                <span class="comment"># track history if only in train</span></span><br><span class="line">                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):</span><br><span class="line">                    outputs = model(inputs)</span><br><span class="line">                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">                    loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># backward + optimize only if in training phase</span></span><br><span class="line">                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                        optimizer.zero_grad()</span><br><span class="line">                        loss.backward()</span><br><span class="line">                        optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># statistics</span></span><br><span class="line">                running_loss += loss.item() * inputs.size(<span class="number">0</span>)</span><br><span class="line">                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">                scheduler.step()</span><br><span class="line"></span><br><span class="line">            epoch_loss = running_loss / dataset_sizes[phase]</span><br><span class="line">            epoch_acc = running_corrects.double() / dataset_sizes[phase]</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; Loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                phase, epoch_loss, epoch_acc))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># deep copy the model</span></span><br><span class="line">            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:</span><br><span class="line">                best_acc = epoch_acc</span><br><span class="line">                best_model_wts = copy.deepcopy(model.state_dict())</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    time_elapsed = time.time() - since</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Training complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        time_elapsed // <span class="number">60</span>, time_elapsed % <span class="number">60</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Best val Acc: &#123;:4f&#125;&#x27;</span>.<span class="built_in">format</span>(best_acc))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># load best model weights</span></span><br><span class="line">    model.load_state_dict(best_model_wts)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Finetuning the convnet ####</span></span><br><span class="line"><span class="comment"># Load a pretrained model and reset final fully connected layer.</span></span><br><span class="line"></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">num_ftrs = model.fc.in_features</span><br><span class="line"><span class="comment"># Here the size of each output sample is set to 2.</span></span><br><span class="line"><span class="comment"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span></span><br><span class="line">model.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that all parameters are being optimized</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># StepLR Decays the learning rate of each parameter group by gamma every step_size epochs</span></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line"><span class="comment"># Learning rate scheduling should be applied after optimizer’s update</span></span><br><span class="line"><span class="comment"># e.g., you should write your code this way:</span></span><br><span class="line"><span class="comment"># for epoch in range(100):</span></span><br><span class="line"><span class="comment">#     train(...)</span></span><br><span class="line"><span class="comment">#     validate(...)</span></span><br><span class="line"><span class="comment">#     scheduler.step()</span></span><br><span class="line"></span><br><span class="line">step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### ConvNet as fixed feature extractor ####</span></span><br><span class="line"><span class="comment"># Here, we need to freeze all the network except the final layer.</span></span><br><span class="line"><span class="comment"># We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()</span></span><br><span class="line">model_conv = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model_conv.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Parameters of newly constructed modules have requires_grad=True by default</span></span><br><span class="line">num_ftrs = model_conv.fc.in_features</span><br><span class="line">model_conv.fc = nn.Linear(num_ftrs, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model_conv = model_conv.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Observe that only parameters of final layer are being optimized as</span></span><br><span class="line"><span class="comment"># opposed to before.</span></span><br><span class="line">optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Decay LR by a factor of 0.1 every 7 epochs</span></span><br><span class="line">exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=<span class="number">7</span>, gamma=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">model_conv = train_model(model_conv, criterion, optimizer_conv,</span><br><span class="line">                         exp_lr_scheduler, num_epochs=<span class="number">25</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="Tensorboard"><a href="#Tensorboard" class="headerlink" title="Tensorboard"></a>Tensorboard</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># default `log_dir` is &quot;runs&quot; - we&#x27;ll be more specific here</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;runs/mnist1&#x27;</span>)</span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters </span></span><br><span class="line">input_size = <span class="number">784</span> <span class="comment"># 28x28</span></span><br><span class="line">hidden_size = <span class="number">500</span> </span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">num_epochs = <span class="number">1</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST dataset </span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),  </span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=<span class="string">&#x27;./data&#x27;</span>, </span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, </span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, </span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">examples = <span class="built_in">iter</span>(test_loader)</span><br><span class="line">example_data, example_targets = examples.<span class="built_in">next</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(example_data[i][<span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">img_grid = torchvision.utils.make_grid(example_data)</span><br><span class="line">writer.add_image(<span class="string">&#x27;mnist_images&#x27;</span>, img_grid)</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully connected neural network with one hidden layer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NeuralNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NeuralNet, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.l1 = nn.Linear(input_size, hidden_size) </span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">        self.l2 = nn.Linear(hidden_size, num_classes)  </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.l1(x)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line">        out = self.l2(out)</span><br><span class="line">        <span class="comment"># no activation and no softmax at the end</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">model = NeuralNet(input_size, hidden_size, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  </span><br><span class="line"></span><br><span class="line"><span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">writer.add_graph(model, example_data.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"><span class="comment">#writer.close()</span></span><br><span class="line"><span class="comment">#sys.exit()</span></span><br><span class="line"><span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model</span></span><br><span class="line">running_loss = <span class="number">0.0</span></span><br><span class="line">running_correct = <span class="number">0</span></span><br><span class="line">n_total_steps = <span class="built_in">len</span>(train_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> i, (images, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):  </span><br><span class="line">        <span class="comment"># origin shape: [100, 1, 28, 28]</span></span><br><span class="line">        <span class="comment"># resized: [100, 784]</span></span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Forward pass</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Backward and optimize</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        running_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span> (<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Step [<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_total_steps&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">            <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;training loss&#x27;</span>, running_loss / <span class="number">100</span>, epoch * n_total_steps + i)</span><br><span class="line">            running_accuracy = running_correct / <span class="number">100</span> / predicted.size(<span class="number">0</span>)</span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;accuracy&#x27;</span>, running_accuracy, epoch * n_total_steps + i)</span><br><span class="line">            running_correct = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">            <span class="comment">###################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="comment"># In test phase, we don&#x27;t need to compute gradients (for memory efficiency)</span></span><br><span class="line">class_labels = []</span><br><span class="line">class_preds = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    n_correct = <span class="number">0</span></span><br><span class="line">    n_samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">        images = images.reshape(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        outputs = model(images)</span><br><span class="line">        <span class="comment"># max returns (value ,index)</span></span><br><span class="line">        values, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        n_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        n_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        class_probs_batch = [F.softmax(output, dim=<span class="number">0</span>) <span class="keyword">for</span> output <span class="keyword">in</span> outputs]</span><br><span class="line"></span><br><span class="line">        class_preds.append(class_probs_batch)</span><br><span class="line">        class_labels.append(predicted)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 10000, 10, and 10000, 1</span></span><br><span class="line">    <span class="comment"># stack concatenates tensors along a new dimension</span></span><br><span class="line">    <span class="comment"># cat concatenates tensors in the given dimension</span></span><br><span class="line">    class_preds = torch.cat([torch.stack(batch) <span class="keyword">for</span> batch <span class="keyword">in</span> class_preds])</span><br><span class="line">    class_labels = torch.cat(class_labels)</span><br><span class="line"></span><br><span class="line">    acc = <span class="number">100.0</span> * n_correct / n_samples</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Accuracy of the network on the 10000 test images: <span class="subst">&#123;acc&#125;</span> %&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">############## TENSORBOARD ########################</span></span><br><span class="line">    classes = <span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> classes:</span><br><span class="line">        labels_i = class_labels == i</span><br><span class="line">        preds_i = class_preds[:, i]</span><br><span class="line">        writer.add_pr_curve(<span class="built_in">str</span>(i), labels_i, preds_i, global_step=<span class="number">0</span>)</span><br><span class="line">        writer.close()</span><br><span class="line">    <span class="comment">###################################################</span></span><br></pre></td></tr></table></figure>

<h1 id="Save-amp-Load"><a href="#Save-amp-Load" class="headerlink" title="Save &amp; Load"></a>Save &amp; Load</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 3 DIFFERENT METHODS TO REMEMBER:</span></span><br><span class="line"><span class="string"> - torch.save(arg, PATH) # can be model, tensor, or dictionary</span></span><br><span class="line"><span class="string"> - torch.load(PATH)</span></span><br><span class="line"><span class="string"> - torch.load_state_dict(arg)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27; 2 DIFFERENT WAYS OF SAVING</span></span><br><span class="line"><span class="string"># 1) lazy way: save whole model</span></span><br><span class="line"><span class="string">torch.save(model, PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model class must be defined somewhere</span></span><br><span class="line"><span class="string">model = torch.load(PATH)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) recommended way: save only the state_dict</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># model must be created again with parameters</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_input_features</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear = nn.Linear(n_input_features, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y_pred = torch.sigmoid(self.linear(x))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line"><span class="comment"># train your model...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">####################save all ######################################</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save and load entire model</span></span><br><span class="line"></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model, FILE)</span><br><span class="line"></span><br><span class="line">loaded_model = torch.load(FILE)</span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> loaded_model.parameters():</span><br><span class="line">    <span class="built_in">print</span>(param)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">############save only state dict #########################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># save only state dict</span></span><br><span class="line">FILE = <span class="string">&quot;model.pth&quot;</span></span><br><span class="line">torch.save(model.state_dict(), FILE)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.state_dict())</span><br><span class="line">loaded_model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">loaded_model.load_state_dict(torch.load(FILE)) <span class="comment"># it takes the loaded dictionary, not the path file itself</span></span><br><span class="line">loaded_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loaded_model.state_dict())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">###########load checkpoint#####################</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line">checkpoint = &#123;</span><br><span class="line"><span class="string">&quot;epoch&quot;</span>: <span class="number">90</span>,</span><br><span class="line"><span class="string">&quot;model_state&quot;</span>: model.state_dict(),</span><br><span class="line"><span class="string">&quot;optim_state&quot;</span>: optimizer.state_dict()</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line">FILE = <span class="string">&quot;checkpoint.pth&quot;</span></span><br><span class="line">torch.save(checkpoint, FILE)</span><br><span class="line"></span><br><span class="line">model = Model(n_input_features=<span class="number">6</span>)</span><br><span class="line">optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(FILE)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">&#x27;model_state&#x27;</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">&#x27;optim_state&#x27;</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">&#x27;epoch&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line"><span class="comment"># model.train()</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(optimizer.state_dict())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remember that you must call model.eval() to set dropout and batch normalization layers </span></span><br><span class="line"><span class="comment"># to evaluation mode before running inference. Failing to do this will yield </span></span><br><span class="line"><span class="comment"># inconsistent inference results. If you wish to resuming training, </span></span><br><span class="line"><span class="comment"># call model.train() to ensure these layers are in training mode.</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot; SAVING ON GPU/CPU </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 1) Save on GPU, Load on CPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=device))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 2) Save on GPU, Load on GPU</span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH))</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Note: Be sure to use the .to(torch.device(&#x27;cuda&#x27;)) function </span></span><br><span class="line"><span class="string"># on all model inputs, too!</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 3) Save on CPU, Load on GPU</span></span><br><span class="line"><span class="string">torch.save(model.state_dict(), PATH)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">device = torch.device(&quot;cuda&quot;)</span></span><br><span class="line"><span class="string">model = Model(*args, **kwargs)</span></span><br><span class="line"><span class="string">model.load_state_dict(torch.load(PATH, map_location=&quot;cuda:0&quot;))  # Choose whatever GPU device number you want</span></span><br><span class="line"><span class="string">model.to(device)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># This loads the model to a given GPU device. </span></span><br><span class="line"><span class="string"># Next, be sure to call model.to(torch.device(&#x27;cuda&#x27;)) to convert the model’s parameter tensors to CUDA tensors</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>





























        </div>
        
<blockquote class="copyright">
    <p><strong>Link to this article : </strong><a class="permalink" href="http://juggler.fun/uncategorized/Pytorch">http://juggler.fun/uncategorized/Pytorch</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">Catalogue</h3>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">1.</span> <span class="toc-text">基本操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Gradients"><span class="toc-number">2.</span> <span class="toc-text">Gradients</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Backpropagation"><span class="toc-number">2.1.</span> <span class="toc-text">Backpropagation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradient-Descent"><span class="toc-number">2.2.</span> <span class="toc-text">Gradient Descent</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Training-pipeline"><span class="toc-number">3.</span> <span class="toc-text">Training pipeline</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Linear-Regression"><span class="toc-number">4.</span> <span class="toc-text">Linear Regression</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Logistic-Regression"><span class="toc-number">4.1.</span> <span class="toc-text">Logistic Regression</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dataset-and-Dataloader"><span class="toc-number">5.</span> <span class="toc-text">Dataset and Dataloader</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dataset-transformers"><span class="toc-number">6.</span> <span class="toc-text">Dataset transformers</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#SoftMax-and-Crossentropy"><span class="toc-number">7.</span> <span class="toc-text">SoftMax and Crossentropy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Neural-network"><span class="toc-number">8.</span> <span class="toc-text">Neural network</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Activation-Function"><span class="toc-number">9.</span> <span class="toc-text">Activation Function</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Feed-Forward-Neural-Net"><span class="toc-number">10.</span> <span class="toc-text">Feed-Forward Neural Net</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CNN"><span class="toc-number">11.</span> <span class="toc-text">CNN</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Transfer-Learning"><span class="toc-number">12.</span> <span class="toc-text">Transfer Learning</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Tensorboard"><span class="toc-number">13.</span> <span class="toc-text">Tensorboard</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Save-amp-Load"><span class="toc-number">14.</span> <span class="toc-text">Save &amp; Load</span></a></li></ol>
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/fengkx">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://t.me/fengkx">
                <i class="iconfont icon-telegram"></i>
            </a>
        
            <a target="_blank" rel="noopener" href="https://twitter.com/example">
                <i class="iconfont icon-twitter"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>



<script src="/js/local-search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>






    </body>
</html>
